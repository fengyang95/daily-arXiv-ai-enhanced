{"id": "2509.09744", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09744", "abs": "https://arxiv.org/abs/2509.09744", "authors": ["Mujie Liu", "Chenze Wang", "Liping Chen", "Nguyen Linh Dan Le", "Niharika Tewari", "Ting Dang", "Jiangang Ma", "Feng Xia"], "title": "Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis", "comment": null, "summary": "The limited availability of labeled brain network data makes it challenging\nto achieve accurate and interpretable psychiatric diagnoses. While\nself-supervised learning (SSL) offers a promising solution, existing methods\noften rely on augmentation strategies that can disrupt crucial structural\nsemantics in brain graphs. To address this, we propose SAM-BG, a two-stage\nframework for learning brain graph representations with structural semantic\npreservation. In the pre-training stage, an edge masker is trained on a small\nlabeled subset to capture key structural semantics. In the SSL stage, the\nextracted structural priors guide a structure-aware augmentation process,\nenabling the model to learn more semantically meaningful and robust\nrepresentations. Experiments on two real-world psychiatric datasets demonstrate\nthat SAM-BG outperforms state-of-the-art methods, particularly in small-labeled\ndata settings, and uncovers clinically relevant connectivity patterns that\nenhance interpretability. Our code is available at\nhttps://github.com/mjliu99/SAM-BG.", "AI": {"tldr": "SAM-BG\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u4fdd\u62a4\u6765\u5b66\u4e60\u8111\u56fe\u8868\u793a\uff0c\u5728\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6837\u672c\u6570\u636e\u573a\u666f\u4e0b\u3002", "motivation": "\u8111\u7f51\u7edc\u6807\u8bb0\u6570\u636e\u6709\u9650\uff0c\u73b0\u6709\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u7684\u6570\u636e\u589e\u5f3a\u7b56\u7565\u53ef\u80fd\u7834\u574f\u8111\u56fe\u7684\u5173\u952e\u7ed3\u6784\u8bed\u4e49\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4fdd\u62a4\u7ed3\u6784\u8bed\u4e49\u7684\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u9884\u8bad\u7ec3\u9636\u6bb5\u5728\u5c0f\u6807\u8bb0\u5b50\u96c6\u4e0a\u8bad\u7ec3\u8fb9\u7f18\u63a9\u7801\u5668\u6355\u83b7\u5173\u952e\u7ed3\u6784\u8bed\u4e49\uff1b2\uff09\u81ea\u76d1\u7763\u5b66\u4e60\u9636\u6bb5\u5229\u7528\u7ed3\u6784\u5148\u9a8c\u6307\u5bfc\u7ed3\u6784\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u8fc7\u7a0b\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u7cbe\u795e\u75be\u75c5\u6570\u636e\u96c6\u4e0a\uff0cSAM-BG\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5c0f\u6807\u8bb0\u6570\u636e\u8bbe\u7f6e\u4e0b\uff0c\u5e76\u53d1\u73b0\u4e86\u5177\u6709\u4e34\u5e8a\u76f8\u5173\u6027\u7684\u8fde\u63a5\u6a21\u5f0f\u3002", "conclusion": "SAM-BG\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u4fdd\u62a4\u6709\u6548\u63d0\u5347\u4e86\u8111\u56fe\u8868\u793a\u5b66\u4e60\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u7cbe\u795e\u75be\u75c5\u8bca\u65ad\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09747", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09747", "abs": "https://arxiv.org/abs/2509.09747", "authors": ["Leen Daher", "Zhaobo Wang", "Malcolm Mielle"], "title": "D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference", "comment": null, "summary": "Cross-modal transfer learning is used to improve multi-modal classification\nmodels (e.g., for human activity recognition in human-robot collaboration).\nHowever, existing methods require paired sensor data at both training and\ninference, limiting deployment in resource-constrained environments where full\nsensor suites are not economically and technically usable. To address this, we\npropose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns\nmodality-specific representations without requiring joint sensor modality\nduring inference. Our approach combines a self-attention module for feature\nextraction with a novel cross-attention alignment loss, which enforces the\nalignment of sensors' feature spaces without requiring the coupling of the\nclassification pipelines of both modalities. We evaluate D-CAT on three\nmulti-modal human activity datasets (IMU, video, and audio) under both\nin-distribution and out-of-distribution scenarios, comparing against uni-modal\nmodels. Results show that in in-distribution scenarios, transferring from\nhigh-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains\nover uni-modal training. In out-of-distribution scenarios, even weaker source\nmodalities (e.g., IMU to video) improve target performance, as long as the\ntarget model isn't overfitted on the training data. By enabling single-sensor\ninference with cross-modal knowledge, D-CAT reduces hardware redundancy for\nperception systems while maintaining accuracy, which is critical for\ncost-sensitive or adaptive deployments (e.g., assistive robots in homes with\nvariable sensor availability). Code is available at\nhttps://github.com/Schindler-EPFL-Lab/D-CAT.", "AI": {"tldr": "D-CAT\u662f\u4e00\u79cd\u89e3\u8026\u8de8\u6ce8\u610f\u529b\u8fc1\u79fb\u6846\u67b6\uff0c\u5141\u8bb8\u5728\u63a8\u7406\u65f6\u4ec5\u4f7f\u7528\u5355\u4e00\u4f20\u611f\u5668\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\u63d0\u5347\u6027\u80fd\uff0c\u51cf\u5c11\u786c\u4ef6\u5197\u4f59\u3002", "motivation": "\u73b0\u6709\u8de8\u6a21\u6001\u8fc1\u79fb\u5b66\u4e60\u65b9\u6cd5\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u90fd\u9700\u8981\u914d\u5bf9\u4f20\u611f\u5668\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u63a8\u7406\u65f6\u4ec5\u4f7f\u7528\u5355\u4e00\u4f20\u611f\u5668\uff0c\u540c\u65f6\u5229\u7528\u5176\u4ed6\u6a21\u6001\u7684\u77e5\u8bc6\u3002", "method": "\u63d0\u51faD-CAT\u6846\u67b6\uff0c\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u65b0\u578b\u8de8\u6ce8\u610f\u529b\u5bf9\u9f50\u635f\u5931\uff0c\u5f3a\u5236\u5bf9\u9f50\u4e0d\u540c\u4f20\u611f\u5668\u7684\u7279\u5f81\u7a7a\u95f4\uff0c\u800c\u4e0d\u9700\u8981\u8026\u5408\u4e24\u4e2a\u6a21\u6001\u7684\u5206\u7c7b\u7ba1\u9053\u3002", "result": "\u5728\u4e09\u4e2a\u591a\u6a21\u6001\u4eba\u7c7b\u6d3b\u52a8\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u5728\u5206\u5e03\u5185\u573a\u666f\u4e2d\uff0c\u4ece\u9ad8\u6027\u80fd\u6a21\u6001\u8fc1\u79fb\u53ef\u83b7\u5f9710% F1\u5206\u6570\u63d0\u5347\uff1b\u5728\u5206\u5e03\u5916\u573a\u666f\u4e2d\uff0c\u5373\u4f7f\u8f83\u5f31\u7684\u6e90\u6a21\u6001\u4e5f\u80fd\u6539\u5584\u76ee\u6807\u6027\u80fd\u3002", "conclusion": "D-CAT\u901a\u8fc7\u5b9e\u73b0\u5355\u4f20\u611f\u5668\u63a8\u7406\u548c\u8de8\u6a21\u6001\u77e5\u8bc6\u8fc1\u79fb\uff0c\u51cf\u5c11\u4e86\u611f\u77e5\u7cfb\u7edf\u7684\u786c\u4ef6\u5197\u4f59\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u6210\u672c\u654f\u611f\u6216\u81ea\u9002\u5e94\u90e8\u7f72\u573a\u666f\u3002"}}
{"id": "2509.09751", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09751", "abs": "https://arxiv.org/abs/2509.09751", "authors": ["Junqiao Wang", "Zhaoyang Guan", "Guanyu Liu", "Tianze Xia", "Xianzhi Li", "Shuo Yin", "Xinyuan Song", "Chuhan Cheng", "Tianyu Shi", "Alex Lee"], "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "comment": null, "summary": "Predicting cryptocurrency returns is notoriously difficult: price movements\nare driven by a fast-shifting blend of on-chain activity, news flow, and social\nsentiment, while labeled training data are scarce and expensive. In this paper,\nwe present Meta-RL-Crypto, a unified transformer-based architecture that\nunifies meta-learning and reinforcement learning (RL) to create a fully\nself-improving trading agent. Starting from a vanilla instruction-tuned LLM,\nthe agent iteratively alternates between three roles-actor, judge, and\nmeta-judge-in a closed-loop architecture. This learning process requires no\nadditional human supervision. It can leverage multimodal market inputs and\ninternal preference feedback. The agent in the system continuously refines both\nthe trading policy and evaluation criteria. Experiments across diverse market\nregimes demonstrate that Meta-RL-Crypto shows good performance on the technical\nindicators of the real market and outperforming other LLM-based baselines.", "AI": {"tldr": "Meta-RL-Crypto\u662f\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u7edf\u4e00\u67b6\u6784\uff0c\u7ed3\u5408\u5143\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u5b8c\u5168\u81ea\u6539\u8fdb\u7684\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u4ee3\u7406\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u5728\u591a\u79cd\u5e02\u573a\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u56de\u62a5\u9884\u6d4b\u6781\u5176\u56f0\u96be\uff0c\u4ef7\u683c\u53d8\u52a8\u53d7\u5230\u94fe\u4e0a\u6d3b\u52a8\u3001\u65b0\u95fb\u6d41\u548c\u793e\u4ea4\u60c5\u7eea\u7b49\u591a\u79cd\u5feb\u901f\u53d8\u5316\u56e0\u7d20\u9a71\u52a8\uff0c\u4e14\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u6602\u8d35\u3002", "method": "\u4ece\u57fa\u7840\u6307\u4ee4\u8c03\u4f18LLM\u5f00\u59cb\uff0c\u4ee3\u7406\u5728\u95ed\u73af\u67b6\u6784\u4e2d\u8fed\u4ee3\u4ea4\u66ff\u626e\u6f14\u4e09\u4e2a\u89d2\u8272\uff08\u6267\u884c\u8005\u3001\u8bc4\u5224\u8005\u548c\u5143\u8bc4\u5224\u8005\uff09\uff0c\u5229\u7528\u591a\u6a21\u6001\u5e02\u573a\u8f93\u5165\u548c\u5185\u90e8\u504f\u597d\u53cd\u9988\uff0c\u6301\u7eed\u6539\u8fdb\u4ea4\u6613\u7b56\u7565\u548c\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u5728\u591a\u6837\u5316\u5e02\u573a\u673a\u5236\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMeta-RL-Crypto\u5728\u771f\u5b9e\u5e02\u573a\u6280\u672f\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u81ea\u6539\u8fdb\u4ea4\u6613\u4ee3\u7406\u67b6\u6784\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u52a0\u5bc6\u8d27\u5e01\u9884\u6d4b\u4e2d\u7684\u590d\u6742\u6027\u548c\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u4ea4\u6613\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09754", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09754", "abs": "https://arxiv.org/abs/2509.09754", "authors": ["Yiqun Shen", "Song Yuan", "Zhengze Zhang", "Xiaoliang Wang", "Daxin Jiang", "Nguyen Cam-Tu"], "title": "LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation", "comment": null, "summary": "KV Cache is commonly used to accelerate LLM inference with long contexts, yet\nits high memory demand drives the need for cache compression. Existing\ncompression methods, however, are largely heuristic and lack dynamic budget\nallocation. To address this limitation, we introduce a unified framework for\ncache compression by minimizing information loss in Transformer residual\nstreams. Building on it, we analyze the layer attention output loss and derive\na new metric to compare cache entries across heads, enabling layer-wise\ncompression with dynamic head budgets. Additionally, by contrasting cross-layer\ninformation, we also achieve dynamic layer budgets. LAVa is the first unified\nstrategy for cache eviction and dynamic budget allocation that, unlike prior\nmethods, does not rely on training or the combination of multiple strategies.\nExperiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and\nInfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a\nnew insight: dynamic layer budgets are crucial for generation tasks (e.g., code\ncompletion), while dynamic head budgets play a key role in extraction tasks\n(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently\nmaintains top performance across task types. Our code is available at\nhttps://github.com/MGDDestiny/Lava.", "AI": {"tldr": "LAVa\u662f\u4e00\u4e2a\u7edf\u4e00\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316Transformer\u6b8b\u5dee\u6d41\u4e2d\u7684\u4fe1\u606f\u635f\u5931\u6765\u5b9e\u73b0\u52a8\u6001\u9884\u7b97\u5206\u914d\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u5927\u591a\u662f\u542f\u53d1\u5f0f\u7684\uff0c\u7f3a\u4e4f\u52a8\u6001\u9884\u7b97\u5206\u914d\u673a\u5236\uff0c\u65e0\u6cd5\u6839\u636e\u4efb\u52a1\u9700\u6c42\u7075\u6d3b\u8c03\u6574\u4e0d\u540c\u5c42\u548c\u6ce8\u610f\u529b\u5934\u7684\u7f13\u5b58\u9884\u7b97\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5c42\u6ce8\u610f\u529b\u8f93\u51fa\u635f\u5931\uff0c\u63a8\u5bfc\u51fa\u8de8\u5934\u6bd4\u8f83\u7684\u65b0\u5ea6\u91cf\u6807\u51c6\uff0c\u5b9e\u73b0\u5c42\u7ea7\u538b\u7f29\u548c\u52a8\u6001\u5934\u9884\u7b97\u5206\u914d\uff1b\u901a\u8fc7\u5bf9\u6bd4\u8de8\u5c42\u4fe1\u606f\uff0c\u5b9e\u73b0\u52a8\u6001\u5c42\u9884\u7b97\u5206\u914d\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08LongBench\u3001Needle-In-A-Haystack\u3001Ruler\u3001InfiniteBench\uff09\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u53d1\u73b0\u52a8\u6001\u5c42\u9884\u7b97\u5bf9\u751f\u6210\u4efb\u52a1\u5173\u952e\uff0c\u52a8\u6001\u5934\u9884\u7b97\u5bf9\u62bd\u53d6\u4efb\u52a1\u91cd\u8981\u3002", "conclusion": "LAVa\u662f\u9996\u4e2a\u7edf\u4e00\u7684\u7f13\u5b58\u9a71\u9010\u548c\u52a8\u6001\u9884\u7b97\u5206\u914d\u7b56\u7565\uff0c\u65e0\u9700\u8bad\u7ec3\u6216\u591a\u7b56\u7565\u7ec4\u5408\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u7c7b\u578b\u4e2d\u4fdd\u6301\u9876\u7ea7\u6027\u80fd\u3002"}}
{"id": "2509.09853", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09853", "abs": "https://arxiv.org/abs/2509.09853", "authors": ["Zhiyu Fan", "Kirill Vasilevski", "Dayi Lin", "Boyuan Chen", "Yihao Chen", "Zhiqing Zhong", "Jie M. Zhang", "Pinjia He", "Ahmed E. Hassan"], "title": "SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints", "comment": null, "summary": "The advancement of large language models (LLMs) and code agents has\ndemonstrated significant potential to assist software engineering (SWE) tasks,\nsuch as autonomous issue resolution and feature addition. Existing AI for\nsoftware engineering leaderboards (e.g., SWE-bench) focus solely on solution\naccuracy, ignoring the crucial factor of effectiveness in a\nresource-constrained world. This is a universal problem that also exists beyond\nsoftware engineering tasks: any AI system should be more than correct - it must\nalso be cost-effective. To address this gap, we introduce SWE-Effi, a set of\nnew metrics to re-evaluate AI systems in terms of holistic effectiveness\nscores. We define effectiveness as the balance between the accuracy of outcome\n(e.g., issue resolve rate) and the resources consumed (e.g., token and time).\nIn this paper, we specifically focus on the software engineering scenario by\nre-ranking popular AI systems for issue resolution on a subset of the SWE-bench\nbenchmark using our new multi-dimensional metrics. We found that AI system's\neffectiveness depends not just on the scaffold itself, but on how well it\nintegrates with the base model, which is key to achieving strong performance in\na resource-efficient manner. We also identified systematic challenges such as\nthe \"token snowball\" effect and, more significantly, a pattern of \"expensive\nfailures\". In these cases, agents consume excessive resources while stuck on\nunsolvable tasks - an issue that not only limits practical deployment but also\ndrives up the cost of failed rollouts during RL training. Lastly, we observed a\nclear trade-off between effectiveness under the token budget and effectiveness\nunder the time budget, which plays a crucial role in managing project budgets\nand enabling scalable reinforcement learning, where fast responses are\nessential.", "AI": {"tldr": "SWE-Effi\u63d0\u51fa\u65b0\u7684\u591a\u7ef4\u5ea6\u6307\u6807\u6765\u8bc4\u4f30AI\u7cfb\u7edf\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u7efc\u5408\u6548\u80fd\uff0c\u4e0d\u4ec5\u8003\u8651\u51c6\u786e\u6027\u8fd8\u8003\u8651\u8d44\u6e90\u6d88\u8017\uff08token\u548c\u65f6\u95f4\uff09\uff0c\u53d1\u73b0\u5728SWE-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2dAI\u7cfb\u7edf\u7684\u6548\u80fd\u53d6\u51b3\u4e8e\u811a\u624b\u67b6\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u6574\u5408\u8d28\u91cf\uff0c\u5e76\u8bc6\u522b\u51fa\"token\u96ea\u7403\u6548\u5e94\"\u548c\"\u6602\u8d35\u5931\u8d25\"\u7b49\u7cfb\u7edf\u6027\u6311\u6218\u3002", "motivation": "\u73b0\u6709AI\u8f6f\u4ef6\u5de5\u7a0b\u6392\u884c\u699c\uff08\u5982SWE-bench\uff09\u4ec5\u5173\u6ce8\u89e3\u51b3\u65b9\u6848\u51c6\u786e\u6027\uff0c\u5ffd\u7565\u4e86\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u6548\u80fd\u56e0\u7d20\u3002\u4efb\u4f55AI\u7cfb\u7edf\u4e0d\u4ec5\u8981\u6b63\u786e\uff0c\u8fd8\u5fc5\u987b\u5177\u6709\u6210\u672c\u6548\u76ca\u3002", "method": "\u5f15\u5165SWE-Effi\u6307\u6807\u96c6\uff0c\u5728\u591a\u7ef4\u5ea6\u4e0a\u91cd\u65b0\u8bc4\u4f30AI\u7cfb\u7edf\u6548\u80fd\uff0c\u5b9a\u4e49\u4e3a\u7ed3\u679c\u51c6\u786e\u6027\uff08\u5982\u95ee\u9898\u89e3\u51b3\u7387\uff09\u4e0e\u8d44\u6e90\u6d88\u8017\uff08\u5982token\u548c\u65f6\u95f4\uff09\u4e4b\u95f4\u7684\u5e73\u8861\u3002\u5728SWE-bench\u5b50\u96c6\u4e0a\u4f7f\u7528\u65b0\u6307\u6807\u5bf9\u6d41\u884c\u7684AI\u95ee\u9898\u89e3\u51b3\u7cfb\u7edf\u8fdb\u884c\u91cd\u65b0\u6392\u540d\u3002", "result": "\u53d1\u73b0AI\u7cfb\u7edf\u6548\u80fd\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u811a\u624b\u67b6\u672c\u8eab\uff0c\u8fd8\u53d6\u51b3\u4e8e\u5176\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u6574\u5408\u8d28\u91cf\uff1b\u8bc6\u522b\u51fa\"token\u96ea\u7403\u6548\u5e94\"\u548c\"\u6602\u8d35\u5931\u8d25\"\u6a21\u5f0f\uff08\u5728\u65e0\u6cd5\u89e3\u51b3\u7684\u4efb\u52a1\u4e0a\u6d88\u8017\u8fc7\u591a\u8d44\u6e90\uff09\uff1b\u89c2\u5bdf\u5230token\u9884\u7b97\u548c\u65f6\u95f4\u9884\u7b97\u4e0b\u7684\u6548\u80fd\u5b58\u5728\u660e\u663e\u6743\u8861\u3002", "conclusion": "\u7efc\u5408\u6548\u80fd\u8bc4\u4f30\u5bf9AI\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u8d44\u6e90\u6548\u7387\u662f\u5b9e\u73b0\u5f3a\u6027\u80fd\u7684\u5173\u952e\uff0c\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u9879\u76ee\u7ba1\u7406\u9884\u7b97\u548c\u53ef\u6269\u5c55\u7684\u5f3a\u5316\u5b66\u4e60\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2509.09699", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09699", "abs": "https://arxiv.org/abs/2509.09699", "authors": ["Mingyang Li", "Viktor Schlegel", "Tingting Mu", "Warren Del-Pinto", "Goran Nenadic"], "title": "Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs", "comment": null, "summary": "Mapping clinical documents to standardised clinical vocabularies is an\nimportant task, as it provides structured data for information retrieval and\nanalysis, which is essential to clinical research, hospital administration and\nimproving patient care. However, manual coding is both difficult and\ntime-consuming, making it impractical at scale. Automated coding can\npotentially alleviate this burden, improving the availability and accuracy of\nstructured clinical data. The task is difficult to automate, as it requires\nmapping to high-dimensional and long-tailed target spaces, such as the\nInternational Classification of Diseases (ICD). While external knowledge\nsources have been readily utilised to enhance output code representation, the\nuse of external resources for representing the input documents has been\nunderexplored. In this work, we compute a structured representation of the\ninput documents, making use of document-level knowledge graphs (KGs) that\nprovide a comprehensive structured view of a patient's condition. The resulting\nknowledge graph efficiently represents the patient-centred input documents with\n23\\% of the original text while retaining 90\\% of the information. We assess\nthe effectiveness of this graph for automated ICD-9 coding by integrating it\ninto the state-of-the-art ICD coding architecture PLM-ICD. Our experiments\nyield improved Macro-F1 scores by up to 3.20\\% on popular benchmarks, while\nimproving training efficiency. We attribute this improvement to different types\nof entities and relationships in the KG, and demonstrate the improved\nexplainability potential of the approach over the text-only baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u5316\u8868\u793a\u4e34\u5e8a\u6587\u6863\uff0c\u7528\u4e8e\u81ea\u52a8\u5316ICD\u7f16\u7801\u4efb\u52a1\uff0c\u5728\u4fdd\u630190%\u4fe1\u606f\u7684\u540c\u65f6\u51cf\u5c1123%\u6587\u672c\u91cf\uff0c\u5c06Macro-F1\u5206\u6570\u63d0\u53473.20%\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u4e34\u5e8a\u6587\u6863\u5230\u6807\u51c6\u5316\u8bcd\u6c47\u7684\u6620\u5c04\u5bf9\u4e34\u5e8a\u7814\u7a76\u548c\u60a3\u8005\u62a4\u7406\u5f88\u91cd\u8981\uff0c\u4f46\u4eba\u5de5\u7f16\u7801\u8017\u65f6\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u589e\u5f3a\u8f93\u51fa\u8868\u793a\uff0c\u800c\u5bf9\u8f93\u5165\u6587\u6863\u7684\u5916\u90e8\u8d44\u6e90\u8868\u793a\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u6587\u6863\u7ea7\u77e5\u8bc6\u56fe\u8c31\u6765\u7ed3\u6784\u5316\u8868\u793a\u8f93\u5165\u6587\u6863\uff0c\u63d0\u4f9b\u60a3\u8005\u72b6\u51b5\u7684\u5168\u9762\u7ed3\u6784\u5316\u89c6\u56fe\u3002\u5c06\u8be5\u56fe\u8c31\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684ICD\u7f16\u7801\u67b6\u6784PLM-ICD\u4e2d\u3002", "result": "\u77e5\u8bc6\u56fe\u8c31\u752823%\u7684\u539f\u59cb\u6587\u672c\u4fdd\u7559\u4e8690%\u7684\u4fe1\u606f\uff0c\u5728ICD-9\u7f16\u7801\u4efb\u52a1\u4e0a\u5c06Macro-F1\u5206\u6570\u63d0\u5347\u6700\u591a3.20%\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u7c7b\u578b\u5e26\u6765\u4e86\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u5316\u8868\u793a\u4e34\u5e8a\u6587\u6863\u80fd\u6709\u6548\u63d0\u5347\u81ea\u52a8\u5316ICD\u7f16\u7801\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u6f5c\u529b\u3002"}}
{"id": "2509.09738", "categories": ["cs.AI", "q-bio.QM", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.09738", "abs": "https://arxiv.org/abs/2509.09738", "authors": ["Umut Eser", "Yael Gozin", "L. Jay Stallons", "Ari Caroline", "Martin Preusse", "Brandon Rice", "Scott Wright", "Andrew Robertson"], "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing", "comment": null, "summary": "Background: Investigational New Drug (IND) application preparation is\ntime-intensive and expertise-dependent, slowing early clinical development.\nObjective: To evaluate whether a large language model (LLM) platform (AutoIND)\ncan reduce first-draft composition time while maintaining document quality in\nregulatory submissions. Methods: Drafting times for IND nonclinical written\nsummaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly\nrecorded. For comparison, manual drafting times for IND summaries previously\ncleared by the U.S. FDA were estimated from the experience of regulatory\nwriters ($\\geq$6 years) and used as industry-standard benchmarks. Quality was\nassessed by a blinded regulatory writing assessor using seven pre-specified\ncategories: correctness, completeness, conciseness, consistency, clarity,\nredundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a\npercentage. A critical regulatory error was defined as any misrepresentation or\nomission likely to alter regulatory interpretation (e.g., incorrect NOAEL,\nomission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced\ninitial drafting time by $\\sim$97% (from $\\sim$100 h to 3.7 h for 18,870\npages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).\nQuality scores were 69.6\\% and 77.9\\% for IND-1 and IND-2. No critical\nregulatory errors were detected, but deficiencies in emphasis, conciseness, and\nclarity were noted. Conclusions: AutoIND can dramatically accelerate IND\ndrafting, but expert regulatory writers remain essential to mature outputs to\nsubmission-ready quality. Systematic deficiencies identified provide a roadmap\nfor targeted model improvements.", "AI": {"tldr": "AutoIND LLM\u5e73\u53f0\u53ef\u5c06IND\u7533\u8bf7\u7684\u975e\u4e34\u5e8a\u4e66\u9762\u603b\u7ed3\u8d77\u8349\u65f6\u95f4\u51cf\u5c11\u7ea697%\uff0c\u4ece\u7ea6100\u5c0f\u65f6\u964d\u81f33-4\u5c0f\u65f6\uff0c\u8d28\u91cf\u8bc4\u5206\u8fbe70-78%\uff0c\u65e0\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u4f46\u4ecd\u9700\u4e13\u5bb6\u5b8c\u5584\u4ee5\u63d0\u9ad8\u8d28\u91cf\u3002", "motivation": "IND\u7533\u8bf7\u51c6\u5907\u8fc7\u7a0b\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u4e1a\u77e5\u8bc6\uff0c\u51cf\u7f13\u4e86\u65e9\u671f\u4e34\u5e8a\u5f00\u53d1\u8fdb\u7a0b\uff0c\u9700\u8981\u5bfb\u627e\u63d0\u9ad8\u6548\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528AutoIND LLM\u5e73\u53f0\u751f\u6210IND\u975e\u4e34\u5e8a\u4e66\u9762\u603b\u7ed3(eCTD\u6a21\u57572.6.2, 2.6.4, 2.6.6)\uff0c\u8bb0\u5f55\u8d77\u8349\u65f6\u95f4\u5e76\u4e0e\u4eba\u5de5\u8d77\u8349\u65f6\u95f4\u5bf9\u6bd4\uff0c\u7531\u76f2\u8bc4\u76d1\u7ba1\u5199\u4f5c\u8bc4\u4f30\u5458\u4ece7\u4e2a\u9884\u8bbe\u7c7b\u522b\u8bc4\u4f30\u8d28\u91cf\u3002", "result": "\u8d77\u8349\u65f6\u95f4\u51cf\u5c1197%(\u4ece~100\u5c0f\u65f6\u964d\u81f33.7\u5c0f\u65f6\u548c2.6\u5c0f\u65f6)\uff0c\u8d28\u91cf\u8bc4\u5206\u5206\u522b\u4e3a69.6%\u548c77.9%\uff0c\u65e0\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u4f46\u5728\u91cd\u70b9\u7a81\u51fa\u3001\u7b80\u6d01\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "AutoIND\u80fd\u663e\u8457\u52a0\u901fIND\u8d77\u8349\uff0c\u4f46\u4e13\u5bb6\u76d1\u7ba1\u5199\u4f5c\u8005\u4ecd\u9700\u5b8c\u5584\u8f93\u51fa\u4ee5\u8fbe\u5230\u63d0\u4ea4\u8d28\u91cf\uff0c\u7cfb\u7edf\u6027\u7f3a\u9677\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u4e86\u8def\u7ebf\u56fe\u3002"}}
{"id": "2509.09772", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.09772", "abs": "https://arxiv.org/abs/2509.09772", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management", "comment": "10 pages, 5 figures, 4 tables", "summary": "Population health management programs for Medicaid populations coordinate\nlongitudinal outreach and services (e.g., benefits navigation, behavioral\nhealth, social needs support, and clinical scheduling) and must be safe, fair,\nand auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement\nLearning (HACO) framework that separates risk calibration from preference\noptimization to generate conservative action recommendations at scale. In our\nsetting, each step involves choosing among common coordination actions (e.g.,\nwhich member to contact, by which modality, and whether to route to a\nspecialized service) while controlling the near-term risk of adverse\nutilization events (e.g., unplanned emergency department visits or\nhospitalizations). Using a de-identified operational dataset from Waymark\ncomprising 2.77 million sequential decisions across 168,126 patients, HACO (i)\ntrains a lightweight risk model for adverse events, (ii) derives a conformal\nthreshold to mask unsafe actions at a target risk level, and (iii) learns a\npreference policy on the resulting safe subset. We evaluate policies with a\nversion-agnostic fitted Q evaluation (FQE) on stratified subsets and audit\nsubgroup performance across age, sex, and race. HACO achieves strong risk\ndiscrimination (AUC ~0.81) with a calibrated threshold ( {\\tau} ~0.038 at\n{\\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses\nreveal systematic differences in estimated value across demographics,\nunderscoring the importance of fairness auditing. Our results show that\nconformal risk gating integrates cleanly with offline RL to deliver\nconservative, auditable decision support for population health management\nteams.", "AI": {"tldr": "HACO\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u98ce\u9669\u6821\u51c6\u548c\u504f\u597d\u4f18\u5316\uff0c\u4e3a\u533b\u7597\u8865\u52a9\u4eba\u7fa4\u7684\u5065\u5eb7\u7ba1\u7406\u63d0\u4f9b\u4fdd\u5b88\u3001\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u652f\u6301\uff0c\u5728\u63a7\u5236\u4e0d\u826f\u4e8b\u4ef6\u98ce\u9669\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u5b89\u5168\u8986\u76d6\u7387\u3002", "motivation": "\u533b\u7597\u8865\u52a9\u4eba\u7fa4\u7684\u5065\u5eb7\u7ba1\u7406\u9879\u76ee\u9700\u8981\u534f\u8c03\u7eb5\u5411\u670d\u52a1\uff0c\u5fc5\u987b\u786e\u4fdd\u5b89\u5168\u3001\u516c\u5e73\u548c\u53ef\u5ba1\u8ba1\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u63a7\u5236\u98ce\u9669\u7684\u540c\u65f6\u4f18\u5316\u670d\u52a1\u504f\u597d\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u81ea\u9002\u5e94\u7b26\u5408\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60(HACO)\u6846\u67b6\uff1a1)\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u98ce\u9669\u6a21\u578b\u9884\u6d4b\u4e0d\u826f\u4e8b\u4ef6\uff1b2)\u4f7f\u7528\u7b26\u5408\u9608\u503c\u5c4f\u853d\u4e0d\u5b89\u5168\u884c\u52a8\uff1b3)\u5728\u5b89\u5168\u5b50\u96c6\u4e0a\u5b66\u4e60\u504f\u597d\u7b56\u7565\u3002\u4f7f\u7528270\u4e07\u6b21\u51b3\u7b56\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "HACO\u5b9e\u73b0\u4e86\u5f3a\u98ce\u9669\u533a\u5206\u80fd\u529b(AUC~0.81)\uff0c\u6821\u51c6\u9608\u503c\u5728\u03b1=0.10\u65f6\u4e3a\u03c4~0.038\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5b89\u5168\u8986\u76d6\u7387\u3002\u4e9a\u7ec4\u5206\u6790\u663e\u793a\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u4ef7\u503c\u5dee\u5f02\u3002", "conclusion": "\u7b26\u5408\u98ce\u9669\u95e8\u63a7\u4e0e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u4e3a\u4eba\u7fa4\u5065\u5eb7\u7ba1\u7406\u56e2\u961f\u63d0\u4f9b\u4fdd\u5b88\u4e14\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u652f\u6301\uff0c\u5f3a\u8c03\u4e86\u516c\u5e73\u6027\u5ba1\u8ba1\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2509.09700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09700", "abs": "https://arxiv.org/abs/2509.09700", "authors": ["Malavika Suresh", "Rahaf Aljundi", "Ikechukwu Nkisi-Orji", "Nirmalie Wiratunga"], "title": "Cross-Layer Attention Probing for Fine-Grained Hallucination Detection", "comment": "To be published at the TRUST-AI workshop, ECAI 2025", "summary": "With the large-scale adoption of Large Language Models (LLMs) in various\napplications, there is a growing reliability concern due to their tendency to\ngenerate inaccurate text, i.e. hallucinations. In this work, we propose\nCross-Layer Attention Probing (CLAP), a novel activation probing technique for\nhallucination detection, which processes the LLM activations across the entire\nresidual stream as a joint sequence. Our empirical evaluations using five LLMs\nand three tasks show that CLAP improves hallucination detection compared to\nbaselines on both greedy decoded responses as well as responses sampled at\nhigher temperatures, thus enabling fine-grained detection, i.e. the ability to\ndisambiguate hallucinations and non-hallucinations among different sampled\nresponses to a given prompt. This allows us to propose a detect-then-mitigate\nstrategy using CLAP to reduce hallucinations and improve LLM reliability\ncompared to direct mitigation approaches. Finally, we show that CLAP maintains\nhigh reliability even when applied out-of-distribution.", "AI": {"tldr": "\u63d0\u51faCLAP\u65b9\u6cd5\uff0c\u901a\u8fc7\u8de8\u5c42\u6ce8\u610f\u529b\u63a2\u6d4b\u6280\u672f\u68c0\u6d4bLLM\u5e7b\u89c9\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u68c0\u6d4b\u548c\u68c0\u6d4b\u540e\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u751f\u6210\u4e0d\u51c6\u786e\u6587\u672c\uff08\u5e7b\u89c9\uff09\u7684\u53ef\u9760\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "Cross-Layer Attention Probing (CLAP)\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u6fc0\u6d3b\u63a2\u6d4b\u6280\u672f\uff0c\u5c06\u6574\u4e2a\u6b8b\u5dee\u6d41\u4e2d\u7684LLM\u6fc0\u6d3b\u4f5c\u4e3a\u8054\u5408\u5e8f\u5217\u5904\u7406\u3002", "result": "\u57285\u4e2aLLM\u548c3\u4e2a\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0cCLAP\u5728\u8d2a\u5a6a\u89e3\u7801\u548c\u9ad8\u6e29\u91c7\u6837\u54cd\u5e94\u4e2d\u90fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u5e7b\u89c9\u68c0\u6d4b\u3002", "conclusion": "CLAP\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5e7b\u89c9\uff0c\u652f\u6301\u68c0\u6d4b\u540e\u7f13\u89e3\u7b56\u7565\uff0c\u63d0\u9ad8LLM\u53ef\u9760\u6027\uff0c\u4e14\u5728\u5206\u5e03\u5916\u573a\u666f\u4e0b\u4ecd\u4fdd\u6301\u9ad8\u53ef\u9760\u6027\u3002"}}
{"id": "2509.09782", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09782", "abs": "https://arxiv.org/abs/2509.09782", "authors": ["Roshini Pulishetty", "Mani Kishan Ghantasala", "Keerthy Kaushik Dasoju", "Niti Mangwani", "Vishal Garimella", "Aditya Mate", "Somya Chatterjee", "Yue Kang", "Ehi Nosakhare", "Sadid Hasan", "Soundar Srinivasan"], "title": "One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection", "comment": null, "summary": "The proliferation of large language models (LLMs) with varying computational\ncosts and performance profiles presents a critical challenge for scalable,\ncost-effective deployment in real-world applications. We introduce a unified\nrouting framework that leverages a single-head cross-attention mechanism to\njointly model query and model embeddings, enabling dynamic selection of the\noptimal LLM for each input query. Our approach is evaluated on RouterBench, a\nlarge-scale, publicly available benchmark encompassing diverse LLM pools and\ndomains. By explicitly capturing fine-grained query-model interactions, our\nrouter predicts both response quality and generation cost, achieving up to 6.6%\nimprovement in Average Improvement in Quality (AIQ) and 2.9% in maximum\nperformance over existing routers. To robustly balance performance and cost, we\npropose an exponential reward function that enhances stability across user\npreferences. The resulting architecture is lightweight, generalizes effectively\nacross domains, and demonstrates improved efficiency compared to prior methods,\nestablishing a new standard for cost-aware LLM routing.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5355\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u7684\u7edf\u4e00\u8def\u7531\u6846\u67b6\uff0c\u52a8\u6001\u9009\u62e9\u6700\u4f18LLM\uff0c\u5728RouterBench\u57fa\u51c6\u4e0a\u5b9e\u73b06.6%\u7684AIQ\u63d0\u5347\u548c2.9%\u7684\u6700\u5927\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u8ba1\u7b97\u6210\u672c\u548c\u6027\u80fd\u5dee\u5f02\u7ed9\u5b9e\u9645\u90e8\u7f72\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u52a8\u6001\u8def\u7531\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5355\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u8054\u5408\u5efa\u6a21\u67e5\u8be2\u548c\u6a21\u578b\u5d4c\u5165\uff0c\u9884\u6d4b\u54cd\u5e94\u8d28\u91cf\u548c\u751f\u6210\u6210\u672c\uff0c\u5e76\u91c7\u7528\u6307\u6570\u5956\u52b1\u51fd\u6570\u5e73\u8861\u6027\u80fd\u4e0e\u6210\u672c\u3002", "result": "\u5728\u591a\u6837\u5316LLM\u6c60\u548c\u9886\u57df\u7684RouterBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u8def\u7531\u5668\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u67b6\u6784\u8f7b\u91cf\u4e14\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u5f3a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6210\u672c\u611f\u77e5\u7684LLM\u8def\u7531\u5efa\u7acb\u4e86\u65b0\u6807\u51c6\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u4f18\u5316\u5e73\u8861\u3002"}}
{"id": "2509.09917", "categories": ["cs.SE", "D.2.4"], "pdf": "https://arxiv.org/pdf/2509.09917", "abs": "https://arxiv.org/abs/2509.09917", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion", "comment": "22 pages, 2 figures, conference", "summary": "Automatically generating formal specifications from program code can greatly\nenhance the efficiency of program verification and enable end-to-end automation\nfrom requirements to reliable software. However, existing LLM-based approaches\noften struggle with programs that include complex loop structures, leading to\nirrelevant specifications. Moreover, the rigorous proof obligations and design\nconstraints imposed by verification tools can further result in incomplete and\nambiguous specifications. To address these challenges, we propose SLD-Spec, an\nLLM-assisted specification generation method tailored for programs with complex\nloop constructs. SLD-Spec introduces two novel phases into the traditional\nspecification generation framework: (1) A slicing phase, which decomposes each\nfunction into code fragments containing independent loop structures, thereby\nreducing the complexity of specification generation; and (2) A logical deletion\nphase, which applies LLM-based reasoning to filter out incorrect candidate\nspecifications--especially those not easily identified by verification\ntool--while retaining valid ones. Experimental results show that on the simple\ndataset, SLD-Spec successfully verifies five more programs than the\nstate-of-the-art AutoSpec and reduces runtime by 23.73%. To address the\nlimitations of existing research, we manually construct a dataset comprising\nfour categories of complex loop programs. On this dataset, SLD-Spec\nsignificantly improves the correctness, relevance, and completeness of\ngenerated specifications compared to baseline methods, enabling 95.1% of\nassertions and 90.91% of programs to pass verification. Ablation studies\nfurther reveal that logical deletion is critical for enhancing specification\ncorrectness and relevance, while program slicing contributes significantly to\nspecification completeness. Our code and data are publicly available.", "AI": {"tldr": "SLD-Spec\u662f\u4e00\u79cd\u9488\u5bf9\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u7684LLM\u8f85\u52a9\u89c4\u8303\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u548c\u903b\u8f91\u5220\u9664\u4e24\u4e2a\u65b0\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u89c4\u8303\u7684\u6b63\u786e\u6027\u3001\u76f8\u5173\u6027\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728\u5904\u7406\u5305\u542b\u590d\u6742\u5faa\u73af\u7ed3\u6784\u7684\u7a0b\u5e8f\u65f6\u5f80\u5f80\u4ea7\u751f\u4e0d\u76f8\u5173\u7684\u89c4\u8303\uff0c\u4e14\u9a8c\u8bc1\u5de5\u5177\u7684\u4e25\u683c\u8bc1\u660e\u4e49\u52a1\u548c\u8bbe\u8ba1\u7ea6\u675f\u4f1a\u5bfc\u81f4\u89c4\u8303\u4e0d\u5b8c\u6574\u548c\u6a21\u7cca\u3002", "method": "\u63d0\u51faSLD-Spec\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u9636\u6bb5\uff1a(1)\u5207\u7247\u9636\u6bb5\u5c06\u51fd\u6570\u5206\u89e3\u4e3a\u5305\u542b\u72ec\u7acb\u5faa\u73af\u7ed3\u6784\u7684\u4ee3\u7801\u7247\u6bb5\uff1b(2)\u903b\u8f91\u5220\u9664\u9636\u6bb5\u5e94\u7528LLM\u63a8\u7406\u8fc7\u6ee4\u9519\u8bef\u5019\u9009\u89c4\u8303\u3002", "result": "\u5728\u7b80\u5355\u6570\u636e\u96c6\u4e0a\u6bd4\u6700\u5148\u8fdb\u7684AutoSpec\u591a\u9a8c\u8bc15\u4e2a\u7a0b\u5e8f\uff0c\u8fd0\u884c\u65f6\u95f4\u51cf\u5c1123.73%\u3002\u5728\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u6570\u636e\u96c6\u4e0a\uff0c95.1%\u7684\u65ad\u8a00\u548c90.91%\u7684\u7a0b\u5e8f\u901a\u8fc7\u9a8c\u8bc1\u3002", "conclusion": "SLD-Spec\u901a\u8fc7\u7a0b\u5e8f\u5207\u7247\u548c\u903b\u8f91\u5220\u9664\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u5faa\u73af\u7a0b\u5e8f\u7684\u89c4\u8303\u751f\u6210\u95ee\u9898\uff0c\u903b\u8f91\u5220\u9664\u5bf9\u63d0\u5347\u89c4\u8303\u6b63\u786e\u6027\u548c\u76f8\u5173\u6027\u81f3\u5173\u91cd\u8981\uff0c\u7a0b\u5e8f\u5207\u7247\u5bf9\u89c4\u8303\u5b8c\u6574\u6027\u8d21\u732e\u663e\u8457\u3002"}}
{"id": "2509.09918", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09918", "abs": "https://arxiv.org/abs/2509.09918", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "WALL: A Web Application for Automated Quality Assurance using Large Language Models", "comment": null, "summary": "As software projects become increasingly complex, the volume and variety of\nissues in code files have grown substantially. Addressing this challenge\nrequires efficient issue detection, resolution, and evaluation tools. This\npaper presents WALL, a web application that integrates SonarQube and large\nlanguage models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these\ntasks. WALL comprises three modules: an issue extraction tool, code issues\nreviser, and code comparison tool. Together, they enable a seamless pipeline\nfor detecting software issues, generating automated code revisions, and\nevaluating the accuracy of revisions. Our experiments, conducted on 563 files\nwith over 7,599 issues, demonstrate WALL's effectiveness in reducing human\neffort while maintaining high-quality revisions. Results show that employing a\nhybrid approach of cost-effective and advanced LLMs can significantly lower\ncosts and improve revision rates. Future work aims to enhance WALL's\ncapabilities by integrating open-source LLMs and eliminating human\nintervention, paving the way for fully automated code quality management.", "AI": {"tldr": "WALL\u662f\u4e00\u4e2a\u96c6\u6210SonarQube\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684Web\u5e94\u7528\uff0c\u901a\u8fc7\u4e09\u4e2a\u6a21\u5757\u81ea\u52a8\u5316\u4ee3\u7801\u95ee\u9898\u68c0\u6d4b\u3001\u4fee\u590d\u548c\u8bc4\u4f30\uff0c\u5728563\u4e2a\u6587\u4ef67599\u4e2a\u95ee\u9898\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u4eba\u5de5\u6210\u672c\u5e76\u63d0\u9ad8\u4fee\u590d\u7387\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u9879\u76ee\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u4ee3\u7801\u95ee\u9898\u6570\u91cf\u548c\u79cd\u7c7b\u6025\u5267\u589e\u957f\uff0c\u9700\u8981\u9ad8\u6548\u7684\u95ee\u9898\u68c0\u6d4b\u3001\u4fee\u590d\u548c\u8bc4\u4f30\u5de5\u5177\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u5f00\u53d1WALL Web\u5e94\u7528\uff0c\u96c6\u6210SonarQube\u548cLLMs\uff08GPT-3.5 Turbo\u548cGPT-4o\uff09\uff0c\u5305\u542b\u95ee\u9898\u63d0\u53d6\u5de5\u5177\u3001\u4ee3\u7801\u95ee\u9898\u4fee\u8ba2\u5668\u548c\u4ee3\u7801\u6bd4\u8f83\u5de5\u5177\u4e09\u4e2a\u6a21\u5757\uff0c\u5f62\u6210\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u3002", "result": "\u5728563\u4e2a\u6587\u4ef67599\u4e2a\u95ee\u9898\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff0cWALL\u80fd\u6709\u6548\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u4fee\u8ba2\uff0c\u91c7\u7528\u6210\u672c\u6548\u76ca\u578b\u548c\u5148\u8fdbLLMs\u7684\u6df7\u5408\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u6210\u672c\u5e76\u63d0\u9ad8\u4fee\u8ba2\u7387\u3002", "conclusion": "WALL\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u4ee3\u7801\u8d28\u91cf\u7ba1\u7406\u7684\u53ef\u884c\u6027\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u6210\u5f00\u6e90LLMs\u5e76\u6d88\u9664\u4eba\u5de5\u5e72\u9884\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u4ee3\u7801\u8d28\u91cf\u7ba1\u7406\u3002"}}
{"id": "2509.09947", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09947", "abs": "https://arxiv.org/abs/2509.09947", "authors": ["Humza Ashraf", "Syed Muhammad Danish", "Zeeshan Sattar"], "title": "Toward Green Code: Prompting Small Language Models for Energy-Efficient Code Generation", "comment": null, "summary": "There is a growing concern about the environmental impact of large language\nmodels (LLMs) in software development, particularly due to their high energy\nuse and carbon footprint. Small Language Models (SLMs) offer a more sustainable\nalternative, requiring fewer computational resources while remaining effective\nfor fundamental programming tasks. In this study, we investigate whether prompt\nengineering can improve the energy efficiency of SLMs in code generation. We\nevaluate four open-source SLMs, StableCode-Instruct-3B,\nQwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct,\nacross 150 Python problems from LeetCode, evenly distributed into easy, medium,\nand hard categories. Each model is tested under four prompting strategies: role\nprompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated\nsolution, we measure runtime, memory usage, and energy consumption, comparing\nthe results with a human-written baseline. Our findings show that CoT prompting\nprovides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while\nCodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any\nprompting strategy. These results highlight that the benefits of prompting are\nmodel-dependent and that carefully designed prompts can guide SLMs toward\ngreener software development.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u7b56\u7565\uff08\u7279\u522b\u662f\u601d\u7ef4\u94fe\u63d0\u793a\uff09\u53ef\u4ee5\u63d0\u9ad8\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u80fd\u6e90\u6548\u7387\uff0c\u4f46\u6548\u679c\u56e0\u6a21\u578b\u800c\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9ad8\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\u95ee\u9898\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u66f4\u53ef\u6301\u7eed\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u63d0\u9ad8\u5176\u80fd\u6e90\u6548\u7387\u3002", "method": "\u8bc4\u4f304\u4e2a\u5f00\u6e90\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728150\u4e2aPython\u7f16\u7a0b\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u6d4b\u8bd54\u79cd\u63d0\u793a\u7b56\u7565\uff08\u89d2\u8272\u63d0\u793a\u3001\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u3001\u601d\u7ef4\u94fe\uff09\uff0c\u6d4b\u91cf\u8fd0\u884c\u65f6\u95f4\u3001\u5185\u5b58\u4f7f\u7528\u548c\u80fd\u8017\uff0c\u5e76\u4e0e\u4eba\u5de5\u7f16\u5199\u57fa\u51c6\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u601d\u7ef4\u94fe\u63d0\u793a\u4e3aQwen2.5-Coder\u548cStableCode-3B\u5e26\u6765\u4e00\u81f4\u7684\u8282\u80fd\u6548\u679c\uff0c\u800cCodeLlama-7B\u548cPhi-3-Mini-4K\u5728\u4efb\u4f55\u63d0\u793a\u7b56\u7565\u4e0b\u90fd\u65e0\u6cd5\u8d85\u8d8a\u57fa\u51c6\u3002", "conclusion": "\u63d0\u793a\u7b56\u7565\u7684\u6548\u76ca\u5177\u6709\u6a21\u578b\u4f9d\u8d56\u6027\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u53ef\u4ee5\u5f15\u5bfc\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u66f4\u73af\u4fdd\u7684\u8f6f\u4ef6\u5f00\u53d1\u3002"}}
{"id": "2509.09703", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09703", "abs": "https://arxiv.org/abs/2509.09703", "authors": ["Zhenhua Xu", "Xixiang Zhao", "Xubin Yue", "Shengwei Tian", "Changting Lin", "Meng Han"], "title": "CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor", "comment": "Accepted by EMNLP2025 MainConference", "summary": "The widespread deployment of large language models (LLMs) has intensified\nconcerns around intellectual property (IP) protection, as model theft and\nunauthorized redistribution become increasingly feasible. To address this,\nmodel fingerprinting aims to embed verifiable ownership traces into LLMs.\nHowever, existing methods face inherent trade-offs between stealthness,\nrobustness, and generalizability, being either detectable via distributional\nshifts, vulnerable to adversarial modifications, or easily invalidated once the\nfingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven\nfingerprinting framework that encodes contextual correlations across multiple\ndialogue turns, such as counterfactual, rather than relying on token-level or\nsingle-turn triggers. CTCC enables fingerprint verification under black-box\naccess while mitigating false positives and fingerprint leakage, supporting\ncontinuous construction under a shared semantic rule even if partial triggers\nare exposed. Extensive experiments across multiple LLM architectures\ndemonstrate that CTCC consistently achieves stronger stealth and robustness\nthan prior work. Our findings position CTCC as a reliable and practical\nsolution for ownership verification in real-world LLM deployment scenarios. Our\ncode and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.", "AI": {"tldr": "CTCC\u662f\u4e00\u4e2a\u57fa\u4e8e\u89c4\u5219\u9a71\u52a8\u7684LLM\u6307\u7eb9\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u7684\u4e0a\u4e0b\u6587\u5173\u8054\u7f16\u7801\u6765\u5b9e\u73b0\u6240\u6709\u6743\u9a8c\u8bc1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u9690\u853d\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u90e8\u7f72\u5f15\u53d1\u4e86\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u62c5\u5fe7\uff0c\u73b0\u6709\u6307\u7eb9\u65b9\u6cd5\u5b58\u5728\u53ef\u68c0\u6d4b\u6027\u3001\u6613\u53d7\u653b\u51fb\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u7b49\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u89c4\u5219\u9a71\u52a8\u7684\u6307\u7eb9\u6846\u67b6\uff0c\u7f16\u7801\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u5173\u8054\uff08\u5982\u53cd\u4e8b\u5b9e\u5173\u7cfb\uff09\uff0c\u800c\u975e\u4f9d\u8d56\u8bcd\u7ea7\u6216\u5355\u8f6e\u89e6\u53d1\u5668\uff0c\u652f\u6301\u9ed1\u76d2\u8bbf\u95ee\u4e0b\u7684\u6307\u7eb9\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u4e2aLLM\u67b6\u6784\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCTCC\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u5f3a\u7684\u9690\u853d\u6027\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u8bef\u62a5\u548c\u6307\u7eb9\u6cc4\u9732\u3002", "conclusion": "CTCC\u4e3a\u5b9e\u9645LLM\u90e8\u7f72\u573a\u666f\u4e2d\u7684\u6240\u6709\u6743\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u9760\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u5728\u90e8\u5206\u89e6\u53d1\u5668\u66b4\u9732\u60c5\u51b5\u4e0b\u7684\u6301\u7eed\u6784\u5efa\u3002"}}
{"id": "2509.09975", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09975", "abs": "https://arxiv.org/abs/2509.09975", "authors": ["Takasaburo Fukuda", "Takao Nakagawa", "Keisuke Miyazaki", "Susumu Tokumoto"], "title": "Development of Automated Software Design Document Review Methods Using Large Language Models", "comment": "SANER 2025", "summary": "In this study, we explored an approach to automate the review process of\nsoftware design documents by using LLM. We first analyzed the review methods of\ndesign documents and organized 11 review perspectives. Additionally, we\nanalyzed the issues of utilizing LLMs for these 11 review perspectives and\ndetermined which perspectives can be reviewed by current general-purpose LLMs\ninstead of humans. For the reviewable perspectives, we specifically developed\nnew techniques to enable LLMs to comprehend complex design documents that\ninclude table data. For evaluation, we conducted experiments using GPT to\nassess the consistency of design items and descriptions across different design\ndocuments in the design process used in actual business operations. Our results\nconfirmed that LLMs can be utilized to identify inconsistencies in software\ndesign documents during the review process.", "AI": {"tldr": "\u4f7f\u7528LLM\u81ea\u52a8\u5316\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u8fc7\u7a0b\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u5206\u679011\u4e2a\u8bc4\u5ba1\u89c6\u89d2\u5e76\u5f00\u53d1\u65b0\u6280\u672f\uff0c\u9a8c\u8bc1\u4e86LLM\u80fd\u591f\u8bc6\u522b\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898", "motivation": "\u63a2\u7d22\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u6765\u81ea\u52a8\u5316\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u7684\u8bc4\u5ba1\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u8bc4\u5ba1\u6548\u7387\u548c\u51c6\u786e\u6027", "method": "\u5206\u6790\u8bbe\u8ba1\u6587\u6863\u8bc4\u5ba1\u65b9\u6cd5\u5e76\u7ec4\u7ec711\u4e2a\u8bc4\u5ba1\u89c6\u89d2\uff0c\u9488\u5bf9\u53ef\u8bc4\u5ba1\u7684\u89c6\u89d2\u5f00\u53d1\u65b0\u6280\u672f\u4f7fLLM\u80fd\u591f\u7406\u89e3\u5305\u542b\u8868\u683c\u6570\u636e\u7684\u590d\u6742\u8bbe\u8ba1\u6587\u6863\uff0c\u4f7f\u7528GPT\u8bc4\u4f30\u5b9e\u9645\u4e1a\u52a1\u4e2d\u4e0d\u540c\u8bbe\u8ba1\u6587\u6863\u95f4\u8bbe\u8ba1\u9879\u548c\u63cf\u8ff0\u7684\u4e00\u81f4\u6027", "result": "\u5b9e\u9a8c\u8bc1\u5b9eLLM\u53ef\u4ee5\u5728\u8bc4\u5ba1\u8fc7\u7a0b\u4e2d\u8bc6\u522b\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898", "conclusion": "LLM\u80fd\u591f\u6709\u6548\u5e94\u7528\u4e8e\u8f6f\u4ef6\u8bbe\u8ba1\u6587\u6863\u7684\u81ea\u52a8\u5316\u8bc4\u5ba1\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u6587\u6863\u95f4\u4e00\u81f4\u6027\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2509.09848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09848", "abs": "https://arxiv.org/abs/2509.09848", "authors": ["Nana Han", "Dong Liu", "Tomas Norton"], "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly being recognised as valuable\nknowledge communication tools in many industries. However, their application in\nlivestock farming remains limited, being constrained by several factors not\nleast the availability, diversity and complexity of knowledge sources. This\nstudy introduces an intelligent knowledge assistant system designed to support\nhealth management in farmed goats. Leveraging the Retrieval-Augmented\nGeneration (RAG), two structured knowledge processing methods, table\ntextualization and decision-tree textualization, were proposed to enhance large\nlanguage models' (LLMs) understanding of heterogeneous data formats. Based on\nthese methods, a domain-specific goat farming knowledge base was established to\nimprove LLM's capacity for cross-scenario generalization. The knowledge base\nspans five key domains: Disease Prevention and Treatment, Nutrition Management,\nRearing Management, Goat Milk Management, and Basic Farming Knowledge.\nAdditionally, an online search module is integrated to enable real-time\nretrieval of up-to-date information. To evaluate system performance, six\nablation experiments were conducted to examine the contribution of each\ncomponent. The results demonstrated that heterogeneous knowledge fusion method\nachieved the best results, with mean accuracies of 87.90% on the validation set\nand 84.22% on the test set. Across the text-based, table-based, decision-tree\nbased Q&A tasks, accuracy consistently exceeded 85%, validating the\neffectiveness of structured knowledge fusion within a modular design. Error\nanalysis identified omission as the predominant error category, highlighting\nopportunities to further improve retrieval coverage and context integration. In\nconclusion, the results highlight the robustness and reliability of the\nproposed system for practical applications in goat farming.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eRAG\u7684\u667a\u80fd\u77e5\u8bc6\u52a9\u624b\u7cfb\u7edf\uff0c\u4e13\u95e8\u7528\u4e8e\u5c71\u7f8a\u517b\u6b96\u5065\u5eb7\u7ba1\u7406\uff0c\u901a\u8fc7\u8868\u683c\u6587\u672c\u5316\u548c\u51b3\u7b56\u6811\u6587\u672c\u5316\u65b9\u6cd5\u5904\u7406\u5f02\u6784\u77e5\u8bc6\uff0c\u5728\u9a8c\u8bc1\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u8fbe\u523087.90%\u548c84.22%\u7684\u5e73\u5747\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u755c\u7267\u4e1a\u5e94\u7528\u6709\u9650\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u77e5\u8bc6\u6e90\u7684\u53ef\u7528\u6027\u3001\u591a\u6837\u6027\u548c\u590d\u6742\u6027\uff0c\u9700\u8981\u4e13\u95e8\u7684\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5bf9\u5f02\u6784\u6570\u636e\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6280\u672f\uff0c\u63d0\u51fa\u8868\u683c\u6587\u672c\u5316\u548c\u51b3\u7b56\u6811\u6587\u672c\u5316\u4e24\u79cd\u7ed3\u6784\u5316\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\uff0c\u5efa\u7acb\u8986\u76d6\u75be\u75c5\u9632\u6cbb\u3001\u8425\u517b\u7ba1\u7406\u3001\u9972\u517b\u7ba1\u7406\u7b49\u4e94\u4e2a\u5173\u952e\u9886\u57df\u7684\u5c71\u7f8a\u517b\u6b96\u77e5\u8bc6\u5e93\uff0c\u5e76\u96c6\u6210\u5728\u7ebf\u641c\u7d22\u6a21\u5757\u5b9e\u73b0\u5b9e\u65f6\u4fe1\u606f\u68c0\u7d22\u3002", "result": "\u5f02\u6784\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u53d6\u5f97\u6700\u4f73\u6548\u679c\uff0c\u9a8c\u8bc1\u96c6\u5e73\u5747\u51c6\u786e\u738787.90%\uff0c\u6d4b\u8bd5\u96c684.22%\u3002\u5728\u6587\u672c\u3001\u8868\u683c\u3001\u51b3\u7b56\u6811\u4e09\u7c7b\u95ee\u7b54\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u5747\u8d85\u8fc785%\uff0c\u8bc1\u660e\u4e86\u6a21\u5757\u5316\u8bbe\u8ba1\u4e2d\u7ed3\u6784\u5316\u77e5\u8bc6\u878d\u5408\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5728\u5c71\u7f8a\u517b\u6b96\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u6027\u548c\u53ef\u9760\u6027\uff0c\u9519\u8bef\u5206\u6790\u663e\u793a\u9057\u6f0f\u662f\u4e3b\u8981\u9519\u8bef\u7c7b\u578b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u63d0\u5347\u68c0\u7d22\u8986\u76d6\u7387\u548c\u4e0a\u4e0b\u6587\u6574\u5408\u63d0\u4f9b\u4e86\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2509.09867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09867", "abs": "https://arxiv.org/abs/2509.09867", "authors": ["Yago Romano Matinez", "Jesse Roberts"], "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "comment": null, "summary": "LLMs promise to assist humans -- not just by answering questions, but by\noffering useful guidance across a wide range of tasks. But how far does that\nassistance go? Can a large language model based agent actually help someone\naccomplish their goal as an active participant? We test this question by\nengaging an LLM in UNO, a turn-based card game, asking it not to win but\ninstead help another player to do so. We built a tool that allows decoder-only\nLLMs to participate as agents within the RLCard game environment. These models\nreceive full game-state information and respond using simple text prompts under\ntwo distinct prompting strategies. We evaluate models ranging from small (1B\nparameters) to large (70B parameters) and explore how model scale impacts\nperformance. We find that while all models were able to successfully outperform\na random baseline when playing UNO, few were able to significantly aid another\nplayer.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5LLM\u5728UNO\u6e38\u620f\u4e2d\u4f5c\u4e3a\u52a9\u624b\u5e2e\u52a9\u5176\u4ed6\u73a9\u5bb6\u83b7\u80dc\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u867d\u7136\u6240\u6709\u6a21\u578b\u90fd\u80fd\u8d85\u8d8a\u968f\u673a\u57fa\u51c6\uff0c\u4f46\u53ea\u6709\u5c11\u6570\u80fd\u663e\u8457\u5e2e\u52a9\u5176\u4ed6\u73a9\u5bb6", "motivation": "\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u4f5c\u4e3a\u4e3b\u52a8\u53c2\u4e0e\u8005\u771f\u6b63\u5e2e\u52a9\u4eba\u7c7b\u5b8c\u6210\u76ee\u6807\uff0c\u7279\u522b\u662f\u5728\u534f\u4f5c\u6e38\u620f\u573a\u666f\u4e2d\u7684\u8868\u73b0", "method": "\u6784\u5efa\u5de5\u5177\u8ba9\u4ec5\u89e3\u7801\u5668LLM\u5728RLCard\u6e38\u620f\u73af\u5883\u4e2d\u4f5c\u4e3a\u4ee3\u7406\u53c2\u4e0eUNO\u6e38\u620f\uff0c\u63a5\u6536\u5b8c\u6574\u6e38\u620f\u72b6\u6001\u4fe1\u606f\uff0c\u4f7f\u7528\u4e24\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u7b56\u7565\uff0c\u8bc4\u4f30\u4ece1B\u523070B\u53c2\u6570\u7684\u4e0d\u540c\u89c4\u6a21\u6a21\u578b", "result": "\u6240\u6709\u6a21\u578b\u5728\u73a9UNO\u65f6\u90fd\u80fd\u6210\u529f\u8d85\u8d8a\u968f\u673a\u57fa\u51c6\uff0c\u4f46\u53ea\u6709\u5c11\u6570\u6a21\u578b\u80fd\u591f\u663e\u8457\u5e2e\u52a9\u5176\u4ed6\u73a9\u5bb6\u83b7\u80dc", "conclusion": "\u867d\u7136LLM\u5728\u5355\u72ec\u73a9\u6e38\u620f\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u534f\u4f5c\u5e2e\u52a9\u4ed6\u4eba\u65b9\u9762\u7684\u80fd\u529b\u4ecd\u7136\u6709\u9650\uff0c\u6a21\u578b\u89c4\u6a21\u5bf9\u6027\u80fd\u6709\u5f71\u54cd\u4f46\u5e76\u975e\u51b3\u5b9a\u6027\u56e0\u7d20"}}
{"id": "2509.09864", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09864", "abs": "https://arxiv.org/abs/2509.09864", "authors": ["Jenny Y. Huang", "Mehul Damani", "Yousef El-Kurdi", "Ramon Astudillo", "Wei Sun"], "title": "Latency and Token-Aware Test-Time Compute", "comment": null, "summary": "Inference-time scaling has emerged as a powerful way to improve large\nlanguage model (LLM) performance by generating multiple candidate responses and\nselecting among them. However, existing work on dynamic allocation for\ntest-time compute typically considers only parallel generation methods such as\nbest-of-N, overlooking incremental decoding methods like beam search, and has\nlargely ignored latency, focusing only on token usage. We formulate\ninference-time scaling as a problem of dynamic compute allocation and method\nselection, where the system must decide which strategy to apply and how much\ncompute to allocate on a per-query basis. Our framework explicitly incorporates\nboth token cost and wall-clock latency, the latter being critical for user\nexperience and particularly for agentic workflows where models must issue\nmultiple queries efficiently. Experiments on reasoning benchmarks show that our\napproach consistently outperforms static strategies, achieving favorable\naccuracy-cost trade-offs while remaining practical for deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u6839\u636e\u67e5\u8be2\u9700\u6c42\u9009\u62e9\u6700\u4f73\u751f\u6210\u7b56\u7565\uff08\u5982beam search\u6216best-of-N\uff09\uff0c\u540c\u65f6\u8003\u8651token\u6210\u672c\u548c\u5ef6\u8fdf\u65f6\u95f4\uff0c\u4ee5\u4f18\u5316LLM\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u65f6\u6269\u5c55\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5e76\u884c\u751f\u6210\u548ctoken\u4f7f\u7528\uff0c\u5ffd\u7565\u4e86\u589e\u91cf\u89e3\u7801\u65b9\u6cd5\u548c\u5ef6\u8fdf\u65f6\u95f4\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u9ad8\u6548\u591a\u67e5\u8be2\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4e2d\u3002", "method": "\u5efa\u7acb\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u548c\u65b9\u6cd5\u9009\u62e9\u6846\u67b6\uff0c\u5728\u6bcf\u67e5\u8be2\u57fa\u7840\u4e0a\u51b3\u5b9a\u5e94\u7528\u54ea\u79cd\u7b56\u7565\u548c\u5206\u914d\u591a\u5c11\u8ba1\u7b97\u8d44\u6e90\uff0c\u540c\u65f6\u663e\u5f0f\u8003\u8651token\u6210\u672c\u548cwall-clock\u5ef6\u8fdf\u3002", "result": "\u5728\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6301\u7eed\u4f18\u4e8e\u9759\u6001\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u51c6\u786e\u7387-\u6210\u672c\u6743\u8861\uff0c\u4e14\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002", "conclusion": "\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e73\u8861LLM\u6027\u80fd\u548c\u8d44\u6e90\u6d88\u8017\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5bf9\u5ef6\u8fdf\u654f\u611f\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2509.10099", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10099", "abs": "https://arxiv.org/abs/2509.10099", "authors": ["Radu Apsan", "Vincenzo Stoico", "Michel Albonico", "Rudra Dhar", "Karthik Vaidhyanathan", "Ivano Malavolta"], "title": "Generating Energy-Efficient Code via Large-Language Models -- Where are we now?", "comment": null, "summary": "Context. The rise of Large Language Models (LLMs) has led to their widespread\nadoption in development pipelines. Goal. We empirically assess the energy\nefficiency of Python code generated by LLMs against human-written code and code\ndeveloped by a Green software expert. Method. We test 363 solutions to 9 coding\nproblems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting\ntechniques, and comparing them to human-developed solutions. Energy consumption\nis measured on three different hardware platforms: a server, a PC, and a\nRaspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%\nmore energy-efficient on the server and 3% on the Raspberry Pi, while LLMs\noutperform human developers by 25% on the PC. Prompting does not consistently\nlead to energy savings, where the most energy-efficient prompts vary by\nhardware platform. The code developed by a Green software expert is\nconsistently more energy-efficient by at least 17% to 30% against all LLMs on\nall hardware platforms. Conclusions. Even though LLMs exhibit relatively good\ncode generation capabilities, no LLM-generated code was more energy-efficient\nthan that of an experienced Green software developer, suggesting that as of\ntoday there is still a great need of human expertise for developing\nenergy-efficient Python code.", "AI": {"tldr": "LLM\u751f\u6210\u7684Python\u4ee3\u7801\u5728\u80fd\u6e90\u6548\u7387\u4e0a\u8868\u73b0\u4e0d\u4e00\uff0c\u4eba\u7c7b\u4ee3\u7801\u5728\u670d\u52a1\u5668\u4e0a\u66f4\u9ad8\u654816%\uff0c\u6811\u8393\u6d3e\u4e0a\u9ad83%\uff0c\u4f46\u5728PC\u4e0aLLM\u4ee3\u7801\u6bd4\u4eba\u7c7b\u4ee3\u7801\u9ad8\u654825%\u3002\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u7f16\u5199\u7684\u4ee3\u7801\u5728\u6240\u6709\u5e73\u53f0\u4e0a\u90fd\u6bd4\u6240\u6709LLM\u4ee3\u7801\u9ad8\u654817-30%\u3002", "motivation": "\u8bc4\u4f30LLM\u751f\u6210\u7684Python\u4ee3\u7801\u4e0e\u4eba\u7c7b\u7f16\u5199\u4ee3\u7801\u5728\u80fd\u6e90\u6548\u7387\u65b9\u9762\u7684\u5bf9\u6bd4\uff0c\u7279\u522b\u662f\u5728\u7eff\u8272\u8f6f\u4ef6\u5f00\u53d1\u80cc\u666f\u4e0b\u3002", "method": "\u4f7f\u7528EvoEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76849\u4e2a\u7f16\u7a0b\u95ee\u9898\u7684363\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u6d4b\u8bd56\u4e2a\u4e3b\u6d41LLM\u548c4\u79cd\u63d0\u793a\u6280\u672f\uff0c\u5e76\u4e0e\u4eba\u7c7b\u5f00\u53d1\u7684\u89e3\u51b3\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\uff0c\u5728\u4e09\u79cd\u786c\u4ef6\u5e73\u53f0\u4e0a\u6d4b\u91cf\u80fd\u6e90\u6d88\u8017\uff08\u603b\u8ba1\u7ea6881\u5c0f\u65f6\uff09\u3002", "result": "\u4eba\u7c7b\u89e3\u51b3\u65b9\u6848\u5728\u670d\u52a1\u5668\u4e0a\u8282\u80fd16%\uff0c\u6811\u8393\u6d3e\u4e0a\u8282\u80fd3%\uff1bLLM\u5728PC\u4e0a\u6bd4\u4eba\u7c7b\u5f00\u53d1\u8005\u8282\u80fd25%\u3002\u63d0\u793a\u6280\u672f\u4e0d\u80fd\u6301\u7eed\u5e26\u6765\u8282\u80fd\u6548\u679c\uff0c\u6700\u8282\u80fd\u7684\u63d0\u793a\u56e0\u786c\u4ef6\u5e73\u53f0\u800c\u5f02\u3002\u7eff\u8272\u8f6f\u4ef6\u4e13\u5bb6\u7684\u4ee3\u7801\u5728\u6240\u6709\u786c\u4ef6\u5e73\u53f0\u4e0a\u90fd\u6bd4\u6240\u6709LLM\u4ee3\u7801\u8282\u80fd\u81f3\u5c1117-30%\u3002", "conclusion": "\u5c3d\u7ba1LLM\u5c55\u73b0\u51fa\u76f8\u5bf9\u826f\u597d\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4f46\u6ca1\u6709LLM\u751f\u6210\u7684\u4ee3\u7801\u6bd4\u7ecf\u9a8c\u4e30\u5bcc\u7684\u7eff\u8272\u8f6f\u4ef6\u5f00\u53d1\u4eba\u5458\u7f16\u5199\u7684\u4ee3\u7801\u66f4\u8282\u80fd\uff0c\u8868\u660e\u76ee\u524d\u5f00\u53d1\u8282\u80fdPython\u4ee3\u7801\u4ecd\u9700\u8981\u5927\u91cf\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002"}}
{"id": "2509.10236", "categories": ["cs.SE", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2509.10236", "abs": "https://arxiv.org/abs/2509.10236", "authors": ["Mingyi Li", "Junmin Xiao", "Siyan Chen", "Hui Ma", "Xi Chen", "Peihua Bao", "Liang Yuan", "Guangming Tan"], "title": "Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes", "comment": "33 pages, 12 figures. Submitted to OOPSLA2'25", "summary": "We introduce Stencil-Lifting, a novel system for automatically converting\nstencil kernels written in low-level languages in legacy code into semantically\nequivalent Domain-Specific Language (DSL) implementations. Targeting the\nefficiency bottlenecks of existing verified lifting systems, Stencil-Lifting\nachieves scalable stencil kernel abstraction through two key innovations.\nFirst, we propose a hierarchical recursive lifting theory that represents\nstencil kernels, structured as nested loops, using invariant subgraphs, which\nare customized data dependency graphs that capture loop-carried computation and\nstructural invariants. Each vertex in the invariant subgraph is associated with\na predicate-based summary, encoding its computational semantics. By enforcing\nself-consistency across these summaries, Stencil-Lifting ensures the derivation\nof correct loop invariants and postconditions for nested loops, eliminating the\nneed for external verification. Second, we develop a hierarchical recursive\nlifting algorithm that guarantees termination through a convergent recursive\nprocess, avoiding the inefficiencies of search-based synthesis. The algorithm\nefficiently derives the valid summaries of stencil kernels, and its\ncompleteness is formally proven. We evaluate Stencil-Lifting on diverse stencil\nbenchmarks from two different suites and on four real-world applications.\nExperimental results demonstrate that Stencil-Lifting achieves 31.62$\\times$\nand 5.8$\\times$ speedups compared to the state-of-the-art verified lifting\nsystems STNG and Dexter, respectively, while maintaining full semantic\nequivalence. Our work significantly enhances the translation efficiency of\nlow-level stencil kernels to DSL implementations, effectively bridging the gap\nbetween legacy optimization techniques and modern DSL-based paradigms.", "AI": {"tldr": "Stencil-Lifting\u662f\u4e00\u4e2a\u81ea\u52a8\u5c06\u4f4e\u7ea7\u8bed\u8a00\u7f16\u5199\u7684\u6a21\u677f\u5185\u6838\u8f6c\u6362\u4e3a\u7b49\u6548DSL\u5b9e\u73b0\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7406\u8bba\u548c\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8f6c\u6362\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u901f\u5ea6\u63d0\u534731.62\u500d\u548c5.8\u500d\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u9a8c\u8bc1\u63d0\u5347\u7cfb\u7edf\u5728\u6a21\u677f\u5185\u6838\u62bd\u8c61\u65b9\u9762\u7684\u6548\u7387\u74f6\u9888\uff0c\u5f25\u5408\u4f20\u7edf\u4f18\u5316\u6280\u672f\u4e0e\u73b0\u4ee3DSL\u8303\u5f0f\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7406\u8bba\uff0c\u4f7f\u7528\u4e0d\u53d8\u5b50\u56fe\u8868\u793a\u6a21\u677f\u5185\u6838\uff0c\u6bcf\u4e2a\u9876\u70b9\u5173\u8054\u57fa\u4e8e\u8c13\u8bcd\u7684\u6458\u8981\uff1b\u5f00\u53d1\u5206\u5c42\u9012\u5f52\u63d0\u5347\u7b97\u6cd5\uff0c\u901a\u8fc7\u6536\u655b\u9012\u5f52\u8fc7\u7a0b\u4fdd\u8bc1\u7ec8\u6b62\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u4e0d\u540c\u6d4b\u8bd5\u5957\u4ef6\u7684\u591a\u6837\u5316\u6a21\u677f\u57fa\u51c6\u548c\u56db\u4e2a\u5b9e\u9645\u5e94\u7528\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684STNG\u548cDexter\u7cfb\u7edf\u5206\u522b\u5b9e\u73b031.62\u500d\u548c5.8\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "Stencil-Lifting\u663e\u8457\u63d0\u9ad8\u4e86\u4f4e\u7ea7\u6a21\u677f\u5185\u6838\u5230DSL\u5b9e\u73b0\u7684\u8f6c\u6362\u6548\u7387\uff0c\u6709\u6548\u8fde\u63a5\u4e86\u4f20\u7edf\u4f18\u5316\u6280\u672f\u548c\u73b0\u4ee3DSL\u8303\u5f0f\u3002"}}
{"id": "2509.10279", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10279", "abs": "https://arxiv.org/abs/2509.10279", "authors": ["Pavel Plyusnin", "Aleksey Antonov", "Vasilii Ermakov", "Aleksandr Khaybriev", "Margarita Kikot", "Ilseyar Alimova", "Stanislav Moiseev"], "title": "Targeted Test Selection Approach in Continuous Integration", "comment": "Accepted at ICSME 2025", "summary": "In modern software development change-based testing plays a crucial role.\nHowever, as codebases expand and test suites grow, efficiently managing the\ntesting process becomes increasingly challenging, especially given the high\nfrequency of daily code commits. We propose Targeted Test Selection (T-TS), a\nmachine learning approach for industrial test selection. Our key innovation is\na data representation that represent commits as Bags-of-Words of changed files,\nincorporates cross-file and additional predictive features, and notably avoids\nthe use of coverage maps. Deployed in production, T-TS was comprehensively\nevaluated against industry standards and recent methods using both internal and\npublic datasets, measuring time efficiency and fault detection. On live\nindustrial data, T-TS selects only 15% of tests, reduces execution time by\n$5.9\\times$, accelerates the pipeline by $5.6\\times$, and detects over 95% of\ntest failures. The implementation is publicly available to support further\nresearch and practical adoption.", "AI": {"tldr": "T-TS\u662f\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5de5\u4e1a\u6d4b\u8bd5\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bcd\u888b\u8868\u793a\u63d0\u4ea4\u6587\u4ef6\u53d8\u5316\uff0c\u65e0\u9700\u8986\u76d6\u7387\u6620\u5c04\uff0c\u80fd\u9009\u62e915%\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u51cf\u5c115.9\u500d\u6267\u884c\u65f6\u95f4\uff0c\u68c0\u6d4b95%\u4ee5\u4e0a\u7684\u6d4b\u8bd5\u5931\u8d25\u3002", "motivation": "\u968f\u7740\u4ee3\u7801\u5e93\u6269\u5c55\u548c\u6d4b\u8bd5\u5957\u4ef6\u589e\u957f\uff0c\u9ad8\u9891\u4ee3\u7801\u63d0\u4ea4\u4f7f\u5f97\u6d4b\u8bd5\u8fc7\u7a0b\u7ba1\u7406\u53d8\u5f97\u56f0\u96be\uff0c\u9700\u8981\u9ad8\u6548\u7684\u6d4b\u8bd5\u9009\u62e9\u65b9\u6cd5\u6765\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u3002", "method": "\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5c06\u63d0\u4ea4\u8868\u793a\u4e3a\u53d8\u66f4\u6587\u4ef6\u7684\u8bcd\u888b\uff0c\u878d\u5165\u8de8\u6587\u4ef6\u548c\u989d\u5916\u9884\u6d4b\u7279\u5f81\uff0c\u907f\u514d\u4f7f\u7528\u8986\u76d6\u7387\u6620\u5c04\u3002", "result": "\u5728\u751f\u4ea7\u73af\u5883\u4e2d\uff0cT-TS\u4ec5\u9009\u62e915%\u7684\u6d4b\u8bd5\uff0c\u51cf\u5c115.9\u500d\u6267\u884c\u65f6\u95f4\uff0c\u52a0\u901f\u6d41\u6c34\u7ebf5.6\u500d\uff0c\u68c0\u6d4b\u8d85\u8fc795%\u7684\u6d4b\u8bd5\u5931\u8d25\u3002", "conclusion": "T-TS\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5de5\u4e1a\u6d4b\u8bd5\u9009\u62e9\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\uff0c\u5b9e\u73b0\u5df2\u516c\u5f00\u4ee5\u652f\u6301\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2509.09710", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09710", "abs": "https://arxiv.org/abs/2509.09710", "authors": ["Sepehr Golrokh Amin", "Devin Rhoads", "Fatemeh Fakhrmoosavi", "Nicholas E. Lownes", "John N. Ivan"], "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data", "comment": null, "summary": "This study introduces a Large Language Model (LLM) scheme for generating\nindividual travel diaries in agent-based transportation models. While\ntraditional approaches rely on large quantities of proprietary household travel\nsurveys, the method presented in this study generates personas stochastically\nfrom open-source American Community Survey (ACS) and Smart Location Database\n(SLD) data, then synthesizes diaries through direct prompting. This study\nfeatures a novel one-to-cohort realism score: a composite of four metrics (Trip\nCount Score, Interval Score, Purpose Score, and Mode Score) validated against\nthe Connecticut Statewide Transportation Study (CSTS) diaries, matched across\ndemographic variables. The validation utilizes Jensen-Shannon Divergence to\nmeasure distributional similarities between generated and real diaries. When\ncompared to diaries generated with classical methods (Negative Binomial for\ntrip generation; Multinomial Logit for mode/purpose) calibrated on the\nvalidation set, LLM-generated diaries achieve comparable overall realism (LLM\nmean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and\ndemonstrates greater consistency (narrower realism score distribution), while\nclassical models lead in numerical estimates of trip count and activity\nduration. Aggregate validation confirms the LLM's statistical\nrepresentativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot\nviability and establishing a quantifiable metric of diary realism for future\nsynthetic diary evaluation systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u57fa\u4e8e\u4ee3\u7406\u7684\u4ea4\u901a\u6a21\u578b\u4e2d\u4e2a\u4f53\u51fa\u884c\u65e5\u8bb0\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u5f00\u6e90\u6570\u636e\u751f\u6210\u865a\u62df\u4eba\u7269\u5e76\u5408\u6210\u65e5\u8bb0\uff0c\u9a8c\u8bc1\u663e\u793aLLM\u5728\u51fa\u884c\u76ee\u7684\u786e\u5b9a\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u6574\u4f53\u771f\u5b9e\u6027\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u4e13\u6709\u5bb6\u5ead\u51fa\u884c\u8c03\u67e5\u6570\u636e\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u6570\u636e\u83b7\u53d6\u56f0\u96be\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u5f00\u6e90\u6570\u636e\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u751f\u6210\u4e2a\u4f53\u51fa\u884c\u65e5\u8bb0\u3002", "method": "\u4f7f\u7528\u7f8e\u56fd\u793e\u533a\u8c03\u67e5\u548c\u667a\u80fd\u4f4d\u7f6e\u6570\u636e\u5e93\u7684\u5f00\u6e90\u6570\u636e\u968f\u673a\u751f\u6210\u865a\u62df\u4eba\u7269\uff0c\u901a\u8fc7\u76f4\u63a5\u63d0\u793a\u65b9\u5f0f\u5408\u6210\u51fa\u884c\u65e5\u8bb0\uff0c\u5e76\u91c7\u7528\u5305\u542b\u56db\u4e2a\u6307\u6807\uff08\u51fa\u884c\u6b21\u6570\u3001\u65f6\u95f4\u95f4\u9694\u3001\u51fa\u884c\u76ee\u7684\u3001\u4ea4\u901a\u65b9\u5f0f\uff09\u7684\u7efc\u5408\u771f\u5b9e\u5ea6\u8bc4\u5206\u4f53\u7cfb\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "LLM\u751f\u6210\u7684\u65e5\u8bb0\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u8d1f\u4e8c\u9879\u5f0f\u51fa\u884c\u751f\u6210+\u591a\u9879\u5f0fLogit\u6a21\u5f0f/\u76ee\u7684\u9009\u62e9\uff09\u76f8\u6bd4\u5177\u6709\u76f8\u5f53\u7684\u6574\u4f53\u771f\u5b9e\u5ea6\uff08LLM\u5747\u503c\uff1a0.485 vs 0.455\uff09\uff0c\u5728\u51fa\u884c\u76ee\u7684\u786e\u5b9a\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u4e00\u81f4\u6027\u66f4\u597d\u3002", "conclusion": "LLM\u5728\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u5177\u6709\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765\u5408\u6210\u51fa\u884c\u65e5\u8bb0\u8bc4\u4f30\u7cfb\u7edf\u5efa\u7acb\u4e86\u53ef\u91cf\u5316\u7684\u771f\u5b9e\u5ea6\u5ea6\u91cf\u6807\u51c6\uff0c\u5c55\u793a\u4e86\u5728\u4ea4\u901a\u5efa\u6a21\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2509.10402", "categories": ["cs.SE", "D.2.0; D.2.7"], "pdf": "https://arxiv.org/pdf/2509.10402", "abs": "https://arxiv.org/abs/2509.10402", "authors": ["Suzhen Zhong", "Ying Zou", "Bram Adams"], "title": "Developer-LLM Conversations: An Empirical Study of Interactions and Generated Code Quality", "comment": null, "summary": "Large Language Models (LLMs) are becoming integral to modern software\ndevelopment workflows, assisting developers with code generation, API\nexplanation, and iterative problem-solving through natural language\nconversations. Despite widespread adoption, there is limited understanding of\nhow developers interact with LLMs in practice and how these conversational\ndynamics influence task outcomes, code quality, and software engineering\nworkflows. To address this, we leverage CodeChat, a large dataset comprising\n82,845 real-world developer-LLM conversations, containing 368,506 code snippets\ngenerated across over 20 programming languages, derived from the WildChat\ndataset. We find that LLM responses are substantially longer than developer\nprompts, with a median token-length ratio of 14:1. Multi-turn conversations\naccount for 68% of the dataset and often evolve due to shifting requirements,\nincomplete prompts, or clarification requests. Topic analysis identifies web\ndesign (9.6% of conversations) and neural network training (8.7% of\nconversations) as the most frequent LLM-assisted tasks. Evaluation across five\nlanguages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and\nlanguage-specific issues in LLM-generated code: generated Python and JavaScript\ncode often include undefined variables (83.4% and 75.3% of code snippets,\nrespectively); Java code lacks required comments (75.9%); C++ code frequently\nomits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a\nconversation, syntax and import errors persist across turns; however,\ndocumentation quality in Java improves by up to 14.7%, and import handling in\nPython improves by 3.7% over 5 turns. Prompts that point out mistakes in code\ngenerated in prior turns and explicitly request a fix are most effective for\nresolving errors.", "AI": {"tldr": "\u57fa\u4e8e82,845\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005-LLM\u5bf9\u8bdd\u7684\u5206\u6790\u663e\u793a\uff0cLLM\u54cd\u5e94\u6bd4\u5f00\u53d1\u8005\u63d0\u793a\u957f14\u500d\uff0c68%\u4e3a\u591a\u8f6e\u5bf9\u8bdd\uff0c\u4ee3\u7801\u751f\u6210\u5b58\u5728\u8bed\u8a00\u7279\u5b9a\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u4f46\u901a\u8fc7\u6307\u51fa\u9519\u8bef\u5e76\u660e\u786e\u8981\u6c42\u4fee\u590d\u7684\u63d0\u793a\u80fd\u6709\u6548\u6539\u8fdb\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5f00\u53d1\u8005\u5b9e\u9645\u4ea4\u4e92\u65b9\u5f0f\u3001\u5bf9\u8bdd\u52a8\u6001\u5982\u4f55\u5f71\u54cd\u4efb\u52a1\u7ed3\u679c\u548c\u4ee3\u7801\u8d28\u91cf\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u5229\u7528CodeChat\u6570\u636e\u96c6\uff08\u5305\u542b82,845\u4e2a\u771f\u5b9e\u5f00\u53d1\u8005-LLM\u5bf9\u8bdd\uff0c368,506\u4e2a\u4ee3\u7801\u7247\u6bb5\uff0c\u8986\u76d620+\u7f16\u7a0b\u8bed\u8a00\uff09\uff0c\u8fdb\u884c\u5bf9\u8bdd\u957f\u5ea6\u3001\u8f6e\u6b21\u3001\u4e3b\u9898\u5206\u6790\u548c\u4e94\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "LLM\u54cd\u5e94\u957f\u5ea6\u4e2d\u4f4d\u6570\u662f\u63d0\u793a\u768414\u500d\uff1b68%\u4e3a\u591a\u8f6e\u5bf9\u8bdd\uff1bPython\u548cJavaScript\u4ee3\u7801\u5e38\u542b\u672a\u5b9a\u4e49\u53d8\u91cf(83.4%/75.3%)\uff1bJava\u4ee3\u7801\u7f3a\u5c11\u6ce8\u91ca(75.9%)\uff1bC++\u5e38\u7701\u7565\u5934\u6587\u4ef6(41.1%)\uff1bC#\u5b58\u5728\u672a\u89e3\u6790\u547d\u540d\u7a7a\u95f4(49.2%)\u3002\u6307\u51fa\u9519\u8bef\u5e76\u8981\u6c42\u4fee\u590d\u7684\u63d0\u793a\u6700\u6709\u6548\u3002", "conclusion": "\u5f00\u53d1\u8005\u4e0eLLM\u7684\u5bf9\u8bdd\u5177\u6709\u590d\u6742\u52a8\u6001\u7279\u6027\uff0c\u4ee3\u7801\u8d28\u91cf\u95ee\u9898\u5177\u6709\u8bed\u8a00\u7279\u5f02\u6027\uff0c\u4f46\u901a\u8fc7\u8fed\u4ee3\u5bf9\u8bdd\u548c\u9488\u5bf9\u6027\u63d0\u793a\u53ef\u4ee5\u663e\u8457\u6539\u5584\u4ee3\u7801\u8d28\u91cf\uff0c\u4e3a\u4f18\u5316LLM\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2509.09711", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09711", "abs": "https://arxiv.org/abs/2509.09711", "authors": ["Aya E. Fouda", "Abdelrahamn A. Hassan", "Radwa J. Hanafy", "Mohammed E. Fouda"], "title": "Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry", "comment": null, "summary": "Large language models (LLMs) hold great promise in enhancing psychiatric\npractice, from improving diagnostic accuracy to streamlining clinical\ndocumentation and therapeutic support. However, existing evaluation resources\nheavily rely on small clinical interview corpora, social media posts, or\nsynthetic dialogues, which limits their clinical validity and fails to capture\nthe full complexity of psychiatric reasoning. In this work, we introduce\nPsychiatryBench, a rigorously curated benchmark grounded exclusively in\nauthoritative, expert-validated psychiatric textbooks and casebooks.\nPsychiatryBench comprises eleven distinct question-answering tasks ranging from\ndiagnostic reasoning and treatment planning to longitudinal follow-up,\nmanagement planning, clinical approach, sequential case analysis, and\nmultiple-choice/extended matching formats totaling over 5,300 expert-annotated\nitems. We evaluate a diverse set of frontier LLMs (including Google Gemini,\nDeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models\n(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an\n\"LLM-as-judge\" similarity scoring framework. Our results reveal substantial\ngaps in clinical consistency and safety, particularly in multi-turn follow-up\nand management tasks, underscoring the need for specialized model tuning and\nmore robust evaluation paradigms. PsychiatryBench offers a modular, extensible\nplatform for benchmarking and improving LLM performance in high-stakes mental\nhealth applications.", "AI": {"tldr": "PsychiatryBench\u662f\u4e00\u4e2a\u57fa\u4e8e\u6743\u5a01\u7cbe\u795e\u75c5\u5b66\u6559\u79d1\u4e66\u548c\u6848\u4f8b\u96c6\u7684\u4e13\u4e1a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b11\u4e2a\u95ee\u7b54\u4efb\u52a1\u548c5300\u591a\u4e2a\u4e13\u5bb6\u6807\u6ce8\u9879\u76ee\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7cbe\u795e\u75c5\u5b66\u5b9e\u8df5\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u8d44\u6e90\u4e3b\u8981\u4f9d\u8d56\u5c0f\u578b\u4e34\u5e8a\u8bbf\u8c08\u8bed\u6599\u5e93\u3001\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u6216\u5408\u6210\u5bf9\u8bdd\uff0c\u4e34\u5e8a\u6709\u6548\u6027\u6709\u9650\uff0c\u65e0\u6cd5\u6355\u6349\u7cbe\u795e\u75c5\u5b66\u63a8\u7406\u7684\u590d\u6742\u6027\uff0c\u9700\u8981\u66f4\u4e13\u4e1a\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u57fa\u4e8e\u4e13\u5bb6\u9a8c\u8bc1\u7684\u7cbe\u795e\u75c5\u5b66\u6559\u79d1\u4e66\u548c\u6848\u4f8b\u96c6\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u8bca\u65ad\u63a8\u7406\u3001\u6cbb\u7597\u8ba1\u5212\u3001\u7eb5\u5411\u968f\u8bbf\u7b4911\u4e2a\u4efb\u52a1\u7c7b\u578b\uff0c\u4f7f\u7528\u4f20\u7edf\u6307\u6807\u548cLLM-as-judge\u76f8\u4f3c\u6027\u8bc4\u5206\u6846\u67b6\u8bc4\u4f30\u591a\u79cd\u524d\u6cbfLLM\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5728\u4e34\u5e8a\u4e00\u81f4\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u591a\u8f6e\u968f\u8bbf\u548c\u7ba1\u7406\u4efb\u52a1\u4e2d\uff0c\u8868\u660e\u9700\u8981\u4e13\u95e8\u7684\u6a21\u578b\u8c03\u4f18\u548c\u66f4\u5f3a\u5927\u7684\u8bc4\u4f30\u8303\u5f0f\u3002", "conclusion": "PsychiatryBench\u4e3a\u9ad8\u98ce\u9669\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2dLLM\u6027\u80fd\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u7684\u5e73\u53f0\u3002"}}
{"id": "2509.10018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10018", "abs": "https://arxiv.org/abs/2509.10018", "authors": ["Hailong Yang", "Renhuo Zhao", "Guanjin Wang", "Zhaohong Deng"], "title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "comment": null, "summary": "With the rapid advancement of Large Language Model (LLM), LLM-based agents\nexhibit exceptional abilities in understanding and generating natural language,\nfacilitating human-like collaboration and information transmission in LLM-based\nMulti-Agent System (MAS). High-performance LLMs are often hosted on remote\nservers in public spaces. When tasks involve privacy data, MAS cannot securely\nutilize these LLMs without implementing privacy-preserving mechanisms. To\naddress this challenge, we propose a General Anonymizing Multi-Agent system\n(GAMA), which divides the agents' workspace into private and public spaces and\nprotects privacy through the anonymizing mechanism. In the private space,\nagents handle sensitive data, while in the public space, only anonymized data\nis utilized. GAMA incorporates two key modules to mitigate semantic loss caused\nby anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and\nDisproof-based Logic Enhancement (DLE). We evaluate GAMA on two public\nquestion-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The\nresults demonstrate that GAMA has superior performance compared to the\nstate-of-the-art models. To further assess its privacy-preserving capabilities,\nwe designed two new datasets: Knowledge Privacy Preservation and Logic Privacy\nPreservation. The final results highlight GAMA's exceptional effectiveness in\nboth task processing and privacy preservation.", "AI": {"tldr": "GAMA\u662f\u4e00\u4e2a\u4fdd\u62a4\u9690\u79c1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u5de5\u4f5c\u7a7a\u95f4\u5212\u5206\u4e3a\u79c1\u6709\u548c\u516c\u5171\u533a\u57df\uff0c\u4f7f\u7528\u533f\u540d\u5316\u673a\u5236\u5904\u7406\u654f\u611f\u6570\u636e\uff0c\u5e76\u5f15\u5165DRKE\u548cDLE\u6a21\u5757\u6765\u51cf\u5c11\u8bed\u4e49\u635f\u5931\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5f53\u4efb\u52a1\u6d89\u53ca\u9690\u79c1\u6570\u636e\u65f6\uff0c\u9700\u8981\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u3002", "method": "\u63d0\u51faGAMA\u7cfb\u7edf\uff0c\u5212\u5206\u79c1\u6709\u548c\u516c\u5171\u7a7a\u95f4\uff0c\u91c7\u7528\u533f\u540d\u5316\u673a\u5236\uff0c\u5e76\u5f15\u5165\u9886\u57df\u89c4\u5219\u77e5\u8bc6\u589e\u5f3a(DRKE)\u548c\u53cd\u8bc1\u903b\u8f91\u589e\u5f3a(DLE)\u6765\u7f13\u89e3\u533f\u540d\u5316\u5e26\u6765\u7684\u8bed\u4e49\u635f\u5931\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5728\u65b0\u8bbe\u8ba1\u7684\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u96c6\u4e0a\u4e5f\u663e\u793a\u51fa\u5353\u8d8a\u7684\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u3002", "conclusion": "GAMA\u5728\u4fdd\u6301\u4efb\u52a1\u5904\u7406\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6709\u6548\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\uff0c\u4e3aLLM-based\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9690\u79c1\u5b89\u5168\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09936", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.09936", "abs": "https://arxiv.org/abs/2509.09936", "authors": ["Saarth Gaonkar", "Xiang Zheng", "Haocheng Xi", "Rishabh Tiwari", "Kurt Keutzer", "Dmitriy Morozov", "Michael W. Mahoney", "Amir Gholami"], "title": "SciML Agents: Write the Solver, Not the Solution", "comment": null, "summary": "Recent work in scientific machine learning aims to tackle scientific tasks\ndirectly by predicting target values with neural networks (e.g.,\nphysics-informed neural networks, neural ODEs, neural operators, etc.), but\nattaining high accuracy and robustness has been challenging. We explore an\nalternative view: use LLMs to write code that leverages decades of numerical\nalgorithms. This shifts the burden from learning a solution function to making\ndomain-aware numerical choices. We ask whether LLMs can act as SciML agents\nthat, given a natural-language ODE description, generate runnable code that is\nscientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),\nand enforcing stability checks. There is currently no benchmark to measure this\nkind of capability for scientific computing tasks. As such, we first introduce\ntwo new datasets: a diagnostic dataset of adversarial \"misleading\" problems;\nand a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set\ncontains problems whose superficial appearance suggests stiffness, and that\nrequire algebraic simplification to demonstrate non-stiffness; and the\nlarge-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-\nand closed-source LLM models along two axes: (i) unguided versus guided\nprompting with domain-specific knowledge; and (ii) off-the-shelf versus\nfine-tuned variants. Our evaluation measures both executability and numerical\nvalidity against reference solutions. We find that with sufficient context and\nguided prompts, newer instruction-following models achieve high accuracy on\nboth criteria. In many cases, recent open-source systems perform strongly\nwithout fine-tuning, while older or smaller models still benefit from\nfine-tuning. Overall, our preliminary results indicate that careful prompting\nand fine-tuning can yield a specialized LLM agent capable of reliably solving\nsimple ODE problems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4f7f\u7528LLMs\u4f5c\u4e3a\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u4ee3\u7406\uff0c\u901a\u8fc7\u751f\u6210\u6570\u503c\u7b97\u6cd5\u4ee3\u7801\u6765\u89e3\u51b3ODE\u95ee\u9898\uff0c\u800c\u975e\u76f4\u63a5\u5b66\u4e60\u89e3\u51fd\u6570\u3002\u4f5c\u8005\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u6570\u636e\u96c6\u6765\u8bc4\u4f30LLMs\u5728\u79d1\u5b66\u8ba1\u7b97\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u76f4\u63a5\u9884\u6d4b\u76ee\u6807\u503c\u5b58\u5728\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u6311\u6218\uff0c\u672c\u6587\u63a2\u7d22\u4f7f\u7528LLMs\u7f16\u5199\u6570\u503c\u7b97\u6cd5\u4ee3\u7801\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c06\u8d1f\u62c5\u4ece\u5b66\u4e60\u89e3\u51fd\u6570\u8f6c\u79fb\u5230\u505a\u51fa\u9886\u57df\u611f\u77e5\u7684\u6570\u503c\u9009\u62e9\u3002", "method": "\u5f15\u5165\u8bca\u65ad\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21ODE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5f00\u6e90\u548c\u95ed\u6e90LLM\u6a21\u578b\u5728\u65e0\u5f15\u5bfc\u4e0e\u9886\u57df\u77e5\u8bc6\u5f15\u5bfc\u63d0\u793a\u3001\u73b0\u6210\u4e0e\u5fae\u8c03\u53d8\u4f53\u4e0b\u7684\u8868\u73b0\uff0c\u6d4b\u91cf\u4ee3\u7801\u53ef\u6267\u884c\u6027\u548c\u6570\u503c\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u8db3\u591f\u4e0a\u4e0b\u6587\u548c\u5f15\u5bfc\u63d0\u793a\u4e0b\uff0c\u8f83\u65b0\u7684\u6307\u4ee4\u8ddf\u968f\u6a21\u578b\u5728\u4e24\u4e2a\u8bc4\u4f30\u6807\u51c6\u4e0a\u90fd\u8fbe\u5230\u9ad8\u7cbe\u5ea6\u3002\u5f00\u6e90\u7cfb\u7edf\u65e0\u9700\u5fae\u8c03\u8868\u73b0\u5f3a\u52b2\uff0c\u800c\u8f83\u8001\u6216\u8f83\u5c0f\u6a21\u578b\u4ecd\u80fd\u4ece\u5fae\u8c03\u4e2d\u53d7\u76ca\u3002", "conclusion": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u5fae\u8c03\u53ef\u4ee5\u4ea7\u751f\u80fd\u591f\u53ef\u9760\u89e3\u51b3\u7b80\u5355ODE\u95ee\u9898\u7684\u4e13\u7528LLM\u4ee3\u7406\u3002"}}
{"id": "2509.09712", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09712", "abs": "https://arxiv.org/abs/2509.09712", "authors": ["Talha Tahir"], "title": "The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization", "comment": null, "summary": "Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral\ntherapy with emerging evidence of efficacy in several psychiatric conditions.\nThis study investigates the impact of post-training methodology and explicit\nreasoning on the ability of a small open-weight large language model (LLM) to\ndeliver ACT. Using 50 sets of synthetic ACT transcripts generated by\nMistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,\nsupervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each\nwith and without an explicit chain-of-thought (COT) reasoning step. Performance\nwas evaluated by comparing these four post-trained variants against the base\nInstruct model. These models were benchmarked in simulated therapy sessions,\nwith performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)\nand the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned\non human evaluations. Our findings demonstrate that the ORPO-trained models\nsignificantly outperformed both their SFT and Instruct counterparts on ACT\nfidelity ($\\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\\chi^2(5) =\n140.37, p < .001$). The effect of COT was conditional as it provided a\nsignificant benefit to SFT models, improving ACT-FM scores by an average of\n2.68 points ($p < .001$), while offering no discernible advantage to the\nsuperior ORPO or instruct-tuned variants. We posit that the superiority of ORPO\nstems from its ability to learn the therapeutic `process' over imitating\n`content,' a key aspect of ACT, while COT acts as a necessary scaffold for\nmodels trained only via imitation. This study establishes that\npreference-aligned policy optimization can effectively instill ACT competencies\nin small LLMs, and that the utility of explicit reasoning is highly dependent\non the underlying training paradigm.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86SFT\u548cORPO\u4e24\u79cd\u8bad\u7ec3\u65b9\u6cd5\u5bf9\u5c0f\u578bLLM\u8fdb\u884c\u63a5\u7eb3\u627f\u8bfa\u7597\u6cd5(ACT)\u8bad\u7ec3\u7684\u6548\u679c\uff0c\u53d1\u73b0ORPO\u65b9\u6cd5\u5728\u6cbb\u7597\u4fdd\u771f\u5ea6\u548c\u5171\u60c5\u65b9\u9762\u663e\u8457\u4f18\u4e8eSFT\u548c\u57fa\u7840\u6a21\u578b\uff0c\u800c\u601d\u7ef4\u94fe\u63a8\u7406\u4ec5\u5bf9SFT\u6a21\u578b\u6709\u663e\u8457\u5e2e\u52a9\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u540e\u8bad\u7ec3\u65b9\u6cd5\u548c\u663e\u5f0f\u63a8\u7406\u5bf9\u5c0f\u578b\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u63a5\u7eb3\u627f\u8bfa\u7597\u6cd5\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u63d0\u9ad8LLM\u5728\u5fc3\u7406\u6cbb\u7597\u5e94\u7528\u4e2d\u7684\u6548\u679c\u3002", "method": "\u4f7f\u7528Mistral-Large\u751f\u6210\u768450\u7ec4\u5408\u6210ACT\u8f6c\u5f55\u672c\uff0c\u5bf9Llama-3.2-3b-Instruct\u8fdb\u884c\u4e24\u79cd\u8bad\u7ec3\uff1a\u76d1\u7763\u5fae\u8c03(SFT)\u548codds ratio\u7b56\u7565\u4f18\u5316(ORPO)\uff0c\u6bcf\u79cd\u65b9\u6cd5\u90fd\u5305\u542b\u6709/\u65e0\u601d\u7ef4\u94fe\u63a8\u7406\u6b65\u9aa4\u3002\u901a\u8fc7\u6a21\u62df\u6cbb\u7597\u4f1a\u8bdd\u8bc4\u4f30\u6a21\u578b\u5728ACT\u4fdd\u771f\u5ea6\u91cf\u8868\u548c\u6cbb\u7597\u5e08\u5171\u60c5\u91cf\u8868\u4e0a\u7684\u8868\u73b0\u3002", "result": "ORPO\u8bad\u7ec3\u6a21\u578b\u5728ACT\u4fdd\u771f\u5ea6(\u03c7\u00b2=185.15, p<.001)\u548c\u6cbb\u7597\u5171\u60c5(\u03c7\u00b2=140.37, p<.001)\u65b9\u9762\u663e\u8457\u4f18\u4e8eSFT\u548c\u57fa\u7840\u6a21\u578b\u3002\u601d\u7ef4\u94fe\u63a8\u7406\u4ec5\u5bf9SFT\u6a21\u578b\u6709\u663e\u8457\u76ca\u5904\uff0c\u5e73\u5747\u63d0\u9ad8ACT-FM\u5f97\u52062.68\u5206(p<.001)\uff0c\u4f46\u5bf9ORPO\u6a21\u578b\u65e0\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u504f\u597d\u5bf9\u9f50\u7b56\u7565\u4f18\u5316\u80fd\u6709\u6548\u57f9\u517b\u5c0f\u578bLLM\u7684ACT\u80fd\u529b\uff0c\u663e\u5f0f\u63a8\u7406\u7684\u6548\u7528\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5e95\u5c42\u8bad\u7ec3\u8303\u5f0f\uff0cORPO\u901a\u8fc7\u5b66\u4e60\u6cbb\u7597\u8fc7\u7a0b\u800c\u975e\u6a21\u4eff\u5185\u5bb9\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2509.10054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10054", "abs": "https://arxiv.org/abs/2509.10054", "authors": ["Hailong Yang", "Mingxian Gu", "Jianqi Wang", "Guanjin Wang", "Zhaohong Deng"], "title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has significantly\nenhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans\nwith complex, real-world tasks. However, MAS still face challenges in effective\ntask planning when handling highly complex tasks with uncertainty, often\nresulting in misleading or incorrect outputs that hinder task execution. To\naddress this, we propose XAgents, a unified multi-agent cooperative framework\nbuilt on a multipolar task processing graph and IF-THEN rules. XAgents uses the\nmultipolar task processing graph to enable dynamic task planning and handle\ntask uncertainty. During subtask processing, it integrates domain-specific\nIF-THEN rules to constrain agent behaviors, while global rules enhance\ninter-agent collaboration. We evaluate the performance of XAgents across three\ndistinct datasets, demonstrating that it consistently surpasses\nstate-of-the-art single-agent and multi-agent approaches in both\nknowledge-typed and logic-typed question-answering tasks. The codes for XAgents\nare available at: https://github.com/AGI-FHBC/XAgents.", "AI": {"tldr": "XAgents\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548cIF-THEN\u89c4\u5219\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4efb\u52a1\u89c4\u5212\u548c\u89c4\u5219\u7ea6\u675f\u6765\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u77e5\u8bc6\u578b\u548c\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u9ad8\u5ea6\u590d\u6742\u548c\u4e0d\u786e\u5b9a\u7684\u4efb\u52a1\u65f6\uff0c\u4ecd\u7136\u5b58\u5728\u4efb\u52a1\u89c4\u5212\u6548\u679c\u4e0d\u4f73\u3001\u4ea7\u751f\u8bef\u5bfc\u6027\u8f93\u51fa\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faXAgents\u6846\u67b6\uff0c\u91c7\u7528\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u5b9e\u73b0\u52a8\u6001\u4efb\u52a1\u89c4\u5212\u548c\u5904\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u5b50\u4efb\u52a1\u5904\u7406\u4e2d\u96c6\u6210\u9886\u57df\u7279\u5b9a\u7684IF-THEN\u89c4\u5219\u7ea6\u675f\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u5168\u5c40\u89c4\u5219\u589e\u5f3a\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cXAgents\u5728\u77e5\u8bc6\u578b\u548c\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u4e2d consistently \u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "conclusion": "XAgents\u901a\u8fc7\u521b\u65b0\u7684\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548c\u89c4\u5219\u96c6\u6210\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4efb\u52a1\u6267\u884c\u80fd\u529b\u3002"}}
{"id": "2509.09714", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09714", "abs": "https://arxiv.org/abs/2509.09714", "authors": ["Serge Lionel Nikiema", "Alb\u00e9rick Euraste Djire", "Abdoul Aziz Bonkoungou", "Micheline B\u00e9n\u00e9dicte Moumoula", "Jordan Samhi", "Abdoul Kader Kabore", "Jacques Klein", "Tegawend\u00e9 F. Bissyande"], "title": "How Small Transformation Expose the Weakness of Semantic Similarity Measures", "comment": null, "summary": "This research examines how well different methods measure semantic\nsimilarity, which is important for various software engineering applications\nsuch as code search, API recommendations, automated code reviews, and\nrefactoring tools. While large language models are increasingly used for these\nsimilarity assessments, questions remain about whether they truly understand\nsemantic relationships or merely recognize surface patterns.\n  The study tested 18 different similarity measurement approaches, including\nword-based methods, embedding techniques, LLM-based systems, and\nstructure-aware algorithms. The researchers created a systematic testing\nframework that applies controlled changes to text and code to evaluate how well\neach method handles different types of semantic relationships.\n  The results revealed significant issues with commonly used metrics. Some\nembedding-based methods incorrectly identified semantic opposites as similar up\nto 99.9 percent of the time, while certain transformer-based approaches\noccasionally rated opposite meanings as more similar than synonymous ones. The\nstudy found that embedding methods' poor performance often stemmed from how\nthey calculate distances; switching from Euclidean distance to cosine\nsimilarity improved results by 24 to 66 percent. LLM-based approaches performed\nbetter at distinguishing semantic differences, producing low similarity scores\n(0.00 to 0.29) for genuinely different meanings, compared to embedding methods\nthat incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e8618\u79cd\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6d4b\u91cf\u65b9\u6cd5\uff0c\u53d1\u73b0\u5e38\u7528\u6307\u6807\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u67d0\u4e9b\u5d4c\u5165\u65b9\u6cd5\u5c06\u8bed\u4e49\u5bf9\u7acb\u5185\u5bb9\u8bef\u5224\u4e3a\u76f8\u4f3c\u5ea6\u9ad8\u8fbe99.9%\uff0c\u800cLLM\u65b9\u6cd5\u5728\u533a\u5206\u8bed\u4e49\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u641c\u7d22\u3001API\u63a8\u8350\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u4e2d\u5e7f\u6cdb\u7528\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u4f30\uff0c\u9700\u8981\u9a8c\u8bc1\u8fd9\u4e9b\u65b9\u6cd5\u662f\u5426\u771f\u6b63\u7406\u89e3\u8bed\u4e49\u5173\u7cfb\u8fd8\u662f\u4ec5\u8bc6\u522b\u8868\u9762\u6a21\u5f0f\u3002", "method": "\u7814\u7a76\u6d4b\u8bd5\u4e8618\u79cd\u4e0d\u540c\u65b9\u6cd5\uff08\u5305\u62ec\u57fa\u4e8e\u8bcd\u7684\u65b9\u6cd5\u3001\u5d4c\u5165\u6280\u672f\u3001LLM\u7cfb\u7edf\u548c\u7ed3\u6784\u611f\u77e5\u7b97\u6cd5\uff09\uff0c\u5efa\u7acb\u4e86\u7cfb\u7edf\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u53d7\u63a7\u6587\u672c\u548c\u4ee3\u7801\u53d8\u5316\u6765\u8bc4\u4f30\u5404\u65b9\u6cd5\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u8bed\u4e49\u5173\u7cfb\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5d4c\u5165\u65b9\u6cd5\u7ecf\u5e38\u9519\u8bef\u8bc6\u522b\u8bed\u4e49\u5bf9\u7acb\u5185\u5bb9\uff08\u76f8\u4f3c\u5ea6\u9ad8\u8fbe0.99\uff09\uff0c\u800cLLM\u65b9\u6cd5\u80fd\u66f4\u597d\u533a\u5206\u8bed\u4e49\u5dee\u5f02\uff08\u76f8\u4f3c\u5ea60.00-0.29\uff09\u3002\u4ece\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u5207\u6362\u5230\u4f59\u5f26\u76f8\u4f3c\u5ea6\u4f7f\u5d4c\u5165\u65b9\u6cd5\u6027\u80fd\u63d0\u534724-66%\u3002", "conclusion": "\u5f53\u524d\u5e38\u7528\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0cLLM\u65b9\u6cd5\u5728\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u9700\u8981\u6539\u8fdb\u8ddd\u79bb\u8ba1\u7b97\u65b9\u5f0f\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002"}}
{"id": "2509.10147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10147", "abs": "https://arxiv.org/abs/2509.10147", "authors": ["Nenad Tomasev", "Matija Franklin", "Joel Z. Leibo", "Julian Jacobs", "William A. Cunningham", "Iason Gabriel", "Simon Osindero"], "title": "Virtual Agent Economies", "comment": null, "summary": "The rapid adoption of autonomous AI agents is giving rise to a new economic\nlayer where agents transact and coordinate at scales and speeds beyond direct\nhuman oversight. We propose the \"sandbox economy\" as a framework for analyzing\nthis emergent system, characterizing it along two key dimensions: its origins\n(emergent vs. intentional) and its degree of separateness from the established\nhuman economy (permeable vs. impermeable). Our current trajectory points toward\na spontaneous emergence of a vast and highly permeable AI agent economy,\npresenting us with opportunities for an unprecedented degree of coordination as\nwell as significant challenges, including systemic economic risk and\nexacerbated inequality. Here we discuss a number of possible design choices\nthat may lead to safely steerable AI agent markets. In particular, we consider\nauction mechanisms for fair resource allocation and preference resolution, the\ndesign of AI \"mission economies\" to coordinate around achieving collective\ngoals, and socio-technical infrastructure needed to ensure trust, safety, and\naccountability. By doing this, we argue for the proactive design of steerable\nagent markets to ensure the coming technological shift aligns with humanity's\nlong-term collective flourishing.", "AI": {"tldr": "\u63d0\u51fa\u4e86\"\u6c99\u76d2\u7ecf\u6d4e\"\u6846\u67b6\u6765\u5206\u6790\u65b0\u5174\u7684AI\u4ee3\u7406\u7ecf\u6d4e\uff0c\u5c06\u5176\u5206\u4e3a\u6d8c\u73b0vs\u6709\u610f\u8bbe\u8ba1\u3001\u53ef\u6e17\u900fvs\u4e0d\u53ef\u6e17\u900f\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u8ba8\u8bba\u4e86\u53ef\u5f15\u5bfcAI\u4ee3\u7406\u5e02\u573a\u7684\u8bbe\u8ba1\u9009\u62e9\u4ee5\u786e\u4fdd\u6280\u672f\u8f6c\u578b\u7b26\u5408\u4eba\u7c7b\u957f\u671f\u7e41\u8363\u3002", "motivation": "\u968f\u7740\u81ea\u4e3bAI\u4ee3\u7406\u7684\u5feb\u901f\u91c7\u7528\uff0c\u6b63\u5728\u5f62\u6210\u4e00\u4e2a\u8d85\u8d8a\u4eba\u7c7b\u76f4\u63a5\u76d1\u7763\u7684\u65b0\u7ecf\u6d4e\u5c42\uff0c\u9700\u8981\u5206\u6790\u8fd9\u4e00\u65b0\u5174\u7cfb\u7edf\u5e76\u8bbe\u8ba1\u53ef\u63a7\u7684\u5e02\u573a\u673a\u5236\u6765\u5e94\u5bf9\u673a\u9047\u548c\u6311\u6218\u3002", "method": "\u63d0\u51fa\u6c99\u76d2\u7ecf\u6d4e\u5206\u6790\u6846\u67b6\uff0c\u4ece\u8d77\u6e90\uff08\u6d8c\u73b0/\u6709\u610f\uff09\u548c\u5206\u79bb\u5ea6\uff08\u53ef\u6e17\u900f/\u4e0d\u53ef\u6e17\u900f\uff09\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8868\u5f81\uff0c\u63a2\u8ba8\u62cd\u5356\u673a\u5236\u3001AI\"\u4efb\u52a1\u7ecf\u6d4e\"\u8bbe\u8ba1\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u7b49\u8bbe\u8ba1\u9009\u62e9\u3002", "result": "\u5f53\u524d\u8d8b\u52bf\u6307\u5411\u4e00\u4e2a\u81ea\u53d1\u6d8c\u73b0\u7684\u5e9e\u5927\u4e14\u9ad8\u5ea6\u53ef\u6e17\u900f\u7684AI\u4ee3\u7406\u7ecf\u6d4e\uff0c\u65e2\u5e26\u6765\u524d\u6240\u672a\u6709\u7684\u534f\u8c03\u673a\u4f1a\uff0c\u4e5f\u5e26\u6765\u7cfb\u7edf\u6027\u7ecf\u6d4e\u98ce\u9669\u548c\u52a0\u5267\u4e0d\u5e73\u7b49\u7684\u6311\u6218\u3002", "conclusion": "\u9700\u8981\u4e3b\u52a8\u8bbe\u8ba1\u53ef\u5f15\u5bfc\u7684\u4ee3\u7406\u5e02\u573a\uff0c\u901a\u8fc7\u62cd\u5356\u673a\u5236\u3001\u96c6\u4f53\u76ee\u6807\u534f\u8c03\u548c\u4fe1\u4efb\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\uff0c\u786e\u4fdd\u6280\u672f\u8f6c\u578b\u4e0e\u4eba\u7c7b\u957f\u671f\u96c6\u4f53\u7e41\u8363\u76f8\u4e00\u81f4\u3002"}}
{"id": "2509.09715", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09715", "abs": "https://arxiv.org/abs/2509.09715", "authors": ["Naveen Lamba", "Sanju Tiwari", "Manas Gaur"], "title": "Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA", "comment": null, "summary": "Hallucination in Large Language Models (LLMs) is a well studied problem.\nHowever, the properties that make LLM intrinsically vulnerable to\nhallucinations have not been identified and studied. This research identifies\nand characterizes the key properties, allowing us to pinpoint vulnerabilities\nwithin the model's internal mechanisms. To solidify on these properties, we\nutilized two established datasets, HaluEval and TruthfulQA and convert their\nexisting format of question answering into various other formats to narrow down\nthese properties as the reason for the hallucinations. Our findings reveal that\nhallucination percentages across symbolic properties are notably high for\nGemma-2-2B, averaging 79.0% across tasks and datasets. With increased model\nscale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,\nreflecting a 15 percentage point reduction overall. Although the hallucination\nrate decreases as the model size increases, a substantial amount of\nhallucination caused by symbolic properties still persists. This is especially\nevident for modifiers (ranging from 84.76% to 94.98%) and named entities\n(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.\nThese findings indicate that symbolic elements continue to confuse the models,\npointing to a fundamental weakness in how these LLMs process such\ninputs--regardless of their scale.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc6\u522b\u5e76\u8868\u5f81\u4e86\u5bfc\u81f4\u5927\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u5e7b\u89c9\u7684\u5173\u952e\u7b26\u53f7\u5c5e\u6027\uff0c\u53d1\u73b0\u7b26\u53f7\u5143\u7d20\uff08\u5982\u4fee\u9970\u8bed\u548c\u547d\u540d\u5b9e\u4f53\uff09\u662f\u6a21\u578b\u4ea7\u751f\u5e7b\u89c9\u7684\u6839\u672c\u539f\u56e0\uff0c\u4e14\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\u5e7b\u89c9\u7387\u4ec5\u7565\u6709\u4e0b\u964d\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5bfc\u81f4\u6a21\u578b\u5185\u5728\u6613\u4ea7\u751f\u5e7b\u89c9\u7684\u5c5e\u6027\u5c1a\u672a\u88ab\u8bc6\u522b\u548c\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc6\u522b\u548c\u8868\u5f81\u8fd9\u4e9b\u5173\u952e\u5c5e\u6027\uff0c\u4ee5\u5b9a\u4f4d\u6a21\u578b\u5185\u90e8\u673a\u5236\u7684\u6f0f\u6d1e\u3002", "method": "\u4f7f\u7528HaluEval\u548cTruthfulQA\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u5c06\u73b0\u6709\u7684\u95ee\u7b54\u683c\u5f0f\u8f6c\u6362\u4e3a\u591a\u79cd\u5176\u4ed6\u683c\u5f0f\uff0c\u4ee5\u786e\u5b9a\u7b26\u53f7\u5c5e\u6027\u662f\u5bfc\u81f4\u5e7b\u89c9\u7684\u539f\u56e0\u3002\u6d4b\u8bd5\u4e86Gemma-2\u7cfb\u5217\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\uff082B\u30019B\u300127B\uff09\u3002", "result": "Gemma-2-2B\u7684\u5e73\u5747\u5e7b\u89c9\u7387\u4e3a79.0%\uff0c\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\uff0cGemma-2-9B\u964d\u81f373.6%\uff0cGemma-2-27B\u964d\u81f363.9%\u3002\u4fee\u9970\u8bed\uff0884.76%-94.98%\uff09\u548c\u547d\u540d\u5b9e\u4f53\uff0883.87%-93.96%\uff09\u5728\u6240\u6709\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u6781\u9ad8\u7684\u5e7b\u89c9\u7387\u3002", "conclusion": "\u7b26\u53f7\u5143\u7d20\u6301\u7eed\u6df7\u6dc6\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u5728\u5904\u7406\u6b64\u7c7b\u8f93\u5165\u65f6\u5b58\u5728\u6839\u672c\u6027\u5f31\u70b9\uff0c\u4e14\u8fd9\u79cd\u5f31\u70b9\u4e0d\u53d7\u6a21\u578b\u89c4\u6a21\u5f71\u54cd\u3002\u7b26\u53f7\u5c5e\u6027\u662f\u5bfc\u81f4\u5e7b\u89c9\u7684\u5185\u5728\u8106\u5f31\u6027\u6765\u6e90\u3002"}}
{"id": "2509.10222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10222", "abs": "https://arxiv.org/abs/2509.10222", "authors": ["Ma\u00ebl Jullien", "Lei Xu", "Marco Valentino", "Andr\u00e9 Freitas"], "title": "Compartmentalised Agentic Reasoning for Clinical NLI", "comment": null, "summary": "A common assumption holds that scaling data and parameters yields\nincreasingly structured, generalisable internal representations. We interrogate\nthis assumption in clinical natural language inference (NLI) by adopting a\nbenchmark decomposed into four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction,\nand introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI\nthat separates knowledge access from principled inference. CARENLI routes each\npremise, statement pair to a family specific solver and enforces auditable\nprocedures via a planner, verifier, and refiner.\n  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching\n98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag\nviolations with near-ceiling reliability, while refiners correct a substantial\nshare of epistemic errors. Remaining failures cluster in routing, identifying\nfamily classification as the main bottleneck. These results show that LLMs\noften retain relevant facts but default to heuristics when inference is\nunderspecified, a dissociation CARENLI makes explicit while offering a\nframework for safer, auditable reasoning.", "AI": {"tldr": "CARENLI\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u7684\u6a21\u5757\u5316\u4ee3\u7406\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u8bbf\u95ee\u4e0e\u63a8\u7406\u5206\u79bb\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u53ef\u5ba1\u8ba1\u6027", "motivation": "\u6311\u6218\u6570\u636e\u89c4\u6a21\u548c\u53c2\u6570\u6269\u5c55\u4f1a\u81ea\u52a8\u4ea7\u751f\u7ed3\u6784\u5316\u3001\u53ef\u6cdb\u5316\u5185\u90e8\u8868\u793a\u7684\u5047\u8bbe\uff0c\u7279\u522b\u662f\u5728\u4e34\u5e8aNLI\u9886\u57df\u9700\u8981\u66f4\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u63a8\u7406\u65b9\u6cd5", "method": "\u5f00\u53d1CARENLI\u6846\u67b6\uff0c\u5c06\u524d\u63d0-\u9648\u8ff0\u5bf9\u8def\u7531\u5230\u56db\u4e2a\u7279\u5b9a\u63a8\u7406\u5bb6\u65cf\u7684\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u89c4\u5212\u5668\u3001\u9a8c\u8bc1\u5668\u548c\u7cbe\u70bc\u5668\u5f3a\u5236\u6267\u884c\u53ef\u5ba1\u8ba1\u7a0b\u5e8f", "result": "\u5728\u56db\u4e2aLLM\u4e0a\uff0cCARENLI\u5c06\u4fdd\u771f\u5ea6\u63d0\u9ad8\u4e86\u591a\u8fbe42\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u56e0\u679c\u5f52\u56e0\u4e2d\u8fbe\u523098.0%\uff0c\u5728\u98ce\u9669\u72b6\u6001\u62bd\u8c61\u4e2d\u8fbe\u523081.2%\uff0c\u9a8c\u8bc1\u5668\u4ee5\u63a5\u8fd1\u9876\u7ea7\u7684\u53ef\u9760\u6027\u6807\u8bb0\u8fdd\u89c4", "conclusion": "LLMs\u901a\u5e38\u4fdd\u7559\u76f8\u5173\u4e8b\u5b9e\u4f46\u5728\u63a8\u7406\u672a\u660e\u786e\u6307\u5b9a\u65f6\u9ed8\u8ba4\u4f7f\u7528\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0cCARENLI\u660e\u786e\u4e86\u8fd9\u79cd\u5206\u79bb\uff0c\u540c\u65f6\u4e3a\u66f4\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u63a8\u7406\u63d0\u4f9b\u4e86\u6846\u67b6"}}
{"id": "2509.09725", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09725", "abs": "https://arxiv.org/abs/2509.09725", "authors": ["Chunyu Li", "Xindi Zheng", "Siqi Liu"], "title": "BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025", "comment": null, "summary": "Entity linking (EL) for biomedical text is typically benchmarked on\nEnglish-only corpora with flat mentions, leaving the more realistic scenario of\nnested and multilingual mentions largely unexplored. We present our system for\nthe BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task\n(English & Russian), closing this gap with a lightweight pipeline that keeps\nthe original EL model intact and modifies only three task-aligned components:\nTwo-stage retrieval-ranking. We leverage the same base encoder model in both\nstages: the retrieval stage uses the original pre-trained model, while the\nranking stage applies domain-specific fine-tuning. Boundary cues. In the\nranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing\nthe encoder with an explicit, language-agnostic span before robustness to\noverlap and nesting. Dataset augmentation. We also automatically expand the\nranking training corpus with three complementary data sources, enhancing\ncoverage without extra manual annotation. On the BioNNE 2025 leaderboard, our\ntwo stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual\ntrack, demonstrating the effectiveness and competitiveness of these minimal yet\nprincipled modifications. Code are publicly available at\nhttps://github.com/Kaggle-Competitions-Code/BioNNE-L.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u4e24\u9636\u6bb5\u5b9e\u4f53\u94fe\u63a5\u7cfb\u7edfBIBERT-Pipe\uff0c\u7528\u4e8e\u5904\u7406\u751f\u7269\u533b\u5b66\u6587\u672c\u4e2d\u7684\u591a\u8bed\u8a00\u5d4c\u5957\u547d\u540d\u5b9e\u4f53\u94fe\u63a5\u4efb\u52a1\uff0c\u5728BioNNE 2025\u591a\u8bed\u8a00\u8d5b\u9053\u4e2d\u6392\u540d\u7b2c\u4e09", "motivation": "\u73b0\u6709\u7684\u751f\u7269\u533b\u5b66\u5b9e\u4f53\u94fe\u63a5\u57fa\u51c6\u4e3b\u8981\u9488\u5bf9\u82f1\u8bed\u548c\u5e73\u5766\u5b9e\u4f53\uff0c\u7f3a\u4e4f\u5bf9\u591a\u8bed\u8a00\u548c\u5d4c\u5957\u5b9e\u4f53\u7684\u7814\u7a76\uff0c\u9700\u8981\u586b\u8865\u8fd9\u4e00\u7a7a\u767d", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22-\u6392\u5e8f\u7ba1\u9053\uff1a\u68c0\u7d22\u9636\u6bb5\u4f7f\u7528\u539f\u59cb\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6392\u5e8f\u9636\u6bb5\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u5fae\u8c03\uff1b\u4f7f\u7528\u53ef\u5b66\u4e60\u7684[Ms]/[Me]\u6807\u7b7e\u5305\u88c5\u63d0\u53ca\uff1b\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u6570\u636e\u6e90\u81ea\u52a8\u6269\u5c55\u8bad\u7ec3\u8bed\u6599", "result": "\u5728BioNNE 2025\u591a\u8bed\u8a00\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c\u4e09\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u6700\u5c0f\u4f46\u539f\u5219\u6027\u4fee\u6539\u7684\u6709\u6548\u6027\u548c\u7ade\u4e89\u529b", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u5728\u4fdd\u6301\u539f\u6709\u5b9e\u4f53\u94fe\u63a5\u6a21\u578b\u5b8c\u6574\u6027\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u7684\u7ec4\u4ef6\u4fee\u6539\u6210\u529f\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u5d4c\u5957\u5b9e\u4f53\u94fe\u63a5\u7684\u6311\u6218"}}
{"id": "2509.09727", "categories": ["cs.CL", "cs.CE"], "pdf": "https://arxiv.org/pdf/2509.09727", "abs": "https://arxiv.org/abs/2509.09727", "authors": ["Andy Zhu", "Yingjun Du"], "title": "A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs", "comment": "8 pages, 6 figures, Underreview", "summary": "Question answering (QA) plays a central role in financial education, yet\nexisting large language model (LLM) approaches often fail to capture the\nnuanced and specialized reasoning required for financial problem-solving. The\nfinancial domain demands multistep quantitative reasoning, familiarity with\ndomain-specific terminology, and comprehension of real-world scenarios. We\npresent a multi-agent framework that leverages role-based prompting to enhance\nperformance on domain-specific QA. Our framework comprises a Base Generator, an\nEvidence Retriever, and an Expert Reviewer agent that work in a single-pass\niteration to produce a refined answer. We evaluated our framework on a set of\n3,532 expert-designed finance education questions from Study.com, an online\nlearning platform. We leverage retrieval-augmented generation (RAG) for\ncontextual evidence from 6 finance textbooks and prompting strategies for a\ndomain-expert reviewer. Our experiments indicate that critique-based refinement\nimproves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,\nwith the highest performance from Gemini-2.0-Flash. Furthermore, our method\nenables GPT-4o-mini to achieve performance comparable to the finance-tuned\nFinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to\nenhancing financial QA and offer insights for further research in multi-agent\nfinancial LLM systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u89d2\u8272\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u91d1\u878d\u95ee\u7b54\u7684\u51c6\u786e\u6027\uff0c\u76f8\u6bd4\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u57fa\u7ebf\u63d0\u9ad86.6-8.3%", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u6559\u80b2\u95ee\u7b54\u4e2d\u96be\u4ee5\u6355\u6349\u4e13\u4e1a\u63a8\u7406\u9700\u6c42\uff0c\u91d1\u878d\u9886\u57df\u9700\u8981\u591a\u6b65\u5b9a\u91cf\u63a8\u7406\u3001\u4e13\u4e1a\u672f\u8bed\u7406\u89e3\u548c\u73b0\u5b9e\u573a\u666f\u7406\u89e3", "method": "\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u62ec\u57fa\u7840\u751f\u6210\u5668\u3001\u8bc1\u636e\u68c0\u7d22\u5668\u548c\u4e13\u5bb6\u8bc4\u5ba1\u5668\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u4ece6\u672c\u91d1\u878d\u6559\u79d1\u4e66\u4e2d\u83b7\u53d6\u4e0a\u4e0b\u6587\u8bc1\u636e", "result": "\u57fa\u4e8e\u6279\u5224\u7684\u7ec6\u5316\u65b9\u6cd5\u6bd4\u96f6\u6837\u672c\u601d\u7ef4\u94fe\u57fa\u7ebf\u63d0\u9ad86.6-8.3%\u7684\u51c6\u786e\u7387\uff0cGemini-2.0-Flash\u8868\u73b0\u6700\u4f73\uff0cGPT-4o-mini\u8fbe\u5230\u4e0e\u91d1\u878d\u8c03\u4f18\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u91d1\u878d\u95ee\u7b54\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u91d1\u878dLLM\u7cfb\u7edf\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u89c1\u89e3"}}
{"id": "2509.10401", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10401", "abs": "https://arxiv.org/abs/2509.10401", "authors": ["Alva West", "Yixuan Weng", "Minjun Zhu", "Zhen Lin", "Yue Zhang"], "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "comment": null, "summary": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.", "AI": {"tldr": "A2P Scaffolding\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u5f52\u56e0\u4ece\u6a21\u5f0f\u8bc6\u522b\u4efb\u52a1\u8f6c\u53d8\u4e3a\u56e0\u679c\u63a8\u7406\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6b65\u9aa4\u7ea7\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6545\u969c\u5f52\u56e0\u65b9\u6cd5\u51c6\u786e\u7387\u6781\u4f4e\uff08\u4f4e\u4e8e17%\uff09\uff0c\u65e0\u6cd5\u8fdb\u884c\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u6765\u786e\u5b9a\u7ea0\u6b63\u5355\u4e2a\u52a8\u4f5c\u662f\u5426\u80fd\u907f\u514d\u4efb\u52a1\u5931\u8d25\u3002", "method": "\u63d0\u51faAbduct-Act-Predict (A2P) Scaffolding\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u7ed3\u6784\u5316\u6b65\u9aa4\uff1a\u6eaf\u56e0\u63a8\u7406\uff08\u63a8\u65ad\u884c\u52a8\u80cc\u540e\u7684\u9690\u85cf\u539f\u56e0\uff09\u3001\u884c\u52a8\uff08\u5b9a\u4e49\u6700\u5c0f\u7ea0\u6b63\u5e72\u9884\uff09\u3001\u9884\u6d4b\uff08\u6a21\u62df\u540e\u7eed\u8f68\u8ff9\u9a8c\u8bc1\u5e72\u9884\u6548\u679c\uff09\u3002", "result": "\u5728Algorithm-Generated\u6570\u636e\u96c6\u4e0a\u8fbe\u523047.46%\u7684\u6b65\u9aa4\u7ea7\u51c6\u786e\u7387\uff08\u6bd4\u57fa\u7ebf16.67%\u63d0\u9ad82.85\u500d\uff09\uff0c\u5728Hand-Crafted\u6570\u636e\u96c6\u4e0a\u8fbe\u523029.31%\u51c6\u786e\u7387\uff08\u6bd4\u57fa\u7ebf12.07%\u63d0\u9ad82.43\u500d\uff09\u3002", "conclusion": "\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u7684\u89c6\u89d2\u91cd\u65b0\u6784\u5efa\u95ee\u9898\uff0cA2P Scaffolding\u4e3a\u81ea\u52a8\u5316\u6545\u969c\u5f52\u56e0\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u3001\u53ef\u9a8c\u8bc1\u4e14\u51c6\u786e\u5ea6\u663e\u8457\u66f4\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09729", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2509.09729", "abs": "https://arxiv.org/abs/2509.09729", "authors": ["Gerard Sant", "Zifan Jiang", "Carlos Escolano", "Amit Moryossef", "Mathias M\u00fcller", "Rico Sennrich", "Sarah Ebling"], "title": "MultimodalHugs: Enabling Sign Language Processing in Hugging Face", "comment": null, "summary": "In recent years, sign language processing (SLP) has gained importance in the\ngeneral field of Natural Language Processing. However, compared to research on\nspoken languages, SLP research is hindered by complex ad-hoc code,\ninadvertently leading to low reproducibility and unfair comparisons. Existing\ntools that are built for fast and reproducible experimentation, such as Hugging\nFace, are not flexible enough to seamlessly integrate sign language\nexperiments. This view is confirmed by a survey we conducted among SLP\nresearchers.\n  To address these challenges, we introduce MultimodalHugs, a framework built\non top of Hugging Face that enables more diverse data modalities and tasks,\nwhile inheriting the well-known advantages of the Hugging Face ecosystem. Even\nthough sign languages are our primary focus, MultimodalHugs adds a layer of\nabstraction that makes it more widely applicable to other use cases that do not\nfit one of the standard templates of Hugging Face. We provide quantitative\nexperiments to illustrate how MultimodalHugs can accommodate diverse modalities\nsuch as pose estimation data for sign languages, or pixel data for text\ncharacters.", "AI": {"tldr": "MultimodalHugs\u662f\u4e00\u4e2a\u57fa\u4e8eHugging Face\u6784\u5efa\u7684\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u624b\u8bed\u5904\u7406\u7814\u7a76\u4e2d\u5b58\u5728\u7684\u4ee3\u7801\u590d\u6742\u3001\u53ef\u590d\u73b0\u6027\u4f4e\u548c\u6bd4\u8f83\u4e0d\u516c\u5e73\u7b49\u95ee\u9898\uff0c\u652f\u6301\u66f4\u591a\u6837\u5316\u7684\u6570\u636e\u6a21\u6001\u548c\u4efb\u52a1\u3002", "motivation": "\u624b\u8bed\u5904\u7406\u7814\u7a76\u76f8\u6bd4\u53e3\u8bed\u8bed\u8a00\u7814\u7a76\u9762\u4e34\u66f4\u591a\u6311\u6218\uff0c\u5305\u62ec\u590d\u6742\u7684\u4e34\u65f6\u4ee3\u7801\u3001\u4f4e\u53ef\u590d\u73b0\u6027\u548c\u4e0d\u516c\u5e73\u6bd4\u8f83\u3002\u73b0\u6709\u5de5\u5177\u5982Hugging Face\u5728\u624b\u8bed\u5b9e\u9a8c\u96c6\u6210\u65b9\u9762\u4e0d\u591f\u7075\u6d3b\u3002", "method": "\u5728Hugging Face\u57fa\u7840\u4e0a\u6784\u5efaMultimodalHugs\u6846\u67b6\uff0c\u589e\u52a0\u62bd\u8c61\u5c42\u4ee5\u652f\u6301\u66f4\u591a\u6570\u636e\u6a21\u6001\u548c\u4efb\u52a1\uff0c\u7279\u522b\u662f\u624b\u8bed\u59ff\u6001\u4f30\u8ba1\u6570\u636e\u548c\u6587\u672c\u5b57\u7b26\u50cf\u7d20\u6570\u636e\u7b49\u591a\u6837\u5316\u6a21\u6001\u3002", "result": "\u901a\u8fc7\u5b9a\u91cf\u5b9e\u9a8c\u8bc1\u660eMultimodalHugs\u80fd\u591f\u6709\u6548\u9002\u5e94\u591a\u79cd\u6570\u636e\u6a21\u6001\uff0c\u4e3a\u624b\u8bed\u5904\u7406\u7814\u7a76\u63d0\u4f9b\u66f4\u597d\u7684\u5b9e\u9a8c\u652f\u6301\u548c\u53ef\u590d\u73b0\u6027\u4fdd\u969c\u3002", "conclusion": "MultimodalHugs\u6846\u67b6\u6269\u5c55\u4e86Hugging Face\u751f\u6001\u7cfb\u7edf\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u624b\u8bed\u5904\u7406\uff0c\u8fd8\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5176\u4ed6\u4e0d\u7b26\u5408Hugging Face\u6807\u51c6\u6a21\u677f\u7684\u591a\u6a21\u6001\u7528\u4f8b\uff0c\u63d0\u9ad8\u4e86\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2509.10423", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10423", "abs": "https://arxiv.org/abs/2509.10423", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "comment": "10 pages, 4 figures, 1 table", "summary": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\u6765\u8bca\u65adRL\u4ee3\u7406\u5728\u90e8\u7f72\u65f6\u7684\u5f02\u5e38\u6545\u969c\uff0c\u80fd\u591f\u533a\u5206\u4f20\u611f\u5668\u6545\u969c\u548c\u9a71\u52a8\u5668\u6545\u969c\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u7684RL\u4ee3\u7406\u9762\u4e34\u4f20\u611f\u5668\u6545\u969c\u3001\u9a71\u52a8\u5668\u78e8\u635f\u548c\u73af\u5883\u53d8\u5316\u7b49\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5185\u5728\u673a\u5236\u6765\u68c0\u6d4b\u548c\u8bca\u65ad\u8fd9\u4e9b\u6545\u969c\u3002", "method": "\u4f7f\u7528\u4fe1\u606f\u8bba\u6846\u67b6\u5206\u6790\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u6a21\u5f0f\uff0c\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5b9e\u9a8c\u9a8c\u8bc1\u4fe1\u606f\u6307\u6807\u5bf9\u7cfb\u7edf\u6545\u969c\u7684\u5dee\u5f02\u8bca\u65ad\u80fd\u529b\u3002", "result": "\u6210\u529f\u5b66\u4e60\u8868\u73b0\u51fa\u7279\u5f81\u6027\u4fe1\u606f\u7b7e\u540d\uff1a\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\u4ece0.84\u589e\u957f\u52302.83\u6bd4\u7279\uff08238%\u589e\u957f\uff09\uff1b\u4fe1\u606f\u6307\u6807\u80fd\u591f\u533a\u5206\u4f20\u611f\u5668\u6545\u969c\uff08\u5e7f\u6cdb\u7684\u4fe1\u606f\u901a\u9053\u5d29\u6e83\uff09\u548c\u9a71\u52a8\u5668\u6545\u969c\uff08\u9009\u62e9\u6027\u7834\u574f\u52a8\u4f5c-\u7ed3\u679c\u53ef\u9884\u6d4b\u6027\uff09\u3002", "conclusion": "\u4fe1\u606f\u6a21\u5f0f\u65e2\u662f\u5b66\u4e60\u7684\u7b7e\u540d\uff0c\u4e5f\u662f\u7cfb\u7edf\u5065\u5eb7\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4e3a\u80fd\u591f\u57fa\u4e8e\u4fe1\u606f\u8bba\u539f\u7406\u8fdb\u884c\u81ea\u4e3b\u6545\u969c\u68c0\u6d4b\u548c\u653f\u7b56\u8c03\u6574\u7684\u81ea\u9002\u5e94RL\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.09734", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09734", "abs": "https://arxiv.org/abs/2509.09734", "authors": ["Zikang Guo", "Benfeng Xu", "Chiwei Zhu", "Wentao Hong", "Xiaorui Wang", "Zhendong Mao"], "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly emerging as a pivotal open\nstandard, designed to enhance agent-tool integration and interoperability, and\nis positioned to unlock a new era of powerful, interconnected, and genuinely\nutilitarian agentic AI. However, despite MCP's growing adoption, existing\nbenchmarks often fail to capture real-world agent performance within this new\nparadigm, leading to a distorted perception of their true operational value and\nan inability to reliably differentiate proficiencies. To bridge this critical\nevaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark\nspecifically engineered to rigorously assess language agent capabilities in\nMCP-mediated tool interactions. Core contributions of MCP-AgentBench include:\nthe establishment of a robust MCP testbed comprising 33 operational servers\nwith 188 distinct tools; the development of a benchmark featuring 600\nsystematically designed queries distributed across 6 distinct categories of\nvarying interaction complexity; and the introduction of MCP-Eval, a novel\noutcome-oriented evaluation methodology prioritizing real-world task success.\nThrough extensive empirical evaluation of leading language agents, we provide\nfoundational insights. MCP-AgentBench aims to equip the research community with\na standardized and reliable framework to build, validate, and advance agents\ncapable of fully leveraging MCP's transformative benefits, thereby accelerating\nprogress toward truly capable and interoperable AI systems.", "AI": {"tldr": "MCP-AgentBench\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9MCP\u534f\u8bae\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b33\u4e2a\u670d\u52a1\u5668\u3001188\u4e2a\u5de5\u5177\u548c600\u4e2a\u67e5\u8be2\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u4ee3\u7406\u5728\u5de5\u5177\u4ea4\u4e92\u4e2d\u7684\u771f\u5b9e\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u5728MCP\u65b0\u8303\u5f0f\u4e0b\u7684\u771f\u5b9e\u4ee3\u7406\u6027\u80fd\uff0c\u5bfc\u81f4\u5bf9\u5176\u5b9e\u9645\u64cd\u4f5c\u4ef7\u503c\u7684\u8ba4\u77e5\u5931\u771f\uff0c\u65e0\u6cd5\u53ef\u9760\u533a\u5206\u4e0d\u540c\u4ee3\u7406\u7684\u80fd\u529b\u5dee\u5f02\u3002", "method": "\u5efa\u7acb\u4e86\u5305\u542b33\u4e2a\u64cd\u4f5c\u670d\u52a1\u5668\u548c188\u4e2a\u4e0d\u540c\u5de5\u5177\u7684MCP\u6d4b\u8bd5\u5e8a\uff1b\u5f00\u53d1\u4e86\u5305\u542b6\u4e2a\u4e0d\u540c\u4ea4\u4e92\u590d\u6742\u5ea6\u7c7b\u522b\u7684600\u4e2a\u7cfb\u7edf\u8bbe\u8ba1\u67e5\u8be2\uff1b\u5f15\u5165\u4e86MCP-Eval\u8fd9\u4e00\u65b0\u9896\u7684\u7ed3\u679c\u5bfc\u5411\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f18\u5148\u8003\u8651\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u6210\u529f\u7387\u3002", "result": "\u901a\u8fc7\u5bf9\u9886\u5148\u8bed\u8a00\u4ee3\u7406\u7684\u5e7f\u6cdb\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u57fa\u7840\u6027\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u4ee3\u7406\u5728MCP\u73af\u5883\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "MCP-AgentBench\u65e8\u5728\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e00\u4e2a\u6807\u51c6\u5316\u3001\u53ef\u9760\u7684\u6846\u67b6\uff0c\u4ee5\u6784\u5efa\u3001\u9a8c\u8bc1\u548c\u63a8\u8fdb\u80fd\u591f\u5145\u5206\u5229\u7528MCP\u53d8\u9769\u6027\u4f18\u52bf\u7684\u4ee3\u7406\uff0c\u4ece\u800c\u52a0\u901f\u771f\u6b63\u80fd\u529b\u548c\u4e92\u64cd\u4f5c\u6027AI\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2509.10161", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.10161", "abs": "https://arxiv.org/abs/2509.10161", "authors": ["Shiwei Li", "Qunwei Li", "Haozhao Wang", "Ruixuan Li", "Jianbin Lin", "Wenliang Zhong"], "title": "FedBiF: Communication-Efficient Federated Learning via Bits Freezing", "comment": "Accepted by TPDS", "summary": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative model training without sharing local data. Despite\nits advantages, FL suffers from substantial communication overhead, which can\naffect training efficiency. Recent efforts have mitigated this issue by\nquantizing model updates to reduce communication costs. However, most existing\nmethods apply quantization only after local training, introducing quantization\nerrors into the trained parameters and potentially degrading model accuracy. In\nthis paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework\nthat directly learns quantized model parameters during local training. In each\ncommunication round, the server first quantizes the model parameters and\ntransmits them to the clients. FedBiF then allows each client to update only a\nsingle bit of the multi-bit parameter representation, freezing the remaining\nbits. This bit-by-bit update strategy reduces each parameter update to one bit\nwhile maintaining high precision in parameter representation. Extensive\nexperiments are conducted on five widely used datasets under both IID and\nNon-IID settings. The results demonstrate that FedBiF not only achieves\nsuperior communication compression but also promotes sparsity in the resulting\nmodels. Notably, FedBiF attains accuracy comparable to FedAvg, even when using\nonly 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.\nThe code is available at https://github.com/Leopold1423/fedbif-tpds25.", "AI": {"tldr": "\u63d0\u51fa\u4e86FedBiF\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u672c\u5730\u8bad\u7ec3\u671f\u95f4\u76f4\u63a5\u5b66\u4e60\u91cf\u5316\u6a21\u578b\u53c2\u6570\uff0c\u6bcf\u6b21\u4ec5\u66f4\u65b0\u5355\u4e2a\u6bd4\u7279\u6765\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5b58\u5728\u663e\u8457\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u73b0\u6709\u91cf\u5316\u65b9\u6cd5\u901a\u5e38\u5728\u672c\u5730\u8bad\u7ec3\u540e\u5e94\u7528\u91cf\u5316\uff0c\u5bfc\u81f4\u91cf\u5316\u8bef\u5dee\u5f71\u54cd\u6a21\u578b\u7cbe\u5ea6\u3002", "method": "\u670d\u52a1\u5668\u5148\u91cf\u5316\u6a21\u578b\u53c2\u6570\u5e76\u53d1\u9001\u7ed9\u5ba2\u6237\u7aef\uff0c\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6bcf\u6b21\u53ea\u66f4\u65b0\u591a\u6bd4\u7279\u53c2\u6570\u8868\u793a\u4e2d\u7684\u5355\u4e2a\u6bd4\u7279\uff0c\u51bb\u7ed3\u5176\u4f59\u6bd4\u7279\u3002", "result": "\u57285\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFedBiF\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u901a\u4fe1\u538b\u7f29\uff0c\u4fc3\u8fdb\u6a21\u578b\u7a00\u758f\u6027\uff0c\u5728\u4ec5\u4f7f\u75281bpp\u4e0a\u884c\u548c3bpp\u4e0b\u884c\u901a\u4fe1\u65f6\u8fbe\u5230\u4e0eFedAvg\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "FedBiF\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u901a\u4fe1\u5f00\u9500\u95ee\u9898\uff0c\u901a\u8fc7\u9010\u6bd4\u7279\u66f4\u65b0\u7b56\u7565\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u3002"}}
{"id": "2509.10163", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10163", "abs": "https://arxiv.org/abs/2509.10163", "authors": ["Francisco Javier Esono Nkulu Andong", "Qi Min"], "title": "Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks", "comment": null, "summary": "As sixth-generation (6G) networks move toward ultra-dense, intelligent edge\nenvironments, efficient resource management under stringent privacy, mobility,\nand energy constraints becomes critical. This paper introduces a novel\nFederated Multi-Agent Reinforcement Learning (Fed-MARL) framework that\nincorporates cross-layer orchestration of both the MAC layer and application\nlayer for energy-efficient, privacy-preserving, and real-time resource\nmanagement across heterogeneous edge devices. Each agent uses a Deep Recurrent\nQ-Network (DRQN) to learn decentralized policies for task offloading, spectrum\naccess, and CPU energy adaptation based on local observations (e.g., queue\nlength, energy, CPU usage, and mobility). To protect privacy, we introduce a\nsecure aggregation protocol based on elliptic curve Diffie Hellman key\nexchange, which ensures accurate model updates without exposing raw data to\nsemi-honest adversaries. We formulate the resource management problem as a\npartially observable multi-agent Markov decision process (POMMDP) with a\nmulti-objective reward function that jointly optimizes latency, energy\nefficiency, spectral efficiency, fairness, and reliability under 6G-specific\nservice requirements such as URLLC, eMBB, and mMTC. Simulation results\ndemonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines\nin task success rate, latency, energy efficiency, and fairness, while ensuring\nrobust privacy protection and scalability in dynamic, resource-constrained 6G\nedge networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u90a6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Fed-MARL\uff0c\u7528\u4e8e6G\u8d85\u5bc6\u96c6\u8fb9\u7f18\u7f51\u7edc\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u3001\u5b9e\u65f6\u8d44\u6e90\u7ba1\u7406\uff0c\u901a\u8fc7\u8de8\u5c42\u534f\u8c03\u548c\u52a0\u5bc6\u805a\u5408\u534f\u8bae\u5b9e\u73b0\u9ad8\u6548\u80fd\u6548\u548c\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "6G\u7f51\u7edc\u5411\u8d85\u5bc6\u96c6\u667a\u80fd\u8fb9\u7f18\u73af\u5883\u53d1\u5c55\uff0c\u9700\u8981\u5728\u4e25\u683c\u9690\u79c1\u3001\u79fb\u52a8\u6027\u548c\u80fd\u8017\u7ea6\u675f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u7ba1\u7406\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u9762\u4e34\u9690\u79c1\u6cc4\u9732\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u8054\u90a6\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4f7f\u7528\u6df1\u5ea6\u5faa\u73afQ\u7f51\u7edc\u5b66\u4e60\u5206\u6563\u5316\u7b56\u7565\uff0c\u7ed3\u5408\u692d\u5706\u66f2\u7ebfDiffie Hellman\u5bc6\u94a5\u4ea4\u6362\u7684\u5b89\u5168\u805a\u5408\u534f\u8bae\u4fdd\u62a4\u9690\u79c1\uff0c\u5c06\u8d44\u6e90\u7ba1\u7406\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u591a\u667a\u80fd\u4f53\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660eFed-MARL\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u5ef6\u8fdf\u3001\u80fd\u6548\u548c\u516c\u5e73\u6027\u65b9\u9762\u4f18\u4e8e\u96c6\u4e2d\u5f0fMARL\u548c\u542f\u53d1\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u786e\u4fdd\u5f3a\u5927\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u5728\u52a8\u6001\u8d44\u6e90\u53d7\u96506G\u8fb9\u7f18\u7f51\u7edc\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "Fed-MARL\u6846\u67b6\u4e3a6G\u8fb9\u7f18\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u8d44\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u6027\u80fd\u6307\u6807\u5e76\u6ee1\u8db36G\u7279\u5b9a\u670d\u52a1\u8981\u6c42\uff0c\u5177\u6709\u5f88\u597d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.10164", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10164", "abs": "https://arxiv.org/abs/2509.10164", "authors": ["Hoshitaro Ohnishi", "Hideo Mukai"], "title": "A Symmetry-Integrated Approach to Surface Code Decoding", "comment": "12 pages, 6 figures", "summary": "Quantum error correction, which utilizes logical qubits that are encoded as\nredundant multiple physical qubits to find and correct errors in physical\nqubits, is indispensable for practical quantum computing. Surface code is\nconsidered to be a promising encoding method with a high error threshold that\nis defined by stabilizer generators. However, previous methods have suffered\nfrom the problem that the decoder acquires solely the error probability\ndistribution because of the non-uniqueness of correct prediction obtained from\nthe input. To circumvent this problem, we propose a technique to reoptimize the\ndecoder model by approximating syndrome measurements with a continuous function\nthat is mathematically interpolated by neural network. We evaluated the\nimprovement in accuracy of a multilayer perceptron based decoder for code\ndistances of 5 and 7 as well as for decoders based on convolutional and\nrecurrent neural networks and transformers for a code distance of 5. In all\ncases, the reoptimized decoder gave better accuracy than the original models,\ndemonstrating the universal effectiveness of the proposed method that is\nindependent of code distance or network architecture. These results suggest\nthat re-framing the problem of surface code decoding into a regression problem\nthat can be tackled by deep learning is a useful strategy.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u7efc\u5408\u6d4b\u91cf\u4f5c\u4e3a\u8fde\u7eed\u51fd\u6570\u6765\u91cd\u65b0\u4f18\u5316\u89e3\u7801\u5668\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u8868\u9762\u7801\u89e3\u7801\u7cbe\u5ea6", "motivation": "\u4f20\u7edf\u89e3\u7801\u5668\u53ea\u80fd\u83b7\u53d6\u8bef\u5dee\u6982\u7387\u5206\u5e03\uff0c\u56e0\u4e3a\u4ece\u8f93\u5165\u83b7\u5f97\u7684\u6b63\u786e\u9884\u6d4b\u4e0d\u552f\u4e00\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898", "method": "\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u5c06\u7efc\u5408\u6d4b\u91cf\u8fd1\u4f3c\u4e3a\u8fde\u7eed\u51fd\u6570\u8fdb\u884c\u6570\u5b66\u63d2\u503c\uff0c\u91cd\u65b0\u4f18\u5316\u89e3\u7801\u5668\u6a21\u578b", "result": "\u5728\u7801\u8ddd5\u548c7\u7684\u591a\u5c42\u611f\u77e5\u673a\u89e3\u7801\u5668\uff0c\u4ee5\u53ca\u5377\u79ef\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548cTransformer\u89e3\u7801\u5668\u4e0a\uff0c\u91cd\u65b0\u4f18\u5316\u7684\u89e3\u7801\u5668\u90fd\u6bd4\u539f\u59cb\u6a21\u578b\u7cbe\u5ea6\u66f4\u9ad8", "conclusion": "\u5c06\u8868\u9762\u7801\u89e3\u7801\u95ee\u9898\u91cd\u65b0\u6784\u5efa\u4e3a\u53ef\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u89e3\u51b3\u7684\u56de\u5f52\u95ee\u9898\u662f\u4e00\u4e2a\u6709\u6548\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u666e\u904d\u6709\u6548\u6027"}}
{"id": "2509.10004", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10004", "abs": "https://arxiv.org/abs/2509.10004", "authors": ["Ponhvoan Srey", "Xiaobao Wu", "Anh Tuan Luu"], "title": "Unsupervised Hallucination Detection by Inspecting Reasoning Processes", "comment": "To appear in EMNLP 2025", "summary": "Unsupervised hallucination detection aims to identify hallucinated content\ngenerated by large language models (LLMs) without relying on labeled data.\nWhile unsupervised methods have gained popularity by eliminating\nlabor-intensive human annotations, they frequently rely on proxy signals\nunrelated to factual correctness. This misalignment biases detection probes\ntoward superficial or non-truth-related aspects, limiting generalizability\nacross datasets and scenarios. To overcome these limitations, we propose IRIS,\nan unsupervised hallucination detection framework, leveraging internal\nrepresentations intrinsic to factual correctness. IRIS prompts the LLM to\ncarefully verify the truthfulness of a given statement, and obtain its\ncontextualized embedding as informative features for training. Meanwhile, the\nuncertainty of each response is considered a soft pseudolabel for truthfulness.\nExperimental results demonstrate that IRIS consistently outperforms existing\nunsupervised methods. Our approach is fully unsupervised, computationally low\ncost, and works well even with few training data, making it suitable for\nreal-time detection.", "AI": {"tldr": "IRIS\u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u5e7b\u89c9\u68c0\u6d4b\u6846\u67b6\uff0c\u5229\u7528LLM\u5185\u90e8\u8868\u793a\u6765\u8bc6\u522b\u751f\u6210\u5185\u5bb9\u7684\u4e8b\u5b9e\u6b63\u786e\u6027\uff0c\u65e0\u9700\u6807\u6ce8\u6570\u636e\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u4e14\u9002\u7528\u4e8e\u5b9e\u65f6\u68c0\u6d4b", "motivation": "\u73b0\u6709\u65e0\u76d1\u7763\u65b9\u6cd5\u4f9d\u8d56\u4e0e\u4e8b\u5b9e\u6b63\u786e\u6027\u65e0\u5173\u7684\u4ee3\u7406\u4fe1\u53f7\uff0c\u5bfc\u81f4\u68c0\u6d4b\u504f\u5411\u8868\u9762\u7279\u5f81\uff0c\u9650\u5236\u4e86\u8de8\u6570\u636e\u96c6\u548c\u573a\u666f\u7684\u6cdb\u5316\u80fd\u529b", "method": "\u901a\u8fc7\u63d0\u793aLLM\u4ed4\u7ec6\u9a8c\u8bc1\u7ed9\u5b9a\u9648\u8ff0\u7684\u771f\u5b9e\u6027\uff0c\u83b7\u53d6\u5176\u60c5\u5883\u5316\u5d4c\u5165\u4f5c\u4e3a\u7279\u5f81\uff0c\u5e76\u5c06\u6bcf\u4e2a\u54cd\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u771f\u5b9e\u6027\u7684\u8f6f\u4f2a\u6807\u7b7e", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eIRIS consistently outperforms existing unsupervised methods", "conclusion": "IRIS\u662f\u4e00\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u3001\u8ba1\u7b97\u6210\u672c\u4f4e\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u4e0b\u4e5f\u80fd\u826f\u597d\u5de5\u4f5c\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u5e7b\u89c9\u68c0\u6d4b"}}
{"id": "2509.10010", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.10010", "abs": "https://arxiv.org/abs/2509.10010", "authors": ["Adnan Ahmad", "Philine Kowol", "Stefan Hillmann", "Sebastian M\u00f6ller"], "title": "Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs", "comment": null, "summary": "In this paper, we provide an extensive analysis of multi-label intent\nclassification using Large Language Models (LLMs) that are open-source,\npublicly available, and can be run in consumer hardware. We use the MultiWOZ\n2.1 dataset, a benchmark in the dialogue system domain, to investigate the\nefficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,\nMistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot\nsetup, giving 20 examples in the prompt with some instructions. Our approach\nfocuses on the differences in performance of these models across several\nperformance metrics by methodically assessing these models on multi-label\nintent classification tasks. Additionally, we compare the performance of the\ninstruction-based fine-tuning approach with supervised learning using the\nsmaller transformer model BertForSequenceClassification as a baseline. To\nevaluate the performance of the models, we use evaluation metrics like\naccuracy, precision, and recall as well as micro, macro, and weighted F1 score.\nWe also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1\noutperforms two other generative models on 11 intent classes out of 14 in terms\nof F-Score, with a weighted average of 0.50. It also has relatively lower\nHumming Loss and higher Jaccard Similarity, making it the winning model in the\nfew-shot setting. We find BERT based supervised classifier having superior\nperformance compared to the best performing few-shot generative LLM. The study\nprovides a framework for small open-source LLMs in detecting complex\nmulti-intent dialogues, enhancing the Natural Language Understanding aspect of\ntask-oriented chatbots.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6807\u7b7e\u610f\u56fe\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\uff0c\u6bd4\u8f83\u4e86LLama2-7B\u3001Mistral-7B\u548cYi-6B\u5728MultiWOZ 2.1\u6570\u636e\u96c6\u4e0a\u7684few-shot\u8868\u73b0\uff0c\u5e76\u4e0eBERT\u76d1\u7763\u5b66\u4e60\u57fa\u7ebf\u5bf9\u6bd4\u3002", "motivation": "\u7814\u7a76\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u5904\u7406\u590d\u6742\u591a\u610f\u56fe\u5bf9\u8bdd\u5206\u7c7b\u4efb\u52a1\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4efb\u52a1\u5bfc\u5411\u804a\u5929\u673a\u5668\u4eba\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u63d0\u4f9b\u5b9e\u7528\u6846\u67b6\u3002", "method": "\u4f7f\u7528MultiWOZ 2.1\u6570\u636e\u96c6\uff0c\u5728few-shot\u8bbe\u7f6e\u4e0b\uff08\u63d0\u793a\u4e2d\u5305\u542b20\u4e2a\u793a\u4f8b\uff09\u6d4b\u8bd5\u4e09\u4e2a\u5f00\u6e90LLM\u6a21\u578b\uff0c\u5e76\u4e0e\u57fa\u4e8eBERT\u7684\u76d1\u7763\u5206\u7c7b\u5668\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548c\u591a\u79cdF1\u5206\u6570\u3002", "result": "Mistral-7B-v0.1\u572814\u4e2a\u610f\u56fe\u7c7b\u522b\u4e2d\u768411\u4e2a\u4e0aF\u5206\u6570\u8868\u73b0\u6700\u4f73\uff0c\u52a0\u6743\u5e73\u5747F\u5206\u6570\u4e3a0.50\uff0c\u5177\u6709\u8f83\u4f4e\u7684Hamming Loss\u548c\u8f83\u9ad8\u7684Jaccard\u76f8\u4f3c\u5ea6\u3002\u4f46BERT\u76d1\u7763\u5206\u7c7b\u5668\u7684\u6027\u80fd\u4ecd\u4f18\u4e8e\u6700\u4f73few-shot\u751f\u6210\u5f0fLLM\u3002", "conclusion": "\u5f00\u6e90LLM\u5728\u591a\u6807\u7b7e\u610f\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0cMistral-7B\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u4ecd\u5177\u6709\u6027\u80fd\u4f18\u52bf\u3002\u7814\u7a76\u4e3a\u5c0f\u89c4\u6a21\u5f00\u6e90LLM\u5728\u590d\u6742\u591a\u610f\u56fe\u5bf9\u8bdd\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u3002"}}
{"id": "2509.10248", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10248", "abs": "https://arxiv.org/abs/2509.10248", "authors": ["Janis Keuper"], "title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "comment": null, "summary": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u53d1\u73b0\uff1a\u7b80\u5355\u7684\u63d0\u793a\u8bcd\u6ce8\u5165\u653b\u51fb\u5728LLM\u79d1\u5b66\u8bc4\u5ba1\u4e2d\u6781\u5176\u6709\u6548\uff08\u53ef\u8fbe100%\u63a5\u53d7\u7387\uff09\uff0c\u4e14LLM\u8bc4\u5ba1\u666e\u904d\u5b58\u5728\u63a5\u53d7\u504f\u5411\uff08>95%\uff09\uff0c\u8fd9\u5bf9LLM\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u4f7f\u7528\u8ba8\u8bba\u5177\u6709\u91cd\u5927\u5f71\u54cd\u3002", "motivation": "\u9488\u5bf9\u4f5c\u8005\u4f7f\u7528\u9690\u85cf\u63d0\u793a\u8bcd\u6ce8\u5165\u64cd\u7eb5\u8bc4\u5ba1\u5206\u6570\u7684\u73b0\u8c61\uff0c\u7814\u7a76\u8fd9\u79cd\u653b\u51fb\u7684\u53ef\u884c\u6027\u548c\u6280\u672f\u6210\u529f\u7387\uff0c\u4ee5\u5f71\u54cd\u5173\u4e8eLLM\u5728\u79d1\u5b66\u540c\u884c\u8bc4\u5ba1\u4e2d\u4f7f\u7528\u7684\u6301\u7eed\u8ba8\u8bba\u3002", "method": "\u4f7f\u7528\u591a\u79cdLLM\u5bf92024\u5e74ICLR\u8bba\u6587\u76841000\u7bc7\u8bc4\u5ba1\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5206\u6790\u7b80\u5355\u63d0\u793a\u8bcd\u6ce8\u5165\u7684\u6548\u679c\u548cLLM\u8bc4\u5ba1\u7684\u504f\u5411\u6027\u3002", "result": "1) \u975e\u5e38\u7b80\u5355\u63d0\u793a\u8bcd\u6ce8\u5165\u9ad8\u5ea6\u6709\u6548\uff0c\u6700\u9ad8\u53ef\u8fbe100%\u63a5\u53d7\u7387\uff1b2) LLM\u8bc4\u5ba1\u666e\u904d\u504f\u5411\u63a5\u53d7\uff08\u8bb8\u591a\u6a21\u578b>95%\u63a5\u53d7\u7387\uff09\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5bf9LLM\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u4f7f\u7528\u8ba8\u8bba\u5177\u6709\u91cd\u5927\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u8bc4\u5ba1\u7cfb\u7edf\u7684\u8106\u5f31\u6027\u548c\u7cfb\u7edf\u6027\u504f\u5411\u95ee\u9898\u3002"}}
{"id": "2509.10078", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10078", "abs": "https://arxiv.org/abs/2509.10078", "authors": ["Dongmin Choi", "Woojung Song", "Jongwook Han", "Eun-Ju Lee", "Yohan Jo"], "title": "Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models", "comment": "17 pages, 4 figures", "summary": "Researchers have applied established psychometric questionnaires (e.g., BFI,\nPVQ) to measure the personality traits and values reflected in the responses of\nLarge Language Models (LLMs). However, concerns have been raised about applying\nthese human-designed questionnaires to LLMs. One such concern is their lack of\necological validity--the extent to which survey questions adequately reflect\nand resemble real-world contexts in which LLMs generate texts in response to\nuser queries. However, it remains unclear how established questionnaires and\necologically valid questionnaires differ in their outcomes, and what insights\nthese differences may provide. In this paper, we conduct a comprehensive\ncomparative analysis of the two types of questionnaires. Our analysis reveals\nthat established questionnaires (1) yield substantially different profiles of\nLLMs from ecologically valid ones, deviating from the psychological\ncharacteristics expressed in the context of user queries, (2) suffer from\ninsufficient items for stable measurement, (3) create misleading impressions\nthat LLMs possess stable constructs, and (4) yield exaggerated profiles for\npersona-prompted LLMs. Overall, our work cautions against the use of\nestablished psychological questionnaires for LLMs. Our code will be released\nupon publication.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4f20\u7edf\u5fc3\u7406\u6d4b\u91cf\u95ee\u5377\u4e0e\u751f\u6001\u6548\u5ea6\u95ee\u5377\u5728\u6d4b\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u4e2a\u6027\u7279\u5f81\u65f6\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u4f20\u7edf\u95ee\u5377\u5b58\u5728\u6d4b\u91cf\u4e0d\u7a33\u5b9a\u3001\u4ea7\u751f\u8bef\u5bfc\u6027\u7ed3\u679c\u7b49\u95ee\u9898\uff0c\u5efa\u8bae\u907f\u514d\u4f7f\u7528\u4f20\u7edf\u5fc3\u7406\u95ee\u5377\u8bc4\u4f30LLMs\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4f7f\u7528\u4eba\u7c7b\u8bbe\u8ba1\u7684\u5fc3\u7406\u95ee\u5377\uff08\u5982BFI\u3001PVQ\uff09\u6765\u6d4b\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u7279\u5f81\u548c\u4ef7\u503c\u89c2\uff0c\u4f46\u8fd9\u4e9b\u95ee\u5377\u7f3a\u4e4f\u751f\u6001\u6548\u5ea6\uff0c\u65e0\u6cd5\u53cd\u6620LLMs\u5728\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u573a\u666f\u4e2d\u7684\u6587\u672c\u751f\u6210\u7279\u6027\u3002\u9700\u8981\u660e\u786e\u4e24\u79cd\u95ee\u5377\u7684\u5dee\u5f02\u53ca\u5176\u63d0\u4f9b\u7684\u6d1e\u5bdf\u3002", "method": "\u5bf9\u4e24\u79cd\u7c7b\u578b\u7684\u95ee\u5377\u8fdb\u884c\u5168\u9762\u7684\u6bd4\u8f83\u5206\u6790\uff1a\u4f20\u7edf\u5fc3\u7406\u6d4b\u91cf\u95ee\u5377\u548c\u751f\u6001\u6548\u5ea6\u95ee\u5377\uff0c\u8bc4\u4f30\u5b83\u4eec\u5728\u6d4b\u91cfLLMs\u4e2a\u6027\u7279\u5f81\u65f6\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u5206\u6790\u53d1\u73b0\u4f20\u7edf\u95ee\u5377\u5b58\u5728\u56db\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u4e0e\u751f\u6001\u6548\u5ea6\u95ee\u5377\u4ea7\u751f\u663e\u8457\u4e0d\u540c\u7684LLMs\u7279\u5f81\u5256\u9762\uff1b2\uff09\u9879\u76ee\u6570\u91cf\u4e0d\u8db3\u5bfc\u81f4\u6d4b\u91cf\u4e0d\u7a33\u5b9a\uff1b3\uff09\u4ea7\u751fLLMs\u5177\u6709\u7a33\u5b9a\u6784\u5ff5\u7684\u8bef\u5bfc\u6027\u5370\u8c61\uff1b4\uff09\u5bf9\u89d2\u8272\u63d0\u793a\u7684LLMs\u4ea7\u751f\u5938\u5927\u7684\u7279\u5f81\u5256\u9762\u3002", "conclusion": "\u7814\u7a76\u8b66\u544a\u4e0d\u8981\u4f7f\u7528\u4f20\u7edf\u5fc3\u7406\u95ee\u5377\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5efa\u8bae\u5f00\u53d1\u66f4\u9002\u5408LLMs\u7279\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002\u4ee3\u7801\u5c06\u5728\u53d1\u8868\u540e\u53d1\u5e03\u3002"}}
{"id": "2509.10303", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10303", "abs": "https://arxiv.org/abs/2509.10303", "authors": ["Jesse van Remmerden", "Zaharah Bukhsh", "Yingqian Zhang"], "title": "Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data", "comment": null, "summary": "The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling\nProblem (FJSP), are canonical combinatorial optimization problems with\nwide-ranging applications in industrial operations. In recent years, many\nonline reinforcement learning (RL) approaches have been proposed to learn\nconstructive heuristics for JSP and FJSP. Although effective, these online RL\nmethods require millions of interactions with simulated environments that may\nnot capture real-world complexities, and their random policy initialization\nleads to poor sample efficiency. To address these limitations, we introduce\nConservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL\nalgorithm that learns effective scheduling policies directly from historical\ndata, eliminating the need for costly online interactions, while maintaining\nthe ability to improve upon suboptimal training data. CDQAC couples a\nquantile-based critic with a delayed policy update, estimating the return\ndistribution of each machine-operation pair rather than selecting pairs\noutright. Our extensive experiments demonstrate CDQAC's remarkable ability to\nlearn from diverse data sources. CDQAC consistently outperforms the original\ndata-generating heuristics and surpasses state-of-the-art offline and online RL\nbaselines. In addition, CDQAC is highly sample efficient, requiring only 10-20\ntraining instances to learn high-quality policies. Surprisingly, we find that\nCDQAC performs better when trained on data generated by a random heuristic than\nwhen trained on higher-quality data from genetic algorithms and priority\ndispatching rules.", "AI": {"tldr": "\u63d0\u51faCDQAC\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f4\u63a5\u4ece\u5386\u53f2\u6570\u636e\u5b66\u4e60\u4f5c\u4e1a\u8f66\u95f4\u8c03\u5ea6\u7b56\u7565\uff0c\u65e0\u9700\u5728\u7ebf\u4ea4\u4e92\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5728\u7ebfRL\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6a21\u62df\u73af\u5883\u4ea4\u4e92\u4e14\u6837\u672c\u6548\u7387\u4f4e\uff0c\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\uff0c\u9700\u8981\u76f4\u63a5\u4ece\u5386\u53f2\u6570\u636e\u5b66\u4e60\u8c03\u5ea6\u7b56\u7565\u7684\u65b9\u6cd5", "method": "CDQAC\u7b97\u6cd5\u7ed3\u5408\u5206\u4f4d\u6570critic\u548c\u5ef6\u8fdf\u7b56\u7565\u66f4\u65b0\uff0c\u4f30\u8ba1\u6bcf\u4e2a\u673a\u5668-\u64cd\u4f5c\u5bf9\u7684\u56de\u62a5\u5206\u5e03\u800c\u975e\u76f4\u63a5\u9009\u62e9\uff0c\u5b9e\u73b0\u79bb\u7ebf\u5b66\u4e60", "result": "CDQAC\u5728\u5404\u79cd\u6570\u636e\u6e90\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u59cb\u7ec8\u4f18\u4e8e\u539f\u59cb\u6570\u636e\u751f\u6210\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u79bb\u7ebf\u548c\u5728\u7ebfRL\u57fa\u7ebf\uff0c\u4ec5\u970010-20\u4e2a\u8bad\u7ec3\u5b9e\u4f8b\u5373\u53ef\u5b66\u4e60\u9ad8\u8d28\u91cf\u7b56\u7565", "conclusion": "CDQAC\u662f\u9ad8\u6548\u7684\u79bb\u7ebfRL\u8c03\u5ea6\u65b9\u6cd5\uff0c\u7279\u522b\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u4f7f\u7528\u968f\u673a\u542f\u53d1\u5f0f\u751f\u6210\u7684\u6570\u636e\u8bad\u7ec3\u6548\u679c\u4f18\u4e8e\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u548c\u4f18\u5148\u7ea7\u8c03\u5ea6\u89c4\u5219\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u6570\u636e"}}
{"id": "2509.10127", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10127", "abs": "https://arxiv.org/abs/2509.10127", "authors": ["Zhengyu Hu", "Zheyuan Xiao", "Max Xiong", "Yuxuan Lei", "Tianfu Wang", "Jianxun Lian", "Kaize Ding", "Ziang Xiao", "Nicholas Jing Yuan", "Xing Xie"], "title": "Population-Aligned Persona Generation for LLM-based Social Simulation", "comment": null, "summary": "Recent advances in large language models (LLMs) have enabled human-like\nsocial simulations at unprecedented scale and fidelity, offering new\nopportunities for computational social science. A key challenge, however, is\nthe construction of persona sets that authentically represent the diversity and\ndistribution of real-world populations. Most existing LLM-based social\nsimulation studies focus primarily on designing agentic frameworks and\nsimulation environments, often overlooking the complexities of persona\ngeneration and the potential biases introduced by unrepresentative persona\nsets. In this paper, we propose a systematic framework for synthesizing\nhigh-quality, population-aligned persona sets for LLM-driven social simulation.\nOur approach begins by leveraging LLMs to generate narrative personas from\nlong-term social media data, followed by rigorous quality assessment to filter\nout low-fidelity profiles. We then apply importance sampling to achieve global\nalignment with reference psychometric distributions, such as the Big Five\npersonality traits. To address the needs of specific simulation contexts, we\nfurther introduce a task-specific module that adapts the globally aligned\npersona set to targeted subpopulations. Extensive experiments demonstrate that\nour method significantly reduces population-level bias and enables accurate,\nflexible social simulation for a wide range of research and policy\napplications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4e0e\u4eba\u53e3\u5206\u5e03\u5bf9\u9f50\u7684LLM\u9a71\u52a8\u793e\u4ea4\u6a21\u62df\u89d2\u8272\u96c6\uff0c\u901a\u8fc7\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u751f\u6210\u3001\u8d28\u91cf\u8bc4\u4f30\u548c\u91cd\u8981\u6027\u91c7\u6837\u6765\u51cf\u5c11\u7fa4\u4f53\u504f\u89c1\u3002", "motivation": "\u73b0\u6709LLM\u793e\u4ea4\u6a21\u62df\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u667a\u80fd\u4f53\u6846\u67b6\u548c\u6a21\u62df\u73af\u5883\u8bbe\u8ba1\uff0c\u5f80\u5f80\u5ffd\u89c6\u89d2\u8272\u751f\u6210\u7684\u590d\u6742\u6027\u4ee5\u53ca\u975e\u4ee3\u8868\u6027\u89d2\u8272\u96c6\u5f15\u5165\u7684\u6f5c\u5728\u504f\u89c1\uff0c\u9700\u8981\u6784\u5efa\u80fd\u771f\u5b9e\u53cd\u6620\u73b0\u5b9e\u4eba\u7fa4\u591a\u6837\u6027\u548c\u5206\u5e03\u7684\u89d2\u8272\u96c6\u3002", "method": "\u5229\u7528LLM\u4ece\u957f\u671f\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u751f\u6210\u53d9\u4e8b\u89d2\u8272\uff0c\u8fdb\u884c\u4e25\u683c\u8d28\u91cf\u8bc4\u4f30\u7b5b\u9009\u4f4e\u8d28\u91cf\u6863\u6848\uff0c\u5e94\u7528\u91cd\u8981\u6027\u91c7\u6837\u5b9e\u73b0\u4e0e\u53c2\u8003\u5fc3\u7406\u6d4b\u91cf\u5206\u5e03\uff08\u5982\u5927\u4e94\u4eba\u683c\u7279\u8d28\uff09\u7684\u5168\u5c40\u5bf9\u9f50\uff0c\u5e76\u5f15\u5165\u4efb\u52a1\u7279\u5b9a\u6a21\u5757\u9488\u5bf9\u7279\u5b9a\u5b50\u4eba\u7fa4\u8fdb\u884c\u9002\u914d\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u7fa4\u4f53\u5c42\u9762\u7684\u504f\u89c1\uff0c\u80fd\u591f\u4e3a\u5e7f\u6cdb\u7684\u7814\u7a76\u548c\u653f\u7b56\u5e94\u7528\u5b9e\u73b0\u51c6\u786e\u3001\u7075\u6d3b\u7684\u793e\u4ea4\u6a21\u62df\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u6846\u67b6\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u4eba\u53e3\u5bf9\u9f50\u7684\u89d2\u8272\u96c6\uff0c\u6709\u6548\u89e3\u51b3LLM\u793e\u4ea4\u6a21\u62df\u4e2d\u7684\u4ee3\u8868\u6027\u504f\u5dee\u95ee\u9898\uff0c\u4e3a\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u6a21\u62df\u57fa\u7840\u3002"}}
{"id": "2509.10396", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10396", "abs": "https://arxiv.org/abs/2509.10396", "authors": ["Siyan Zhao", "Mengchen Liu", "Jing Huang", "Miao Liu", "Chenyu Wang", "Bo Liu", "Yuandong Tian", "Guan Pang", "Sean Bell", "Aditya Grover", "Feiyu Chen"], "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "comment": "preprint; 21 pages", "summary": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.", "AI": {"tldr": "IGPO\u662f\u4e00\u79cd\u9488\u5bf9\u63a9\u7801\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u90e8\u5206\u771f\u5b9e\u63a8\u7406\u8f68\u8ff9\u7684\u4fee\u590d\u5f15\u5bfc\u6765\u63d0\u5347\u63a2\u7d22\u6548\u7387\u548c\u6837\u672c\u5229\u7528\u7387\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86SOTA\u7ed3\u679c", "motivation": "\u89e3\u51b3\u4f20\u7edfRL\u65b9\u6cd5\u5728LLM\u5bf9\u9f50\u4e2d\u7684\u63a2\u7d22\u6311\u6218\uff0c\u5982\u7a00\u758f\u5956\u52b1\u548c\u6837\u672c\u6d6a\u8d39\u95ee\u9898\uff0c\u5229\u7528dLLM\u7684\u4fee\u590d\u80fd\u529b\u6765\u6307\u5bfc\u63a2\u7d22", "method": "\u63d0\u51faIGPO\u6846\u67b6\uff0c\u5728\u5728\u7ebf\u91c7\u6837\u4e2d\u7b56\u7565\u6027\u5730\u63d2\u5165\u90e8\u5206\u771f\u5b9e\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u71b5\u7684\u8fc7\u6ee4\u7b49\u6280\u672f", "result": "\u5728GSM8K\u3001Math500\u548cAMC\u4e09\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5168\u6ce8\u610f\u529b\u63a9\u7801dLLM\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c", "conclusion": "IGPO\u901a\u8fc7\u4fee\u590d\u5f15\u5bfc\u6709\u6548\u89e3\u51b3\u4e86RL\u63a2\u7d22\u6548\u7387\u95ee\u9898\uff0c\u4e3adLLM\u7684\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u65b9\u6cd5"}}
{"id": "2509.10208", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10208", "abs": "https://arxiv.org/abs/2509.10208", "authors": ["Shengqiang Fu"], "title": "SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning", "comment": null, "summary": "Large Language Models often generate unfaithful responses in knowledge\nintensive tasks due to knowledge conflict,that is,a preference for relying on\ninternal parametric knowledge rather than the provided context.To address this\nissue,we propose a novel self improving framework,Self Improving Faithfulness\nAware Contrastive Tuning.The framework uses a self instruct mechanism that\nallows the base LLM to automatically generate high quality,structured\ncontrastive learning data,including anchor samples,semantically equivalent\npositive samples,and negative samples simulating unfaithful scenarios.This\napproach significantly reduces the cost of manual\nannotation.Subsequently,contrastive learning is applied to train the\nmodel,enabling it to pull faithful responses closer and push unfaithful\nresponses farther apart in the representation space.Experiments on knowledge\nconflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT\nmodel based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%\nover the best baseline method,while significantly reducing dependence on\ninternal memory.The results indicate that SI FACT provides strong effectiveness\nand high data efficiency in enhancing the contextual faithfulness of\nLLMs,offering a practical pathway toward building more proactive and\ntrustworthy language models.", "AI": {"tldr": "\u63d0\u51faSelf Improving Faithfulness Aware Contrastive Tuning\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u6307\u5bfc\u673a\u5236\u81ea\u52a8\u751f\u6210\u5bf9\u6bd4\u5b66\u4e60\u6570\u636e\uff0c\u63d0\u5347LLM\u5728\u77e5\u8bc6\u51b2\u7a81\u4efb\u52a1\u4e2d\u7684\u5fe0\u5b9e\u6027", "motivation": "\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u56e0\u504f\u597d\u4f9d\u8d56\u5185\u90e8\u53c2\u6570\u77e5\u8bc6\u800c\u975e\u63d0\u4f9b\u4e0a\u4e0b\u6587\u800c\u5bfc\u81f4\u7684\u4e0d\u5fe0\u5b9e\u54cd\u5e94\u95ee\u9898", "method": "\u4f7f\u7528\u81ea\u6307\u5bfc\u673a\u5236\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u5bf9\u6bd4\u5b66\u4e60\u6570\u636e\uff08\u951a\u6837\u672c\u3001\u8bed\u4e49\u7b49\u4ef7\u6b63\u6837\u672c\u3001\u6a21\u62df\u4e0d\u5fe0\u5b9e\u573a\u666f\u7684\u8d1f\u6837\u672c\uff09\uff0c\u7136\u540e\u5e94\u7528\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b", "result": "\u5728ECARE KRE\u548cCOSE KRE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eLlama3 8B Instruct\u7684SI FACT\u6a21\u578b\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e0a\u4e0b\u6587\u53ec\u56de\u73876.2%\uff0c\u663e\u8457\u51cf\u5c11\u5bf9\u5185\u90e8\u8bb0\u5fc6\u7684\u4f9d\u8d56", "conclusion": "SI FACT\u5728\u589e\u5f3aLLM\u4e0a\u4e0b\u6587\u5fe0\u5b9e\u6027\u65b9\u9762\u5177\u6709\u5f3a\u6709\u6548\u6027\u548c\u9ad8\u6570\u636e\u6548\u7387\uff0c\u4e3a\u6784\u5efa\u66f4\u4e3b\u52a8\u548c\u53ef\u4fe1\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84"}}
{"id": "2509.10436", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10436", "abs": "https://arxiv.org/abs/2509.10436", "authors": ["Shadikur Rahman", "Aroosa Hameed", "Gautam Srivastava", "Syed Muhammad Danish"], "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment", "comment": "12 pages, 5 figures, submitted to IEEE Transactions on Services\n  Computing", "summary": "To optimize the reasoning and problem-solving capabilities of Large Language\nModels (LLMs), we propose a novel cloud-edge collaborative architecture that\nenables a structured, multi-agent prompting framework. This framework comprises\nthree specialized components: GuideLLM, a lightweight model deployed at the\nedge to provide methodological guidance; SolverLLM, a more powerful model\nhosted in the cloud responsible for generating code solutions; and JudgeLLM, an\nautomated evaluator for assessing solution correctness and quality. To evaluate\nand demonstrate the effectiveness of this architecture in realistic settings,\nwe introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate\nand enhance the performance of Large Language Models (LLMs) across multi-domain\ncoding tasks. Motivated by the limitations of existing benchmarks,\nRefactorCoderQA systematically covers various technical domains, including\nSoftware Engineering, Data Science, Machine Learning, and Natural Language\nProcessing, using authentic coding challenges from Stack Overflow. Extensive\nexperiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves\nstate-of-the-art performance, significantly outperforming leading open-source\nand commercial baselines with an overall accuracy of 76.84%. Human evaluations\nfurther validate the interpretability, accuracy, and practical relevance of the\ngenerated solutions. In addition, we evaluate system-level metrics, such as\nthroughput and latency, to gain deeper insights into the performance\ncharacteristics and trade-offs of the proposed architecture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e91\u8fb9\u534f\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u63d0\u793a\u6846\u67b6\uff0c\u5305\u542bGuideLLM\u3001SolverLLM\u548cJudgeLLM\u4e09\u4e2a\u7ec4\u4ef6\uff0c\u5e76\u521b\u5efa\u4e86RefactorCoderQA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u591a\u4e2a\u6280\u672f\u9886\u57df\u53d6\u5f97\u4e8676.84%\u7684\u6700\u4f18\u51c6\u786e\u7387\u3002", "motivation": "\u4e3a\u4e86\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u514b\u670d\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u67b6\u6784\u6765\u63d0\u5347\u591a\u9886\u57df\u7f16\u7a0b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e91\u8fb9\u534f\u4f5c\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u4e13\u95e8\u7ec4\u4ef6\uff1a\u8fb9\u7f18\u90e8\u7f72\u7684\u8f7b\u91cf\u7ea7GuideLLM\u63d0\u4f9b\u65b9\u6cd5\u6307\u5bfc\uff0c\u4e91\u7aefSolverLLM\u751f\u6210\u4ee3\u7801\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u53ca\u81ea\u52a8\u8bc4\u4f30\u5668JudgeLLM\u3002\u4f7f\u7528RefactorCoderQA\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5fae\u8c03\u6a21\u578bRefactorCoder-MoE\u5b9e\u73b0\u4e8676.84%\u7684\u6574\u4f53\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u9886\u5148\u7684\u5f00\u6e90\u548c\u5546\u4e1a\u57fa\u7ebf\u6a21\u578b\u3002\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u751f\u6210\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e91\u8fb9\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLMs\u7684\u7f16\u7a0b\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0cRefactorCoderQA\u57fa\u51c6\u4e3a\u591a\u9886\u57df\u7f16\u7801\u4efb\u52a1\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u7cfb\u7edf\u6027\u80fd\u6307\u6807\u5206\u6790\u63ed\u793a\u4e86\u67b6\u6784\u7684\u6027\u80fd\u7279\u5f81\u548c\u6743\u8861\u3002"}}
{"id": "2509.10446", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10446", "abs": "https://arxiv.org/abs/2509.10446", "authors": ["Rui Lu", "Zhenyu Hou", "Zihan Wang", "Hanchen Zhang", "Xiao Liu", "Yujiang Li", "Shi Feng", "Jie Tang", "Yuxiao Dong"], "title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL", "comment": null, "summary": "Augmenting large language models (LLMs) with browsing tools substantially\nimproves their potential as deep search agents to solve complex, real-world\ntasks. Yet, open LLMs still perform poorly in such settings due to limited\nlong-horizon reasoning capacity with browsing tools and the lack of\nsufficiently difficult supervised data. To address these challenges, we present\nDeepDive to advance deep search agents. First, we propose a strategy to\nautomatically synthesize complex, difficult, and hard-to-find questions from\nopen knowledge graphs. Second, we apply end-to-end multi-turn reinforcement\nlearning (RL) to enhance LLMs' long-horizon reasoning with deep search.\nExperiments show that DeepDive-32B achieves a new open-source competitive\nresult on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and\nSearch-o1. We demonstrate that multi-turn RL training improves deep search\nability and significantly contributes to the performance improvements across\nmultiple benchmarks. We observe that DeepDive enables test-time scaling of tool\ncalls and parallel sampling. All datasets, models, and code are publicly\navailable at https://github.com/THUDM/DeepDive.", "AI": {"tldr": "DeepDive\u662f\u4e00\u4e2a\u901a\u8fc7\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u6df1\u5ea6\u641c\u7d22\u80fd\u529b\u7684\u7cfb\u7edf\uff0c\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u81ea\u52a8\u5408\u6210\u590d\u6742\u95ee\u9898\uff0c\u5728BrowseComp\u57fa\u51c6\u4e0a\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u6700\u4f73\u6027\u80fd", "motivation": "\u89e3\u51b3\u73b0\u6709\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u641c\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u662f\u957f\u65f6\u7a0b\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u548c\u7f3a\u4e4f\u8db3\u591f\u96be\u5ea6\u7684\u76d1\u7763\u6570\u636e", "method": "1. \u4ece\u5f00\u653e\u77e5\u8bc6\u56fe\u8c31\u81ea\u52a8\u5408\u6210\u590d\u6742\u3001\u56f0\u96be\u4e14\u96be\u4ee5\u627e\u5230\u7684\u95ee\u9898\uff1b2. \u5e94\u7528\u7aef\u5230\u7aef\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u6765\u589e\u5f3aLLMs\u7684\u6df1\u5ea6\u641c\u7d22\u957f\u65f6\u7a0b\u63a8\u7406\u80fd\u529b", "result": "DeepDive-32B\u5728BrowseComp\u57fa\u51c6\u4e0a\u53d6\u5f97\u65b0\u7684\u5f00\u6e90\u7ade\u4e89\u6027\u7ed3\u679c\uff0c\u4f18\u4e8eWebSailor\u3001DeepSeek-R1-Browse\u548cSearch-o1\uff0c\u591a\u8f6eRL\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u641c\u7d22\u80fd\u529b", "conclusion": "DeepDive\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u8bad\u7ec3\u6570\u636e\u548c\u591a\u8f6eRL\u8bad\u7ec3\u6709\u6548\u63d0\u5347\u4e86LLMs\u7684\u6df1\u5ea6\u641c\u7d22\u80fd\u529b\uff0c\u652f\u6301\u5de5\u5177\u8c03\u7528\u548c\u5e76\u884c\u91c7\u6837\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u6240\u6709\u8d44\u6e90\u5df2\u5f00\u6e90"}}
