{"id": "2509.15283", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "I.2.7; F.2.2; I.2.2"], "pdf": "https://arxiv.org/pdf/2509.15283", "abs": "https://arxiv.org/abs/2509.15283", "authors": ["Kadin Matotek", "Heather Cassel", "Md Amiruzzaman", "Linh B. Ngo"], "title": "Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges", "comment": "Comments: 16 pages, 3 figures, 8 tables, accepted to CCSC Eastern\n  2025", "summary": "This study examines the performance of today's open-source, locally hosted\nlarge-language models (LLMs) in handling complex competitive programming tasks\nwith extended problem descriptions and contexts. Building on the original\nFramework for AI-driven Code Generation Evaluation (FACE), the authors retrofit\nthe pipeline to work entirely offline through the Ollama runtime, collapsing\nFACE's sprawling per-problem directory tree into a handful of consolidated JSON\nfiles, and adding robust checkpointing so multi-day runs can resume after\nfailures. The enhanced framework generates, submits, and records solutions for\nthe full Kattis corpus of 3,589 problems across eight code-oriented models\nranging from 6.7-9 billion parameters. The submission results show that the\noverall pass@1 accuracy is modest for the local models, with the best models\nperforming at approximately half the acceptance rate of the proprietary models,\nGemini 1.5 and ChatGPT-4. These findings expose a persistent gap between\nprivate, cost-controlled LLM deployments and state-of-the-art proprietary\nservices, yet also highlight the rapid progress of open models and the\npractical benefits of an evaluation workflow that organizations can replicate\non in-house hardware.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5f00\u6e90\u672c\u5730\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7f16\u7a0b\u7ade\u8d5b\u4efb\u52a1\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u6027\u80fd\u7ea6\u4e3a\u4e13\u6709\u6a21\u578b\u7684\u4e00\u534a\uff0c\u4f46\u5c55\u793a\u4e86\u5f00\u6e90\u6a21\u578b\u7684\u5feb\u901f\u8fdb\u6b65\u548c\u672c\u5730\u90e8\u7f72\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u8bc4\u4f30\u5f00\u6e90\u672c\u5730LLMs\u5728\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\uff0c\u6bd4\u8f83\u4e0e\u4e13\u6709\u6a21\u578b\u7684\u5dee\u8ddd\uff0c\u63a2\u7d22\u7ec4\u7ec7\u5185\u90e8\u53ef\u590d\u5236\u7684\u8bc4\u4f30\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u57fa\u4e8eFACE\u6846\u67b6\u6539\u9020\u4e3a\u5b8c\u5168\u79bb\u7ebf\u8fd0\u884c\u7684Ollama\u8fd0\u884c\u65f6\uff0c\u5c06\u76ee\u5f55\u7ed3\u6784\u7b80\u5316\u4e3aJSON\u6587\u4ef6\uff0c\u589e\u52a0\u68c0\u67e5\u70b9\u673a\u5236\uff0c\u5bf93,589\u4e2aKattis\u95ee\u9898\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6db5\u76d68\u4e2a6.7-90\u4ebf\u53c2\u6570\u7684\u4ee3\u7801\u5bfc\u5411\u6a21\u578b\u3002", "result": "\u672c\u5730\u6a21\u578b\u7684pass@1\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u6700\u4f73\u6a21\u578b\u6027\u80fd\u7ea6\u4e3aGemini 1.5\u548cChatGPT-4\u7b49\u4e13\u6709\u6a21\u578b\u63a5\u53d7\u7387\u7684\u4e00\u534a\u3002", "conclusion": "\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u670d\u52a1\u5b58\u5728\u660e\u663e\u5dee\u8ddd\uff0c\u4f46\u8fdb\u6b65\u8fc5\u901f\uff0c\u672c\u5730\u8bc4\u4f30\u5de5\u4f5c\u6d41\u7a0b\u5177\u6709\u5b9e\u7528\u4ef7\u503c\uff0c\u53ef\u5728\u7ec4\u7ec7\u5185\u90e8\u786c\u4ef6\u4e0a\u590d\u5236\u3002", "topic": "swe benchmark"}}
{"id": "2509.15237", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15237", "abs": "https://arxiv.org/abs/2509.15237", "authors": ["Di Wen", "Kunyu Peng", "Junwei Zheng", "Yufan Chen", "Yitain Shi", "Jiale Wei", "Ruiping Liu", "Kailun Yang", "Rainer Stiefelhagen"], "title": "MICA: Multi-Agent Industrial Coordination Assistant", "comment": "The source code will be made publicly available at\n  https://github.com/Kratos-Wen/MICA", "summary": "Industrial workflows demand adaptive and trustworthy assistance that can\noperate under limited computing, connectivity, and strict privacy constraints.\nIn this work, we present MICA (Multi-Agent Industrial Coordination Assistant),\na perception-grounded and speech-interactive system that delivers real-time\nguidance for assembly, troubleshooting, part queries, and maintenance. MICA\ncoordinates five role-specialized language agents, audited by a safety checker,\nto ensure accurate and compliant support. To achieve robust step understanding,\nwe introduce Adaptive Step Fusion (ASF), which dynamically blends expert\nreasoning with online adaptation from natural speech feedback. Furthermore, we\nestablish a new multi-agent coordination benchmark across representative task\ncategories and propose evaluation metrics tailored to industrial assistance,\nenabling systematic comparison of different coordination topologies. Our\nexperiments demonstrate that MICA consistently improves task success,\nreliability, and responsiveness over baseline structures, while remaining\ndeployable on practical offline hardware. Together, these contributions\nhighlight MICA as a step toward deployable, privacy-preserving multi-agent\nassistants for dynamic factory environments. The source code will be made\npublicly available at https://github.com/Kratos-Wen/MICA.", "AI": {"tldr": "MICA\u662f\u4e00\u4e2a\u9762\u5411\u5de5\u4e1a\u73af\u5883\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u52a9\u624b\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u97f3\u4ea4\u4e92\u63d0\u4f9b\u5b9e\u65f6\u6307\u5bfc\uff0c\u5305\u542b\u4e94\u4e2a\u89d2\u8272\u4e13\u4e1a\u5316\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u6b65\u9aa4\u878d\u5408\u6280\u672f\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u79bb\u7ebf\u786c\u4ef6\u4e0a\u5b9e\u73b0\u90e8\u7f72\u3002", "motivation": "\u5de5\u4e1a\u5de5\u4f5c\u6d41\u9700\u8981\u80fd\u591f\u5728\u6709\u9650\u8ba1\u7b97\u3001\u8fde\u63a5\u6027\u548c\u4e25\u683c\u9690\u79c1\u7ea6\u675f\u4e0b\u8fd0\u884c\u7684\u9002\u5e94\u6027\u5f3a\u7684\u53ef\u4fe1\u52a9\u624b\u7cfb\u7edf\u3002", "method": "MICA\u534f\u8c03\u4e94\u4e2a\u89d2\u8272\u4e13\u4e1a\u5316\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5b89\u5168\u68c0\u67e5\u5668\u5ba1\u6838\u786e\u4fdd\u51c6\u786e\u6027\u3002\u5f15\u5165\u81ea\u9002\u5e94\u6b65\u9aa4\u878d\u5408\u6280\u672f\u52a8\u6001\u878d\u5408\u4e13\u5bb6\u63a8\u7406\u4e0e\u81ea\u7136\u8bed\u97f3\u53cd\u9988\u7684\u5728\u7ebf\u9002\u5e94\u3002\u5efa\u7acb\u65b0\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u57fa\u51c6\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMICA\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u53ef\u9760\u6027\u548c\u54cd\u5e94\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u7ed3\u6784\uff0c\u540c\u65f6\u53ef\u5728\u5b9e\u9645\u79bb\u7ebf\u786c\u4ef6\u4e0a\u90e8\u7f72\u3002", "conclusion": "MICA\u662f\u5411\u53ef\u90e8\u7f72\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u591a\u667a\u80fd\u4f53\u52a9\u624b\u5728\u52a8\u6001\u5de5\u5382\u73af\u5883\u4e2d\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\u3002", "topic": "agent analysis"}}
{"id": "2509.15397", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15397", "abs": "https://arxiv.org/abs/2509.15397", "authors": ["Simantika Bhattacharjee Dristi", "Matthew B. Dwyer"], "title": "LoCaL: Countering Surface Bias in Code Evaluation Metrics", "comment": null, "summary": "With the increasing popularity of large language models (LLMs) and LLM-based\nagents, reliable and effective code evaluation metrics (CEMs) have become\ncrucial for progress across several software engineering tasks. While popular\nbenchmarks often provide test cases to assess the correctness of generated\ncode, crafting and executing test cases is expensive. Reference-based CEMs\nprovide a cheaper alternative by scoring a candidate program based on its\nfunctional similarity to a reference. Although prior research has focused on\nreporting the weak correlation between these CEMs and functional correctness,\nthe causes are only assumed, and plausible solutions remain unexplored. In this\nwork, we critically evaluate four state-of-the-art reference-based CEMs,\nrevealing their strong bias towards surface-level features rather than code\nfunctionality. Despite this surface bias, current evaluation datasets for these\nCEMs rarely include code pairs that are surface-similar yet functionally\ndissimilar, or functionally similar yet surface-dissimilar. To mitigate this\ngap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117\ncode pairs at both the method and program levels. Each pair is labeled with a\nfunctional similarity score and aims to target regions where CEMs are likely to\nperform poorly. The functional similarity scores are calculated through\ndifferential fuzzing, which eliminates the need for predefined test cases and,\nat the same time, improves the reliability of the scores by executing an order\nof magnitude more tests than prior work. We find that all four CEMs show\nsignificant performance degradation on LoCaL, compared to the baselines.\nFinally, based on our findings, we draw the implication that exposing CEMs to\nLoCaL-like data might facilitate the development of metrics that are robust to\nsurface bias.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86LoCaL\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u53c2\u8003\u7684\u4ee3\u7801\u8bc4\u4f30\u6307\u6807\uff08CEMs\uff09\u7684\u529f\u80fd\u76f8\u4f3c\u6027\u5224\u65ad\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709CEMs\u5b58\u5728\u8868\u9762\u7279\u5f81\u504f\u89c1\uff0c\u5728\u529f\u80fd\u76f8\u4f3c\u4f46\u8868\u9762\u4e0d\u540c\u6216\u8868\u9762\u76f8\u4f3c\u4f46\u529f\u80fd\u4e0d\u540c\u7684\u4ee3\u7801\u5bf9\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u968f\u7740LLM\u548c\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u65e5\u76ca\u6d41\u884c\uff0c\u53ef\u9760\u7684\u4ee3\u7801\u8bc4\u4f30\u6307\u6807\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u73b0\u6709\u7814\u7a76\u5df2\u62a5\u544aCEMs\u4e0e\u529f\u80fd\u6b63\u786e\u6027\u4e4b\u95f4\u7684\u5f31\u76f8\u5173\u6027\uff0c\u4f46\u5176\u539f\u56e0\u4ec5\u88ab\u5047\u8bbe\uff0c\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u8ba1\u7b97\u529f\u80fd\u76f8\u4f3c\u6027\u5206\u6570\uff0c\u6784\u5efa\u5305\u542b3117\u4e2a\u4ee3\u7801\u5bf9\u7684LoCaL\u57fa\u51c6\uff0c\u8fd9\u4e9b\u4ee3\u7801\u5bf9\u9488\u5bf9CEMs\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\u7684\u533a\u57df\u8bbe\u8ba1\uff0c\u5305\u62ec\u65b9\u6cd5\u7ea7\u548c\u7a0b\u5e8f\u7ea7\u4ee3\u7801\u3002", "result": "\u56db\u79cd\u6700\u5148\u8fdb\u7684CEMs\u5728LoCaL\u57fa\u51c6\u4e0a\u5747\u8868\u73b0\u51fa\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6570\u636e\u96c6\u6027\u80fd\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "\u5c06CEMs\u66b4\u9732\u4e8eLoCaL\u7c7b\u6570\u636e\u53ef\u80fd\u6709\u52a9\u4e8e\u5f00\u53d1\u5bf9\u8868\u9762\u504f\u89c1\u5177\u6709\u9c81\u68d2\u6027\u7684\u8bc4\u4f30\u6307\u6807\u3002", "topic": "swe benchmark"}}
{"id": "2509.15269", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15269", "abs": "https://arxiv.org/abs/2509.15269", "authors": ["Elisabetta Rocchetti"], "title": "Modeling Transformers as complex networks to analyze learning dynamics", "comment": null, "summary": "The process by which Large Language Models (LLMs) acquire complex\ncapabilities during training remains a key open question in mechanistic\ninterpretability. This project investigates whether these learning dynamics can\nbe characterized through the lens of Complex Network Theory (CNT). I introduce\na novel methodology to represent a Transformer-based LLM as a directed,\nweighted graph where nodes are the model's computational components (attention\nheads and MLPs) and edges represent causal influence, measured via an\nintervention-based ablation technique. By tracking the evolution of this\ncomponent-graph across 143 training checkpoints of the Pythia-14M model on a\ncanonical induction task, I analyze a suite of graph-theoretic metrics. The\nresults reveal that the network's structure evolves through distinct phases of\nexploration, consolidation, and refinement. Specifically, I identify the\nemergence of a stable hierarchy of information spreader components and a\ndynamic set of information gatherer components, whose roles reconfigure at key\nlearning junctures. This work demonstrates that a component-level network\nperspective offers a powerful macroscopic lens for visualizing and\nunderstanding the self-organizing principles that drive the formation of\nfunctional circuits in LLMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u590d\u6742\u7f51\u7edc\u7406\u8bba\u5206\u6790LLM\u8bad\u7ec3\u52a8\u6001\uff0c\u5c06Transformer\u6a21\u578b\u8868\u793a\u4e3a\u6709\u5411\u52a0\u6743\u56fe\uff0c\u8ffd\u8e2aPythia-14M\u6a21\u578b\u5728\u5f52\u7eb3\u4efb\u52a1\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u7f51\u7edc\u7ed3\u6784\u6f14\u5316\u3002", "motivation": "\u7406\u89e3LLM\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5982\u4f55\u83b7\u5f97\u590d\u6742\u80fd\u529b\u662f\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7684\u5173\u952e\u5f00\u653e\u95ee\u9898\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u590d\u6742\u7f51\u7edc\u7406\u8bba\u89c6\u89d2\u6765\u8868\u5f81\u8fd9\u4e9b\u5b66\u4e60\u52a8\u6001\u3002", "method": "\u5f15\u5165\u65b0\u65b9\u6cd5\u5c06\u57fa\u4e8eTransformer\u7684LLM\u8868\u793a\u4e3a\u6709\u5411\u52a0\u6743\u56fe\uff08\u8282\u70b9\u4e3a\u8ba1\u7b97\u7ec4\u4ef6\uff0c\u8fb9\u8868\u793a\u56e0\u679c\u5f71\u54cd\uff09\uff0c\u5728143\u4e2a\u8bad\u7ec3\u68c0\u67e5\u70b9\u4e0a\u5206\u6790\u56fe\u8bba\u6307\u6807\u3002", "result": "\u53d1\u73b0\u7f51\u7edc\u7ed3\u6784\u7ecf\u5386\u63a2\u7d22\u3001\u5de9\u56fa\u548c\u7cbe\u70bc\u4e09\u4e2a\u9636\u6bb5\u7684\u6f14\u5316\uff0c\u8bc6\u522b\u51fa\u7a33\u5b9a\u7684\u4fe1\u606f\u4f20\u64ad\u7ec4\u4ef6\u5c42\u6b21\u7ed3\u6784\u548c\u52a8\u6001\u7684\u4fe1\u606f\u6536\u96c6\u7ec4\u4ef6\u96c6\u5408\u3002", "conclusion": "\u7ec4\u4ef6\u7ea7\u7f51\u7edc\u89c6\u89d2\u4e3a\u53ef\u89c6\u5316\u548c\u7406\u89e3LLM\u4e2d\u529f\u80fd\u7535\u8def\u5f62\u6210\u7684\u81ea\u7ec4\u7ec7\u539f\u5219\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b8f\u89c2\u89c6\u89d2\u3002", "topic": "agent analysis"}}
{"id": "2509.15567", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15567", "abs": "https://arxiv.org/abs/2509.15567", "authors": ["Hongyu Kuang", "Ning Zhang", "Hui Gao", "Xin Zhou", "Wesley K. G. Assun\u00e7\u00e3o", "Xiaoxing Ma", "Dong Shao", "Guoping Rong", "He Zhang"], "title": "Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation", "comment": null, "summary": "Commit messages are valuable resources for describing why code changes are\ncommitted to repositories in version control systems (e.g., Git). They\neffectively help developers understand code changes and better perform software\nmaintenance tasks. Unfortunately, developers often neglect to write\nhigh-quality commit messages in practice. Therefore, a growing body of work is\nproposed to generate commit messages automatically. These works all\ndemonstrated that how to organize and represent code changes is vital in\ngenerating good commit messages, including the use of fine-grained graphs or\nembeddings to better represent code changes. In this study, we choose an\nalternative way to condense code changes before generation, i.e., proposing\nbrief yet concise text templates consisting of the following three parts: (1)\nsummarized code changes, (2) elicited comments, and (3) emphasized code\nidentifiers. Specifically, we first condense code changes by using our proposed\ntemplates with the help of a heuristic-based tool named ChangeScribe, and then\nfine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding\ncommit messages. Our proposed templates better utilize pre-trained language\nmodels, while being naturally brief and readable to complement generated commit\nmessages for developers. Our evaluation based on a widely used dataset showed\nthat our approach can outperform six baselines in terms of BLEU-Norm, METEOR,\nand ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,\nrespectively. The ablation study and human evaluation also provide further\ninsights into the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6587\u672c\u6a21\u677f\u7684\u63d0\u4ea4\u4fe1\u606f\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u603b\u7ed3\u4ee3\u7801\u53d8\u66f4\u3001\u63d0\u53d6\u6ce8\u91ca\u548c\u5f3a\u8c03\u4ee3\u7801\u6807\u8bc6\u7b26\u6765\u538b\u7f29\u4ee3\u7801\u53d8\u66f4\u4fe1\u606f\uff0c\u7136\u540e\u5fae\u8c03CodeLlama-7B\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u63d0\u4ea4\u4fe1\u606f\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\u7ecf\u5e38\u5ffd\u89c6\u7f16\u5199\u9ad8\u8d28\u91cf\u7684\u63d0\u4ea4\u4fe1\u606f\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u66f4\u597d\u5730\u8868\u793a\u4ee3\u7801\u53d8\u66f4\u3002\u672c\u7814\u7a76\u9009\u62e9\u901a\u8fc7\u6587\u672c\u6a21\u677f\u6765\u538b\u7f29\u4ee3\u7801\u53d8\u66f4\u4fe1\u606f\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u9996\u5148\u4f7f\u7528\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684ChangeScribe\u5de5\u5177\u5c06\u4ee3\u7801\u53d8\u66f4\u538b\u7f29\u4e3a\u5305\u542b\u4e09\u90e8\u5206\u7684\u6587\u672c\u6a21\u677f\uff1a(1)\u603b\u7ed3\u7684\u4ee3\u7801\u53d8\u66f4\u3001(2)\u63d0\u53d6\u7684\u6ce8\u91ca\u3001(3)\u5f3a\u8c03\u7684\u4ee3\u7801\u6807\u8bc6\u7b26\u3002\u7136\u540e\u4f7f\u7528\u8fd9\u4e9b\u6a21\u677f\u4e0e\u5bf9\u5e94\u63d0\u4ea4\u4fe1\u606f\u5bf9\u6765\u5fae\u8c03CodeLlama-7B\u6a21\u578b\u3002", "result": "\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728BLEU-Norm\u3001METEOR\u548cROUGE-L\u6307\u6807\u4e0a\u4f18\u4e8e\u516d\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u6539\u8fdb\u5206\u522b\u4e3a51.7%\u300178.7%\u548c62.5%\u3002\u6d88\u878d\u7814\u7a76\u548c\u4eba\u5de5\u8bc4\u4f30\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6587\u672c\u6a21\u677f\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u7b80\u6d01\u53ef\u8bfb\u6027\uff0c\u4e3a\u5f00\u53d1\u8005\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u63d0\u4ea4\u4fe1\u606f\u63d0\u4f9b\u4e86\u6709\u6548\u8865\u5145\u3002", "topic": "swe application"}}
{"id": "2509.15291", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.15291", "abs": "https://arxiv.org/abs/2509.15291", "authors": ["Federico Taschin", "Abderrahmane Lazaraq", "Ozan K. Tonguz", "Inci Ozgunes"], "title": "The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI", "comment": null, "summary": "The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart\ntransportation networks has increased significantly in the last few years.\nAmong these ML and AI approaches, Reinforcement Learning (RL) has been shown to\nbe a very promising approach by several authors. However, a problem with using\nReinforcement Learning in Traffic Signal Control is the reliability of the\ntrained RL agents due to the dynamically changing distribution of the input\ndata with respect to the distribution of the data used for training. This\npresents a major challenge and a reliability problem for the trained network of\nAI agents and could have very undesirable and even detrimental consequences if\na suitable solution is not found. Several researchers have tried to address\nthis problem using different approaches. In particular, Meta Reinforcement\nLearning (Meta RL) promises to be an effective solution. In this paper, we\nevaluate and analyze a state-of-the-art Meta RL approach called MetaLight and\nshow that, while under certain conditions MetaLight can indeed lead to\nreasonably good results, under some other conditions it might not perform well\n(with errors of up to 22%), suggesting that Meta RL schemes are often not\nrobust enough and can even pose major reliability problems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86MetaLight\u8fd9\u4e00\u6700\u5148\u8fdb\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u867d\u7136\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5176\u4ed6\u6761\u4ef6\u4e0b\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\uff08\u8bef\u5dee\u9ad8\u8fbe22%\uff09\uff0c\u8868\u660e\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\u901a\u5e38\u4e0d\u591f\u9c81\u68d2\u3002", "motivation": "\u5728\u667a\u80fd\u4ea4\u901a\u7f51\u7edc\u4e2d\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u8bad\u7ec3\u4ee3\u7406\u53ef\u9760\u6027\u95ee\u9898\uff0c\u56e0\u4e3a\u8f93\u5165\u6570\u636e\u7684\u52a8\u6001\u53d8\u5316\u4e0e\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\uff0c\u8fd9\u53ef\u80fd\u5e26\u6765\u4e25\u91cd\u540e\u679c\u3002\u5143\u5f3a\u5316\u5b66\u4e60\u88ab\u8ba4\u4e3a\u662f\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bc4\u4f30\u548c\u5206\u6790MetaLight\u8fd9\u4e00\u6700\u5148\u8fdb\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684\u8868\u73b0\u3002", "result": "MetaLight\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u80fd\u4ea7\u751f\u76f8\u5f53\u597d\u7684\u7ed3\u679c\uff0c\u4f46\u5728\u5176\u4ed6\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u8bef\u5dee\u53ef\u8fbe22%\uff0c\u8868\u660e\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\u9c81\u68d2\u6027\u4e0d\u8db3\u3002", "conclusion": "\u5143\u5f3a\u5316\u5b66\u4e60\u65b9\u6848\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u53ef\u80fd\u4e0d\u591f\u53ef\u9760\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u786e\u4fdd\u5176\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002", "topic": "agent analysis"}}
{"id": "2509.15336", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15336", "abs": "https://arxiv.org/abs/2509.15336", "authors": ["Humam Kourani", "Anton Antonov", "Alessandro Berti", "Wil M. P. van der Aalst"], "title": "Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling", "comment": "The Version of Record of this contribution will be published in the\n  proceedings of the 2nd International Workshop on Generative AI for Process\n  Mining (GenAI4PM 2025). This preprint has not undergone peer review or any\n  post-submission improvements or corrections", "summary": "The utility of Large Language Models (LLMs) in analytical tasks is rooted in\ntheir vast pre-trained knowledge, which allows them to interpret ambiguous\ninputs and infer missing information. However, this same capability introduces\na critical risk of what we term knowledge-driven hallucination: a phenomenon\nwhere the model's output contradicts explicit source evidence because it is\noverridden by the model's generalized internal knowledge. This paper\ninvestigates this phenomenon by evaluating LLMs on the task of automated\nprocess modeling, where the goal is to generate a formal business process model\nfrom a given source artifact. The domain of Business Process Management (BPM)\nprovides an ideal context for this study, as many core business processes\nfollow standardized patterns, making it likely that LLMs possess strong\npre-trained schemas for them. We conduct a controlled experiment designed to\ncreate scenarios with deliberate conflict between provided evidence and the\nLLM's background knowledge. We use inputs describing both standard and\ndeliberately atypical process structures to measure the LLM's fidelity to the\nprovided evidence. Our work provides a methodology for assessing this critical\nreliability issue and raises awareness of the need for rigorous validation of\nAI-generated artifacts in any evidence-based domain.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76LLMs\u5728\u77e5\u8bc6\u9a71\u52a8\u5e7b\u89c9\u65b9\u9762\u7684\u98ce\u9669\uff0c\u5373\u5728\u81ea\u52a8\u5316\u6d41\u7a0b\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u8f93\u51fa\u4f1a\u56e0\u5185\u90e8\u77e5\u8bc6\u8986\u76d6\u800c\u8fdd\u80cc\u660e\u786e\u8bc1\u636e\u6e90\u3002", "motivation": "LLMs\u7684\u9884\u8bad\u7ec3\u77e5\u8bc6\u4f7f\u5176\u80fd\u89e3\u91ca\u6a21\u7cca\u8f93\u5165\u548c\u63a8\u65ad\u7f3a\u5931\u4fe1\u606f\uff0c\u4f46\u8fd9\u4e5f\u5e26\u6765\u4e86\u77e5\u8bc6\u9a71\u52a8\u5e7b\u89c9\u7684\u98ce\u9669\u2014\u2014\u6a21\u578b\u8f93\u51fa\u4f1a\u56e0\u5185\u90e8\u77e5\u8bc6\u800c\u8fdd\u80cc\u660e\u786e\u8bc1\u636e\u6e90\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30LLMs\u5728\u81ea\u52a8\u5316\u6d41\u7a0b\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bbe\u8ba1\u63a7\u5236\u5b9e\u9a8c\u521b\u5efa\u8bc1\u636e\u4e0e\u80cc\u666f\u77e5\u8bc6\u51b2\u7a81\u7684\u573a\u666f\uff0c\u4f7f\u7528\u6807\u51c6\u548c\u975e\u5178\u578b\u6d41\u7a0b\u7ed3\u6784\u8f93\u5165\u6765\u8861\u91cfLLMs\u5bf9\u8bc1\u636e\u7684\u5fe0\u5b9e\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u5728BPM\u9886\u57df\u786e\u5b9e\u5b58\u5728\u77e5\u8bc6\u9a71\u52a8\u5e7b\u89c9\u73b0\u8c61\uff0c\u5f53\u63d0\u4f9b\u7684\u8bc1\u636e\u4e0e\u6a21\u578b\u9884\u8bad\u7ec3\u77e5\u8bc6\u51b2\u7a81\u65f6\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u4f9d\u8d56\u5185\u90e8\u77e5\u8bc6\u800c\u975e\u9075\u5faa\u660e\u786e\u8bc1\u636e\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u8bc4\u4f30\u8fd9\u4e00\u5173\u952e\u53ef\u9760\u6027\u95ee\u9898\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u5f3a\u8c03\u5728\u4efb\u4f55\u57fa\u4e8e\u8bc1\u636e\u7684\u9886\u57df\u90fd\u9700\u8981\u5bf9AI\u751f\u6210\u7269\u8fdb\u884c\u4e25\u683c\u9a8c\u8bc1\u3002", "topic": "agent analysis"}}
{"id": "2509.15971", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2509.15971", "abs": "https://arxiv.org/abs/2509.15971", "authors": ["Owen Truong", "Terrence Zhang", "Arnav Marchareddy", "Ryan Lee", "Jeffery Busold", "Michael Socas", "Eman Abdullah AlOmar"], "title": "LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine Learning Pipelines", "comment": null, "summary": "In software development environments, code quality is crucial. This study\naims to assist Machine Learning (ML) engineers in enhancing their code by\nidentifying and correcting Data Leakage issues within their models. Data\nLeakage occurs when information from the test dataset is inadvertently included\nin the training data when preparing a data science model, resulting in\nmisleading performance evaluations. ML developers must carefully separate their\ndata into training, evaluation, and test sets to avoid introducing Data Leakage\ninto their code. In this paper, we develop a new Visual Studio Code (VS Code)\nextension, called LeakageDetector, that detects Data Leakage, mainly Overlap,\nPreprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond\ndetection, we included two correction mechanisms: a conventional approach,\nknown as a quick fix, which manually fixes the leakage, and an LLM-driven\napproach that guides ML developers toward best practices for building ML\npipelines.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aLeakageDetector\u7684VS Code\u6269\u5c55\uff0c\u7528\u4e8e\u68c0\u6d4bJupyter Notebook\u4e2d\u7684\u6570\u636e\u6cc4\u6f0f\u95ee\u9898\uff0c\u5e76\u63d0\u4f9b\u4e24\u79cd\u4fee\u590d\u673a\u5236\u3002", "motivation": "\u5e2e\u52a9\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u8bc6\u522b\u548c\u7ea0\u6b63\u6570\u636e\u6cc4\u6f0f\u95ee\u9898\uff0c\u907f\u514d\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u5931\u771f\u3002\u6570\u636e\u6cc4\u6f0f\u4f1a\u5bfc\u81f4\u6d4b\u8bd5\u6570\u636e\u96c6\u4fe1\u606f\u610f\u5916\u5305\u542b\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u3002", "method": "\u5f00\u53d1VS Code\u6269\u5c55\uff0c\u68c0\u6d4b\u4e09\u79cd\u4e3b\u8981\u6570\u636e\u6cc4\u6f0f\u7c7b\u578b\uff08\u91cd\u53e0\u6cc4\u6f0f\u3001\u9884\u5904\u7406\u6cc4\u6f0f\u3001\u591a\u6d4b\u8bd5\u6cc4\u6f0f\uff09\uff0c\u63d0\u4f9b\u4f20\u7edf\u5feb\u901f\u4fee\u590d\u548cLLM\u9a71\u52a8\u7684\u4fee\u590d\u6307\u5bfc\u3002", "result": "\u521b\u5efa\u4e86LeakageDetector\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u6570\u636e\u6cc4\u6f0f\u5e76\u63d0\u4f9b\u4fee\u590d\u65b9\u6848\u3002", "conclusion": "\u8be5\u5de5\u5177\u80fd\u5e2e\u52a9ML\u5f00\u53d1\u8005\u66f4\u597d\u5730\u6784\u5efa\u673a\u5668\u5b66\u4e60\u7ba1\u9053\uff0c\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u3002", "topic": "swe application"}}
{"id": "2509.15350", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.15350", "abs": "https://arxiv.org/abs/2509.15350", "authors": ["Yitong Wang", "Zhongping Zhang", "Margherita Piana", "Zheng Zhou", "Peter Gerstoft", "Bryan A. Plummer"], "title": "Real, Fake, or Manipulated? Detecting Machine-Influenced Text", "comment": "Accepted to EMNLP 2025 Findings", "summary": "Large Language Model (LLMs) can be used to write or modify documents,\npresenting a challenge for understanding the intent behind their use. For\nexample, benign uses may involve using LLM on a human-written document to\nimprove its grammar or to translate it into another language. However, a\ndocument entirely produced by a LLM may be more likely to be used to spread\nmisinformation than simple translation (\\eg, from use by malicious actors or\nsimply by hallucinating). Prior works in Machine Generated Text (MGT) detection\nmostly focus on simply identifying whether a document was human or machine\nwritten, ignoring these fine-grained uses. In this paper, we introduce a\nHiErarchical, length-RObust machine-influenced text detector (HERO), which\nlearns to separate text samples of varying lengths from four primary types:\nhuman-written, machine-generated, machine-polished, and machine-translated.\nHERO accomplishes this by combining predictions from length-specialist models\nthat have been trained with Subcategory Guidance. Specifically, for categories\nthat are easily confused (\\eg, different source languages), our Subcategory\nGuidance module encourages separation of the fine-grained categories, boosting\nperformance. Extensive experiments across five LLMs and six domains demonstrate\nthe benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on\naverage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HERO\u6a21\u578b\uff0c\u7528\u4e8e\u7ec6\u7c92\u5ea6\u68c0\u6d4b\u673a\u5668\u5f71\u54cd\u6587\u672c\u7684\u56db\u79cd\u7c7b\u578b\uff1a\u4eba\u5de5\u64b0\u5199\u3001\u673a\u5668\u751f\u6210\u3001\u673a\u5668\u6da6\u8272\u548c\u673a\u5668\u7ffb\u8bd1\uff0c\u901a\u8fc7\u957f\u5ea6\u4e13\u7528\u6a21\u578b\u548c\u5b50\u7c7b\u522b\u6307\u5bfc\u6a21\u5757\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u533a\u5206\u4eba\u5de5\u4e0e\u673a\u5668\u64b0\u5199\uff0c\u5ffd\u7565\u4e86\u673a\u5668\u5f71\u54cd\u6587\u672c\u7684\u7ec6\u7c92\u5ea6\u7528\u9014\uff08\u5982\u6da6\u8272\u3001\u7ffb\u8bd1\uff09\uff0c\u8fd9\u4e9b\u4e0d\u540c\u7528\u9014\u5bf9\u4fe1\u606f\u4f20\u64ad\u7684\u771f\u5b9e\u6027\u548c\u610f\u56fe\u6709\u91cd\u8981\u5f71\u54cd\u3002", "method": "HERO\u91c7\u7528\u5206\u5c42\u7ed3\u6784\uff0c\u7ed3\u5408\u957f\u5ea6\u4e13\u7528\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u5e76\u5f15\u5165\u5b50\u7c7b\u522b\u6307\u5bfc\u6a21\u5757\u6765\u533a\u5206\u6613\u6df7\u6dc6\u7684\u7ec6\u7c92\u5ea6\u7c7b\u522b\uff08\u5982\u4e0d\u540c\u6e90\u8bed\u8a00\uff09\uff0c\u63d0\u5347\u68c0\u6d4b\u51c6\u786e\u6027\u3002", "result": "\u5728\u4e94\u4e2aLLM\u548c\u516d\u4e2a\u9886\u57df\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cHERO\u5e73\u5747\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u63d0\u53472.5-3 mAP\u3002", "conclusion": "HERO\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u673a\u5668\u5f71\u54cd\u6587\u672c\u7684\u7ec6\u7c92\u5ea6\u7c7b\u578b\uff0c\u4e3a\u7406\u89e3LLM\u4f7f\u7528\u610f\u56fe\u63d0\u4f9b\u4e86\u66f4\u7cbe\u786e\u7684\u5de5\u5177\u3002", "topic": "agent analysis"}}
{"id": "2509.15366", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15366", "abs": "https://arxiv.org/abs/2509.15366", "authors": ["Andrejs Sorstkins", "Josh Bailey", "Dr Alistair Baron"], "title": "Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context", "comment": "Dissertation and research project created in collaboration with\n  JobFair LTD", "summary": "The rapid evolution of neural architectures - from multilayer perceptrons to\nlarge-scale Transformer-based models - has enabled language models (LLMs) to\nexhibit emergent agentic behaviours when equipped with memory, planning, and\nexternal tool use. However, their inherent stochasticity and multi-step\ndecision processes render classical evaluation methods inadequate for\ndiagnosing agentic performance. This work introduces a diagnostic framework for\nexpert systems that not only evaluates but also facilitates the transfer of\nexpert behaviour into LLM-powered agents. The framework integrates (i) curated\ngolden datasets of expert annotations, (ii) silver datasets generated through\ncontrolled behavioural mutation, and (iii) an LLM-based Agent Judge that scores\nand prescribes targeted improvements. These prescriptions are embedded into a\nvectorized recommendation map, allowing expert interventions to propagate as\nreusable improvement trajectories across multiple system instances. We\ndemonstrate the framework on a multi-agent recruiter-assistant system, showing\nthat it uncovers latent cognitive failures - such as biased phrasing,\nextraction drift, and tool misrouting - while simultaneously steering agents\ntoward expert-level reasoning and style. The results establish a foundation for\nstandardized, reproducible expert behaviour transfer in stochastic,\ntool-augmented LLM agents, moving beyond static evaluation to active expert\nsystem refinement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bca\u65ad\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u4fc3\u8fdb\u4e13\u5bb6\u884c\u4e3a\u5411LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u8f6c\u79fb\u3002\u8be5\u6846\u67b6\u6574\u5408\u4e86\u4e13\u5bb6\u6ce8\u91ca\u6570\u636e\u96c6\u3001\u884c\u4e3a\u53d8\u5f02\u751f\u6210\u7684\u6570\u636e\u96c6\u4ee5\u53ca\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u8bc4\u5224\u5668\uff0c\u901a\u8fc7\u5411\u91cf\u5316\u63a8\u8350\u56fe\u5b9e\u73b0\u4e13\u5bb6\u5e72\u9884\u7684\u53ef\u590d\u7528\u4f20\u64ad\u3002", "motivation": "\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u6f14\u8fdb\uff0c\u8bed\u8a00\u6a21\u578b\u5728\u914d\u5907\u8bb0\u5fc6\u3001\u89c4\u5212\u548c\u5916\u90e8\u5de5\u5177\u4f7f\u7528\u65f6\u5c55\u73b0\u51fa\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u4f46\u4f20\u7edf\u7684\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8bca\u65ad\u5176\u667a\u80fd\u4f53\u6027\u80fd\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a(i) \u7cbe\u5fc3\u7b56\u5212\u7684\u4e13\u5bb6\u6ce8\u91ca\u9ec4\u91d1\u6570\u636e\u96c6\uff0c(ii) \u901a\u8fc7\u53d7\u63a7\u884c\u4e3a\u53d8\u5f02\u751f\u6210\u7684\u94f6\u6570\u636e\u96c6\uff0c(iii) \u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u8bc4\u5224\u5668\uff0c\u7528\u4e8e\u8bc4\u5206\u548c\u5236\u5b9a\u9488\u5bf9\u6027\u6539\u8fdb\u65b9\u6848\u3002\u8fd9\u4e9b\u6539\u8fdb\u65b9\u6848\u88ab\u5d4c\u5165\u5230\u5411\u91cf\u5316\u63a8\u8350\u56fe\u4e2d\u3002", "result": "\u5728\u591a\u667a\u80fd\u4f53\u62db\u8058\u52a9\u624b\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u53d1\u73b0\u6f5c\u5728\u7684\u8ba4\u77e5\u5931\u8d25\uff08\u5982\u504f\u89c1\u63aa\u8f9e\u3001\u63d0\u53d6\u6f02\u79fb\u548c\u5de5\u5177\u8bef\u8def\u7531\uff09\uff0c\u540c\u65f6\u5f15\u5bfc\u667a\u80fd\u4f53\u5411\u4e13\u5bb6\u7ea7\u63a8\u7406\u548c\u98ce\u683c\u53d1\u5c55\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u968f\u673a\u6027\u3001\u5de5\u5177\u589e\u5f3a\u7684LLM\u667a\u80fd\u4f53\u5efa\u7acb\u4e86\u6807\u51c6\u5316\u3001\u53ef\u590d\u73b0\u7684\u4e13\u5bb6\u884c\u4e3a\u8f6c\u79fb\u57fa\u7840\uff0c\u4ece\u9759\u6001\u8bc4\u4f30\u8f6c\u5411\u4e3b\u52a8\u7684\u4e13\u5bb6\u7cfb\u7edf\u4f18\u5316\u3002", "topic": "agent analysis"}}
{"id": "2509.16187", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.16187", "abs": "https://arxiv.org/abs/2509.16187", "authors": ["Ali Reza Ibrahimzada", "Brandon Paulsen", "Reyhaneh Jabbarvand", "Joey Dodds", "Daniel Kroening"], "title": "MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair", "comment": null, "summary": "Code translation transforms source code from one programming language (PL) to\nanother. Validating the functional equivalence of translation and repairing, if\nnecessary, are critical steps in code translation. Existing automated\nvalidation and repair approaches struggle to generalize to many PLs due to high\nengineering overhead, and they rely on existing and often inadequate test\nsuites, which results in false claims of equivalence and ineffective\ntranslation repair. We develop MatchFixAgent, a large language model\n(LLM)-based, PL-agnostic framework for equivalence validation and repair of\ntranslations. MatchFixAgent features a multi-agent architecture that divides\nequivalence validation into several sub-tasks to ensure thorough and consistent\nsemantic analysis of the translation. Then it feeds this analysis to test agent\nto write and execute tests. Upon observing a test failure, the repair agent\nattempts to fix the translation bug. The final (in)equivalence decision is made\nby the verdict agent, considering semantic analyses and test execution results.\n  We compare MatchFixAgent's validation and repair results with four\nrepository-level code translation techniques. We use 2,219 translation pairs\nfrom their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub\nprojects totaling over 900K lines of code. Our results demonstrate that\nMatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,\nwith the same equivalence validation result as prior work on 72.8% of them.\nWhen MatchFixAgent's result disagrees with prior work, we find that 60.7% of\nthe time MatchFixAgent's result is actually correct. In addition, we show that\nMatchFixAgent can repair 50.6% of inequivalent translation, compared to prior\nwork's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to\nmany PL pairs than prior work, while producing highly accurate validation\nresults.", "AI": {"tldr": "MatchFixAgent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u4ee3\u7801\u7ffb\u8bd1\u7684\u7b49\u4ef7\u6027\u9a8c\u8bc1\u548c\u4fee\u590d\uff0c\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u5bf9\uff0c\u5728\u9a8c\u8bc1\u8986\u76d6\u7387\u548c\u4fee\u590d\u6210\u529f\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u7ffb\u8bd1\u9a8c\u8bc1\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\u5230\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u4f9d\u8d56\u4e0d\u5145\u5206\u7684\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5bfc\u81f4\u7b49\u4ef7\u6027\u8bef\u5224\u548c\u4fee\u590d\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06\u7b49\u4ef7\u6027\u9a8c\u8bc1\u5206\u89e3\u4e3a\u8bed\u4e49\u5206\u6790\u3001\u6d4b\u8bd5\u751f\u6210\u6267\u884c\u3001\u7ffb\u8bd1\u4fee\u590d\u548c\u6700\u7ec8\u88c1\u51b3\u7b49\u5b50\u4efb\u52a1\uff0c\u5b9e\u73b0\u5168\u9762\u8bed\u4e49\u5206\u6790\u548c\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u57286\u79cd\u7f16\u7a0b\u8bed\u8a00\u5bf9\u76842,219\u4e2a\u7ffb\u8bd1\u5bf9\u4e0a\uff0cMatchFixAgent\u5bf999.2%\u7684\u7ffb\u8bd1\u5bf9\u7ed9\u51fa\u7b49\u4ef7\u6027\u88c1\u51b3\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u7ed3\u679c\u4e00\u81f4\u7387\u4e3a72.8%\uff0c\u5728\u5206\u6b67\u60c5\u51b5\u4e0b60.7% MatchFixAgent\u6b63\u786e\uff0c\u4fee\u590d\u6210\u529f\u738750.6%\u8fdc\u9ad8\u4e8e\u73b0\u6709\u65b9\u6cd5\u768418.5%\u3002", "conclusion": "MatchFixAgent\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u7f16\u7a0b\u8bed\u8a00\u9002\u5e94\u6027\uff0c\u80fd\u4ea7\u751f\u66f4\u51c6\u786e\u7684\u9a8c\u8bc1\u7ed3\u679c\u548c\u66f4\u9ad8\u7684\u4fee\u590d\u6210\u529f\u7387\u3002", "topic": "code agent"}}
{"id": "2509.15635", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15635", "abs": "https://arxiv.org/abs/2509.15635", "authors": ["Pan Tang", "Shixiang Tang", "Huanqi Pu", "Zhiqing Miao", "Zhixing Wang"], "title": "MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents", "comment": "18 pages, 22 figures", "summary": "This paper presents MicroRCA-Agent, an innovative solution for microservice\nroot cause analysis based on large language model agents, which constructs an\nintelligent fault root cause localization system with multimodal data fusion.\nThe technical innovations are embodied in three key aspects: First, we combine\nthe pre-trained Drain log parsing algorithm with multi-level data filtering\nmechanism to efficiently compress massive logs into high-quality fault\nfeatures. Second, we employ a dual anomaly detection approach that integrates\nIsolation Forest unsupervised learning algorithms with status code validation\nto achieve comprehensive trace anomaly identification. Third, we design a\nstatistical symmetry ratio filtering mechanism coupled with a two-stage LLM\nanalysis strategy to enable full-stack phenomenon summarization across\nnode-service-pod hierarchies. The multimodal root cause analysis module\nleverages carefully designed cross-modal prompts to deeply integrate multimodal\nanomaly information, fully exploiting the cross-modal understanding and logical\nreasoning capabilities of large language models to generate structured analysis\nresults encompassing fault components, root cause descriptions, and reasoning\ntrace. Comprehensive ablation studies validate the complementary value of each\nmodal data and the effectiveness of the system architecture. The proposed\nsolution demonstrates superior performance in complex microservice fault\nscenarios, achieving a final score of 50.71. The code has been released at:\nhttps://github.com/tangpan360/MicroRCA-Agent.", "AI": {"tldr": "MicroRCA-Agent\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u5fae\u670d\u52a1\u6839\u56e0\u5206\u6790\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u5b9e\u73b0\u667a\u80fd\u6545\u969c\u5b9a\u4f4d\u3002", "motivation": "\u89e3\u51b3\u5fae\u670d\u52a1\u73af\u5883\u4e2d\u590d\u6742\u6545\u969c\u6839\u56e0\u5b9a\u4f4d\u7684\u6311\u6218\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u6a21\u6001\u7406\u89e3\u548c\u903b\u8f91\u63a8\u7406\u80fd\u529b\u63d0\u5347\u6545\u969c\u5206\u6790\u6548\u7387\u3002", "method": "1) \u7ed3\u5408Drain\u65e5\u5fd7\u89e3\u6790\u7b97\u6cd5\u548c\u591a\u7ea7\u6570\u636e\u8fc7\u6ee4\u538b\u7f29\u6d77\u91cf\u65e5\u5fd7\uff1b2) \u91c7\u7528\u9694\u79bb\u68ee\u6797\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u72b6\u6001\u7801\u9a8c\u8bc1\u7684\u53cc\u5f02\u5e38\u68c0\u6d4b\uff1b3) \u7edf\u8ba1\u5bf9\u79f0\u6bd4\u8fc7\u6ee4\u673a\u5236\u548c\u4e24\u9636\u6bb5LLM\u5206\u6790\u7b56\u7565\u5b9e\u73b0\u5168\u6808\u73b0\u8c61\u603b\u7ed3\uff1b4) \u591a\u6a21\u6001\u6839\u56e0\u5206\u6790\u6a21\u5757\u901a\u8fc7\u8de8\u6a21\u6001\u63d0\u793a\u6df1\u5ea6\u6574\u5408\u5f02\u5e38\u4fe1\u606f\u3002", "result": "\u5728\u590d\u6742\u5fae\u670d\u52a1\u6545\u969c\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u6700\u7ec8\u5f97\u520650.71\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5404\u6a21\u6001\u6570\u636e\u7684\u4e92\u8865\u4ef7\u503c\u548c\u7cfb\u7edf\u67b6\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "MicroRCA-Agent\u901a\u8fc7\u521b\u65b0\u7684\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u548cLLM\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u5fae\u670d\u52a1\u6839\u56e0\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2509.15690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15690", "abs": "https://arxiv.org/abs/2509.15690", "authors": ["Weixuan Sun", "Jucai Zhai", "Dengfeng Liu", "Xin Zhang", "Xiaojun Wu", "Qiaobo Hao", "AIMgroup", "Yang Fang", "Jiuyang Tang"], "title": "CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair", "comment": null, "summary": "The automated repair of C++ compilation errors presents a significant\nchallenge, the resolution of which is critical for developer productivity.\nProgress in this domain is constrained by two primary factors: the scarcity of\nlarge-scale, high-fidelity datasets and the limitations of conventional\nsupervised methods, which often fail to generate semantically correct\npatches.This paper addresses these gaps by introducing a comprehensive\nframework with three core contributions. First, we present CCrepair, a novel,\nlarge-scale C++ compilation error dataset constructed through a sophisticated\ngenerate-and-verify pipeline. Second, we propose a Reinforcement Learning (RL)\nparadigm guided by a hybrid reward signal, shifting the focus from mere\ncompilability to the semantic quality of the fix. Finally, we establish the\nrobust, two-stage evaluation system providing this signal, centered on an\nLLM-as-a-Judge whose reliability has been rigorously validated against the\ncollective judgments of a panel of human experts. This integrated approach\naligns the training objective with generating high-quality, non-trivial patches\nthat are both syntactically and semantically correct. The effectiveness of our\napproach was demonstrated experimentally. Our RL-trained Qwen2.5-1.5B-Instruct\nmodel achieved performance comparable to a Qwen2.5-14B-Instruct model,\nvalidating the efficiency of our training paradigm. Our work provides the\nresearch community with a valuable new dataset and a more effective paradigm\nfor training and evaluating robust compilation repair models, paving the way\nfor more practical and reliable automated programming assistants.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u89e3\u51b3C++\u7f16\u8bd1\u9519\u8bef\u7684\u7efc\u5408\u6846\u67b6\uff0c\u5305\u62ecCCrepair\u6570\u636e\u96c6\u3001\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4fee\u590d\u65b9\u6cd5\u4ee5\u53ca\u4e24\u9636\u6bb5\u8bc4\u4f30\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u4fee\u590d\u7684\u8bed\u4e49\u8d28\u91cf\u3002", "motivation": "\u5f53\u524dC++\u7f16\u8bd1\u9519\u8bef\u81ea\u52a8\u4fee\u590d\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u7f3a\u4e4f\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u751f\u6210\u8bed\u4e49\u6b63\u786e\u7684\u4fee\u590d\u8865\u4e01\u3002", "method": "1) \u6784\u5efaCCrepair\u5927\u89c4\u6a21C++\u7f16\u8bd1\u9519\u8bef\u6570\u636e\u96c6\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u6df7\u5408\u5956\u52b1\u4fe1\u53f7\u7684\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff1b3) \u5efa\u7acb\u4ee5LLM\u4e3a\u8bc4\u5224\u8005\u7684\u4e24\u9636\u6bb5\u8bc4\u4f30\u7cfb\u7edf\u3002", "result": "RL\u8bad\u7ec3\u7684Qwen2.5-1.5B\u6a21\u578b\u6027\u80fd\u8fbe\u5230\u4e0eQwen2.5-14B\u6a21\u578b\u76f8\u5f53\u7684\u6c34\u5e73\uff0c\u9a8c\u8bc1\u4e86\u8bad\u7ec3\u8303\u5f0f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u96c6\u548c\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u8bc4\u4f30\u8303\u5f0f\uff0c\u4e3a\u5f00\u53d1\u66f4\u5b9e\u7528\u53ef\u9760\u7684\u81ea\u52a8\u7f16\u7a0b\u52a9\u624b\u94fa\u5e73\u4e86\u9053\u8def\u3002", "topic": "code agent"}}
{"id": "2509.16112", "categories": ["cs.CL", "cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.16112", "abs": "https://arxiv.org/abs/2509.16112", "authors": ["Sheng Zhang", "Yifan Ding", "Shuquan Lian", "Shun Song", "Hui Li"], "title": "CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion", "comment": "EMNLP 2025", "summary": "Repository-level code completion automatically predicts the unfinished code\nbased on the broader information from the repository. Recent strides in Code\nLarge Language Models (code LLMs) have spurred the development of\nrepository-level code completion methods, yielding promising results.\nNevertheless, they suffer from issues such as inappropriate query construction,\nsingle-path code retrieval, and misalignment between code retriever and code\nLLM. To address these problems, we introduce CodeRAG, a framework tailored to\nidentify relevant and necessary knowledge for retrieval-augmented\nrepository-level code completion. Its core components include log probability\nguided query construction, multi-path code retrieval, and preference-aligned\nBestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval\ndemonstrate that CodeRAG significantly and consistently outperforms\nstate-of-the-art methods. The implementation of CodeRAG is available at\nhttps://github.com/KDEGroup/CodeRAG.", "AI": {"tldr": "CodeRAG\u662f\u4e00\u4e2a\u9488\u5bf9\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u7684\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u67e5\u8be2\u6784\u5efa\u3001\u591a\u8def\u5f84\u4ee3\u7801\u68c0\u7d22\u548c\u504f\u597d\u5bf9\u9f50\u91cd\u6392\u5e8f\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u65b9\u6cd5\u5b58\u5728\u67e5\u8be2\u6784\u5efa\u4e0d\u5f53\u3001\u5355\u8def\u5f84\u4ee3\u7801\u68c0\u7d22\u4ee5\u53ca\u4ee3\u7801\u68c0\u7d22\u5668\u4e0e\u4ee3\u7801LLM\u4e0d\u5bf9\u9f50\u7b49\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u8865\u5168\u8d28\u91cf\u3002", "method": "CodeRAG\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u67e5\u8be2\u6784\u5efa\u3001\u591a\u8def\u5f84\u4ee3\u7801\u68c0\u7d22\u548c\u504f\u597d\u5bf9\u9f50\u7684BestFit\u91cd\u6392\u5e8f\u65b9\u6cd5\u3002", "result": "\u5728ReccEval\u548cCCEval\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCodeRAG\u663e\u8457\u4e14\u6301\u7eed\u5730\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "CodeRAG\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u6539\u8fdb\u89e3\u51b3\u4e86\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u68c0\u7d22\u589e\u5f3a\u89e3\u51b3\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "2509.16198", "categories": ["cs.CL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.16198", "abs": "https://arxiv.org/abs/2509.16198", "authors": ["Jane Luo", "Xin Zhang", "Steven Liu", "Jie Wu", "Yiming Huang", "Yangyu Huang", "Chengyu Yin", "Ying Xin", "Jianfeng Liu", "Yuefeng Zhan", "Hao Sun", "Qi Chen", "Scarlett Li", "Mao Yang"], "title": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "comment": null, "summary": "Large language models excel at function- and file-level code generation, yet\ngenerating complete repositories from scratch remains a fundamental challenge.\nThis process demands coherent and reliable planning across proposal- and\nimplementation-level stages, while natural language, due to its ambiguity and\nverbosity, is ill-suited for faithfully representing complex software\nstructures. To address this, we introduce the Repository Planning Graph (RPG),\na persistent representation that unifies proposal- and implementation-level\nplanning by encoding capabilities, file structures, data flows, and functions\nin one graph. RPG replaces ambiguous natural language with an explicit\nblueprint, enabling long-horizon planning and scalable repository generation.\nBuilding on RPG, we develop ZeroRepo, a graph-driven framework for repository\ngeneration from scratch. It operates in three stages: proposal-level planning\nand implementation-level refinement to construct the graph, followed by\ngraph-guided code generation with test validation. To evaluate this setting, we\nconstruct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.\nOn RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly\n3.9$\\times$ the strongest baseline (Claude Code) and about 64$\\times$ other\nbaselines. It attains 81.5% functional coverage and a 69.7% pass rate,\nexceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further\nanalysis shows that RPG models complex dependencies, enables progressively more\nsophisticated planning through near-linear scaling, and enhances LLM\nunderstanding of repositories, thereby accelerating agent localization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86Repository Planning Graph (RPG)\u6765\u89e3\u51b3\u4ece\u96f6\u751f\u6210\u5b8c\u6574\u4ee3\u7801\u4ed3\u5e93\u7684\u6311\u6218\uff0c\u5f00\u53d1\u4e86ZeroRepo\u6846\u67b6\uff0c\u5728RepoCraft\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u64c5\u957f\u51fd\u6570\u548c\u6587\u4ef6\u7ea7\u522b\u7684\u4ee3\u7801\u751f\u6210\uff0c\u4f46\u4ece\u96f6\u751f\u6210\u5b8c\u6574\u4ee3\u7801\u4ed3\u5e93\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u8de8\u63d0\u6848\u548c\u5b9e\u73b0\u9636\u6bb5\u7684\u8fde\u8d2f\u89c4\u5212\uff0c\u800c\u81ea\u7136\u8bed\u8a00\u7531\u4e8e\u6a21\u7cca\u6027\u548c\u5197\u957f\u6027\u4e0d\u9002\u5408\u8868\u793a\u590d\u6742\u8f6f\u4ef6\u7ed3\u6784\u3002", "method": "\u5f15\u5165Repository Planning Graph (RPG)\u4f5c\u4e3a\u6301\u4e45\u5316\u8868\u793a\uff0c\u7edf\u4e00\u63d0\u6848\u548c\u5b9e\u73b0\u7ea7\u89c4\u5212\uff0c\u6784\u5efaZeroRepo\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a\u63d0\u6848\u7ea7\u89c4\u5212\u3001\u5b9e\u73b0\u7ea7\u7ec6\u5316\u548c\u56fe\u5f15\u5bfc\u7684\u4ee3\u7801\u751f\u6210\u4e0e\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u5728RepoCraft\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cZeroRepo\u751f\u6210\u5e73\u5747\u8fd136K\u884c\u4ee3\u7801\u7684\u4ed3\u5e93\uff0c\u6bd4\u6700\u5f3a\u57fa\u7ebfClaude Code\u591a3.9\u500d\uff0c\u529f\u80fd\u8986\u76d6\u7387\u8fbe\u523081.5%\uff0c\u901a\u8fc7\u738769.7%\uff0c\u5206\u522b\u6bd4Claude Code\u9ad8\u51fa27.3\u548c35.8\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "RPG\u80fd\u591f\u5efa\u6a21\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u901a\u8fc7\u8fd1\u7ebf\u6027\u6269\u5c55\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u590d\u6742\u89c4\u5212\uff0c\u589e\u5f3aLLM\u5bf9\u4ed3\u5e93\u7684\u7406\u89e3\uff0c\u4ece\u800c\u52a0\u901f\u667a\u80fd\u4f53\u5b9a\u4f4d\u3002", "topic": "code agent"}}
{"id": "2509.15957", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.15957", "abs": "https://arxiv.org/abs/2509.15957", "authors": ["Kanato Masayoshi", "Masahiro Hashimoto", "Ryoichi Yokoyama", "Naoki Toda", "Yoshifumi Uwamino", "Shogo Fukuda", "Ho Namkoong", "Masahiro Jinzaki"], "title": "EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol", "comment": null, "summary": "Background: Large language models (LLMs) show promise in medicine, but their\ndeployment in hospitals is limited by restricted access to electronic health\nrecord (EHR) systems. The Model Context Protocol (MCP) enables integration\nbetween LLMs and external tools.\n  Objective: To evaluate whether an LLM connected to an EHR database via MCP\ncan autonomously retrieve clinically relevant information in a real hospital\nsetting.\n  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated\nwith the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct\nagent to interact with it. Six tasks were tested, derived from use cases of the\ninfection control team (ICT). Eight patients discussed at ICT conferences were\nretrospectively analyzed. Agreement with physician-generated gold standards was\nmeasured.\n  Results: The LLM consistently selected and executed the correct MCP tools.\nExcept for two tasks, all tasks achieved near-perfect accuracy. Performance was\nlower in the complex task requiring time-dependent calculations. Most errors\narose from incorrect arguments or misinterpretation of tool results. Responses\nfrom EHR-MCP were reliable, though long and repetitive data risked exceeding\nthe context window.\n  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a\nreal hospital setting, achieving near-perfect performance in simple tasks while\nhighlighting challenges in complex ones. EHR-MCP provides an infrastructure for\nsecure, consistent data access and may serve as a foundation for hospital AI\nagents. Future work should extend beyond retrieval to reasoning, generation,\nand clinical impact assessment, paving the way for effective integration of\ngenerative AI into clinical practice.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u901a\u8fc7MCP\u534f\u8bae\u8fde\u63a5\u533b\u9662EHR\u6570\u636e\u5e93\u7684LLM\u5728\u771f\u5b9e\u533b\u9662\u73af\u5883\u4e2d\u81ea\u4e3b\u68c0\u7d22\u4e34\u5e8a\u76f8\u5173\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u5728\u7b80\u5355\u4efb\u52a1\u4e2d\u8868\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\uff0c\u4f46\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u9762\u4e34\u6311\u6218\u3002", "motivation": "LLMs\u5728\u533b\u7597\u9886\u57df\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u533b\u9662\u90e8\u7f72\u53d7\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u65e0\u6cd5\u76f4\u63a5\u8bbf\u95ee\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\u3002MCP\u534f\u8bae\u4e3aLLM\u4e0e\u5916\u90e8\u5de5\u5177\u96c6\u6210\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u5f00\u53d1\u4e86EHR-MCP\u6846\u67b6\uff0c\u5c06\u81ea\u5b9a\u4e49MCP\u5de5\u5177\u4e0e\u533b\u9662EHR\u6570\u636e\u5e93\u96c6\u6210\uff0c\u4f7f\u7528GPT-4.1\u901a\u8fc7LangGraph ReAct\u4ee3\u7406\u8fdb\u884c\u4ea4\u4e92\uff0c\u6d4b\u8bd5\u4e866\u4e2a\u611f\u67d3\u63a7\u5236\u56e2\u961f\u76f8\u5173\u4efb\u52a1\u3002", "result": "LLM\u80fd\u6b63\u786e\u9009\u62e9\u548c\u6267\u884cMCP\u5de5\u5177\uff0c\u9664\u4e24\u4e2a\u4efb\u52a1\u5916\u5747\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u51c6\u786e\u7387\u3002\u590d\u6742\u7684\u65f6\u95f4\u4f9d\u8d56\u8ba1\u7b97\u4efb\u52a1\u8868\u73b0\u8f83\u5dee\uff0c\u9519\u8bef\u4e3b\u8981\u6765\u81ea\u53c2\u6570\u4e0d\u6b63\u786e\u6216\u7ed3\u679c\u8bef\u89e3\u3002", "conclusion": "LLMs\u53ef\u4ee5\u901a\u8fc7MCP\u5de5\u5177\u4ece\u533b\u9662EHR\u4e2d\u68c0\u7d22\u4e34\u5e8a\u6570\u636e\uff0cEHR-MCP\u4e3a\u533b\u9662AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b89\u5168\u3001\u4e00\u81f4\u7684\u6570\u636e\u8bbf\u95ee\u57fa\u7840\u67b6\u6784\u3002", "topic": "agent analysis"}}
{"id": "2509.15518", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15518", "abs": "https://arxiv.org/abs/2509.15518", "authors": ["Siyang Wu", "Zhewei Sun"], "title": "How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages", "comment": null, "summary": "Slang is a commonly used type of informal language that poses a daunting\nchallenge to NLP systems. Recent advances in large language models (LLMs),\nhowever, have made the problem more approachable. While LLM agents are becoming\nmore widely applied to intermediary tasks such as slang detection and slang\ninterpretation, their generalizability and reliability are heavily dependent on\nwhether these models have captured structural knowledge about slang that align\nwell with human attested slang usages. To answer this question, we contribute a\nsystematic comparison between human and machine-generated slang usages. Our\nevaluative framework focuses on three core aspects: 1) Characteristics of the\nusages that reflect systematic biases in how machines perceive slang, 2)\nCreativity reflected by both lexical coinages and word reuses employed by the\nslang usages, and 3) Informativeness of the slang usages when used as\ngold-standard examples for model distillation. By comparing human-attested\nslang usages from the Online Slang Dictionary (OSD) and slang generated by\nGPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our\nresults suggest that while LLMs have captured significant knowledge about the\ncreative aspects of slang, such knowledge does not align with humans\nsufficiently to enable LLMs for extrapolative tasks such as linguistic\nanalyses.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4eba\u7c7b\u548c\u673a\u5668\u751f\u6210\u7684\u4fda\u8bed\u7528\u6cd5\uff0c\u53d1\u73b0LLMs\u5728\u4fda\u8bed\u7406\u89e3\u4e0a\u5b58\u5728\u663e\u8457\u504f\u89c1\uff0c\u867d\u7136\u638c\u63e1\u4e86\u4fda\u8bed\u7684\u521b\u9020\u6027\u7279\u5f81\uff0c\u4f46\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u5b58\u5728\u5dee\u5f02\uff0c\u9650\u5236\u4e86\u5176\u5728\u8bed\u8a00\u5206\u6790\u7b49\u5916\u63a8\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u4fda\u8bed\u4f5c\u4e3a\u975e\u6b63\u5f0f\u8bed\u8a00\u5bf9NLP\u7cfb\u7edf\u6784\u6210\u6311\u6218\uff0c\u9700\u8981\u8bc4\u4f30LLMs\u662f\u5426\u638c\u63e1\u4e86\u4e0e\u4eba\u7c7b\u4fda\u8bed\u4f7f\u7528\u4e00\u81f4\u7684\u7ed3\u6784\u6027\u77e5\u8bc6\uff0c\u4ee5\u786e\u5b9a\u5176\u5728\u4fda\u8bed\u68c0\u6d4b\u548c\u89e3\u91ca\u7b49\u4e2d\u4ecb\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\uff0c\u4ece\u4e09\u4e2a\u6838\u5fc3\u65b9\u9762\u6bd4\u8f83\u4eba\u7c7b\uff08\u6765\u81ea\u5728\u7ebf\u4fda\u8bed\u8bcd\u5178OSD\uff09\u548c\u673a\u5668\uff08GPT-4o\u548cLlama-3\uff09\u751f\u6210\u7684\u4fda\u8bed\u7528\u6cd5\uff1a\u7cfb\u7edf\u6027\u504f\u89c1\u7279\u5f81\u3001\u521b\u9020\u6027\uff08\u8bcd\u6c47\u521b\u65b0\u548c\u8bcd\u8bed\u91cd\u7528\uff09\u3001\u4f5c\u4e3a\u6a21\u578b\u84b8\u998f\u91d1\u6807\u51c6\u793a\u4f8b\u7684\u4fe1\u606f\u91cf\u3002", "result": "\u53d1\u73b0LLMs\u5728\u4fda\u8bed\u611f\u77e5\u4e0a\u5b58\u5728\u663e\u8457\u504f\u89c1\uff0c\u867d\u7136\u638c\u63e1\u4e86\u4fda\u8bed\u7684\u521b\u9020\u6027\u77e5\u8bc6\uff0c\u4f46\u8fd9\u4e9b\u77e5\u8bc6\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u4e0d\u591f\u4e00\u81f4\uff0c\u65e0\u6cd5\u652f\u6301\u5916\u63a8\u6027\u4efb\u52a1\u5982\u8bed\u8a00\u5206\u6790\u3002", "conclusion": "LLMs\u5728\u4fda\u8bed\u7406\u89e3\u65b9\u9762\u4ecd\u6709\u5c40\u9650\uff0c\u5176\u77e5\u8bc6\u7ed3\u6784\u4e0e\u4eba\u7c7b\u4fda\u8bed\u4f7f\u7528\u5b58\u5728\u5dee\u5f02\uff0c\u9650\u5236\u4e86\u5728\u9700\u8981\u6df1\u5ea6\u8bed\u8a00\u7406\u89e3\u7684\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "topic": "agent analysis"}}
{"id": "2509.15498", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15498", "abs": "https://arxiv.org/abs/2509.15498", "authors": ["Zahra Aref", "Narayan B. Mandayam"], "title": "Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers", "comment": null, "summary": "Transformers have emerged as a compelling architecture for sequential\ndecision-making by modeling trajectories via self-attention. In reinforcement\nlearning (RL), they enable return-conditioned control without relying on value\nfunction approximation. Decision Transformers (DTs) exploit this by casting RL\nas supervised sequence modeling, but they are restricted to offline data and\nlack exploration. Online Decision Transformers (ODTs) address this limitation\nthrough entropy-regularized training on on-policy rollouts, offering a stable\nalternative to traditional RL methods like Soft Actor-Critic, which depend on\nbootstrapped targets and reward shaping. Despite these advantages, ODTs use\nstandard attention, which lacks explicit memory of action-specific outcomes.\nThis leads to inefficiencies in learning long-term action effectiveness.\nInspired by cognitive models such as Experience-Weighted Attraction (EWA), we\npropose Experience-Weighted Attraction with Vector Quantization for Online\nDecision Transformers (EWA-VQ-ODT), a lightweight module that maintains\nper-action mental accounts summarizing recent successes and failures.\nContinuous actions are routed via direct grid lookup to a compact\nvector-quantized codebook, where each code stores a scalar attraction updated\nonline through decay and reward-based reinforcement. These attractions modulate\nattention by biasing the columns associated with action tokens, requiring no\nchange to the backbone or training objective. On standard continuous-control\nbenchmarks, EWA-VQ-ODT improves sample efficiency and average return over ODT,\nparticularly in early training. The module is computationally efficient,\ninterpretable via per-code traces, and supported by theoretical guarantees that\nbound the attraction dynamics and its impact on attention drift.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEWA-VQ-ODT\u65b9\u6cd5\uff0c\u901a\u8fc7\u5411\u91cf\u91cf\u5316\u7684\u7ecf\u9a8c\u52a0\u6743\u5438\u5f15\u529b\u6a21\u5757\u589e\u5f3a\u5728\u7ebf\u51b3\u7b56\u53d8\u6362\u5668\uff0c\u63d0\u9ad8\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u5728\u7ebf\u51b3\u7b56\u53d8\u6362\u5668\u4f7f\u7528\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u4f5c\u7279\u5b9a\u7ed3\u679c\u7684\u663e\u5f0f\u8bb0\u5fc6\uff0c\u5bfc\u81f4\u5b66\u4e60\u957f\u671f\u52a8\u4f5c\u6548\u679c\u65f6\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6a21\u5757\uff0c\u7ef4\u62a4\u6bcf\u4e2a\u52a8\u4f5c\u7684\u5fc3\u7406\u8d26\u6237\uff0c\u901a\u8fc7\u5411\u91cf\u91cf\u5316\u4ee3\u7801\u672c\u5b58\u50a8\u6807\u91cf\u5438\u5f15\u529b\uff0c\u5728\u7ebf\u66f4\u65b0\u5e76\u8c03\u5236\u6ce8\u610f\u529b\u673a\u5236\u3002", "result": "\u5728\u6807\u51c6\u8fde\u7eed\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEWA-VQ-ODT\u76f8\u6bd4ODT\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u548c\u5e73\u5747\u56de\u62a5\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u8bad\u7ec3\u9636\u6bb5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u7ea6\u675f\u4e86\u5438\u5f15\u529b\u52a8\u6001\u548c\u6ce8\u610f\u529b\u6f02\u79fb\u7684\u5f71\u54cd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.15631", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15631", "abs": "https://arxiv.org/abs/2509.15631", "authors": ["Tomoya Yamashita", "Akira Ito", "Yuuki Yamanaka", "Masanori Yamada", "Takayuki Miura", "Toshiki Shibahara"], "title": "Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models", "comment": null, "summary": "As large language models (LLMs) are increasingly deployed across various\napplications, privacy and copyright concerns have heightened the need for more\neffective LLM unlearning techniques. Many existing unlearning methods aim to\nsuppress undesirable outputs through additional training (e.g., gradient\nascent), which reduces the probability of generating such outputs. While such\nsuppression-based approaches can control model outputs, they may not eliminate\nthe underlying knowledge embedded in the model's internal activations; muting a\nresponse is not the same as forgetting it. Moreover, such suppression-based\nmethods often suffer from model collapse. To address these issues, we propose a\nnovel unlearning method that directly intervenes in the model's internal\nactivations. In our formulation, forgetting is defined as a state in which the\nactivation of a forgotten target is indistinguishable from that of ``unknown''\nentities. Our method introduces an unlearning objective that modifies the\nactivation of the target entity away from those of known entities and toward\nthose of unknown entities in a sparse autoencoder latent space. By aligning the\ntarget's internal activation with those of unknown entities, we shift the\nmodel's recognition of the target entity from ``known'' to ``unknown'',\nachieving genuine forgetting while avoiding over-suppression and model\ncollapse. Empirically, we show that our method effectively aligns the internal\nactivations of the forgotten target, a result that the suppression-based\napproaches do not reliably achieve. Additionally, our method effectively\nreduces the model's recall of target knowledge in question-answering tasks\nwithout significant damage to the non-target knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684LLM\u9057\u5fd8\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u5e72\u9884\u6a21\u578b\u5185\u90e8\u6fc0\u6d3b\uff0c\u5c06\u76ee\u6807\u5b9e\u4f53\u7684\u6fc0\u6d3b\u72b6\u6001\u4ece\u201c\u5df2\u77e5\u201d\u8c03\u6574\u4e3a\u201c\u672a\u77e5\u201d\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u9057\u5fd8\u800c\u975e\u7b80\u5355\u6291\u5236\u8f93\u51fa\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6291\u5236\u7684\u9057\u5fd8\u65b9\u6cd5\u53ea\u80fd\u63a7\u5236\u6a21\u578b\u8f93\u51fa\uff0c\u4f46\u65e0\u6cd5\u6d88\u9664\u6a21\u578b\u5185\u90e8\u5d4c\u5165\u7684\u77e5\u8bc6\uff0c\u4e14\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u5d29\u6e83\u3002\u9700\u8981\u4e00\u79cd\u80fd\u771f\u6b63\u5b9e\u73b0\u77e5\u8bc6\u9057\u5fd8\u7684\u65b9\u6cd5\u3002", "method": "\u5728\u7a00\u758f\u81ea\u7f16\u7801\u5668\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u901a\u8fc7\u9057\u5fd8\u76ee\u6807\u5c06\u76ee\u6807\u5b9e\u4f53\u7684\u6fc0\u6d3b\u72b6\u6001\u4ece\u5df2\u77e5\u5b9e\u4f53\u8fdc\u79bb\uff0c\u5411\u672a\u77e5\u5b9e\u4f53\u9760\u8fd1\uff0c\u4f7f\u6a21\u578b\u5bf9\u76ee\u6807\u5b9e\u4f53\u7684\u8bc6\u522b\u4ece\u201c\u5df2\u77e5\u201d\u8f6c\u53d8\u4e3a\u201c\u672a\u77e5\u201d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5bf9\u9f50\u88ab\u9057\u5fd8\u76ee\u6807\u7684\u5185\u90e8\u6fc0\u6d3b\uff0c\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u663e\u8457\u51cf\u5c11\u76ee\u6807\u77e5\u8bc6\u7684\u56de\u5fc6\uff0c\u540c\u65f6\u5bf9\u975e\u76ee\u6807\u77e5\u8bc6\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u771f\u6b63\u7684\u77e5\u8bc6\u9057\u5fd8\uff0c\u907f\u514d\u4e86\u8fc7\u5ea6\u6291\u5236\u548c\u6a21\u578b\u5d29\u6e83\u95ee\u9898\uff0c\u4e3aLLM\u9690\u79c1\u548c\u7248\u6743\u4fdd\u62a4\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2509.15519", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15519", "abs": "https://arxiv.org/abs/2509.15519", "authors": ["Chao Li", "Bingkun Bao", "Yang Gao"], "title": "Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem", "comment": null, "summary": "This paper studies fully decentralized cooperative multi-agent reinforcement\nlearning, where each agent solely observes the states, its local actions, and\nthe shared rewards. The inability to access other agents' actions often leads\nto non-stationarity during value function updates and relative\novergeneralization during value function estimation, hindering effective\ncooperative policy learning. However, existing works fail to address both\nissues simultaneously, due to their inability to model the joint policy of\nother agents in a fully decentralized setting. To overcome this limitation, we\npropose a novel method named Dynamics-Aware Context (DAC), which formalizes the\ntask, as locally perceived by each agent, as an Contextual Markov Decision\nProcess, and further addresses both non-stationarity and relative\novergeneralization through dynamics-aware context modeling. Specifically, DAC\nattributes the non-stationary local task dynamics of each agent to switches\nbetween unobserved contexts, each corresponding to a distinct joint policy.\nThen, DAC models the step-wise dynamics distribution using latent variables and\nrefers to them as contexts. For each agent, DAC introduces a context-based\nvalue function to address the non-stationarity issue during value function\nupdate. For value function estimation, an optimistic marginal value is derived\nto promote the selection of cooperative actions, thereby addressing the\nrelative overgeneralization issue. Experimentally, we evaluate DAC on various\ncooperative tasks (including matrix game, predator and prey, and SMAC), and its\nsuperior performance against multiple baselines validates its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDAC\u65b9\u6cd5\u89e3\u51b3\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u548c\u76f8\u5bf9\u8fc7\u5ea6\u6cdb\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u611f\u77e5\u4e0a\u4e0b\u6587\u5efa\u6a21\u5c06\u5c40\u90e8\u4efb\u52a1\u52a8\u6001\u5f52\u56e0\u4e8e\u672a\u89c2\u6d4b\u4e0a\u4e0b\u6587\u5207\u6362\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u4ef7\u503c\u51fd\u6570\u548c\u4e50\u89c2\u8fb9\u9645\u4ef7\u503c\u6765\u4fc3\u8fdb\u5408\u4f5c\u884c\u52a8\u9009\u62e9\u3002", "motivation": "\u5728\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u667a\u80fd\u4f53\u65e0\u6cd5\u8bbf\u95ee\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u52a8\u4f5c\u4f1a\u5bfc\u81f4\u4ef7\u503c\u51fd\u6570\u66f4\u65b0\u65f6\u7684\u975e\u5e73\u7a33\u6027\u548c\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u65f6\u7684\u76f8\u5bf9\u8fc7\u5ea6\u6cdb\u5316\uff0c\u963b\u788d\u6709\u6548\u7684\u5408\u4f5c\u7b56\u7565\u5b66\u4e60\u3002\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u89e3\u51b3\u8fd9\u4e24\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51faDynamics-Aware Context (DAC)\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u667a\u80fd\u4f53\u611f\u77e5\u7684\u5c40\u90e8\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u4e0a\u4e0b\u6587\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u52a8\u6001\u611f\u77e5\u4e0a\u4e0b\u6587\u5efa\u6a21\u89e3\u51b3\u975e\u5e73\u7a33\u6027\u548c\u76f8\u5bf9\u8fc7\u5ea6\u6cdb\u5316\u95ee\u9898\u3002\u5177\u4f53\u5305\u62ec\uff1a\u5c06\u975e\u5e73\u7a33\u5c40\u90e8\u4efb\u52a1\u52a8\u6001\u5f52\u56e0\u4e8e\u672a\u89c2\u6d4b\u4e0a\u4e0b\u6587\u5207\u6362\uff0c\u4f7f\u7528\u6f5c\u5728\u53d8\u91cf\u5efa\u6a21\u6b65\u8fdb\u52a8\u6001\u5206\u5e03\uff0c\u5f15\u5165\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u4ef7\u503c\u51fd\u6570\u548c\u4e50\u89c2\u8fb9\u9645\u4ef7\u503c\u3002", "result": "\u5728\u591a\u79cd\u5408\u4f5c\u4efb\u52a1\uff08\u5305\u62ec\u77e9\u9635\u6e38\u620f\u3001\u6355\u98df\u8005-\u730e\u7269\u6e38\u620f\u548cSMAC\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDAC\u76f8\u6bd4\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "DAC\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u611f\u77e5\u4e0a\u4e0b\u6587\u5efa\u6a21\u6210\u529f\u89e3\u51b3\u4e86\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u975e\u5e73\u7a33\u6027\u548c\u76f8\u5bf9\u8fc7\u5ea6\u6cdb\u5316\u95ee\u9898\uff0c\u5728\u591a\u79cd\u5408\u4f5c\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.15652", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15652", "abs": "https://arxiv.org/abs/2509.15652", "authors": ["Kyohei Suzuki", "Konstantinos Slavakis"], "title": "Nonconvex Regularization for Feature Selection in Reinforcement Learning", "comment": null, "summary": "This work proposes an efficient batch algorithm for feature selection in\nreinforcement learning (RL) with theoretical convergence guarantees. To\nmitigate the estimation bias inherent in conventional regularization schemes,\nthe first contribution extends policy evaluation within the classical\nleast-squares temporal-difference (LSTD) framework by formulating a\nBellman-residual objective regularized with the sparsity-inducing, nonconvex\nprojected minimax concave (PMC) penalty. Owing to the weak convexity of the PMC\npenalty, this formulation can be interpreted as a special instance of a general\nnonmonotone-inclusion problem. The second contribution establishes novel\nconvergence conditions for the forward-reflected-backward splitting (FRBS)\nalgorithm to solve this class of problems. Numerical experiments on benchmark\ndatasets demonstrate that the proposed approach substantially outperforms\nstate-of-the-art feature-selection methods, particularly in scenarios with many\nnoisy features.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u6279\u91cf\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\uff0c\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7b56\u7565\u8bc4\u4f30\uff0c\u901a\u8fc7\u975e\u51f8PMC\u60e9\u7f5a\u51cf\u5c11\u4f30\u8ba1\u504f\u5dee\uff0c\u5e76\u5efa\u7acb\u4e86FRBS\u7b97\u6cd5\u7684\u6536\u655b\u7406\u8bba\u3002", "motivation": "\u4f20\u7edf\u6b63\u5219\u5316\u65b9\u6cd5\u5728\u5f3a\u5316\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u4e2d\u5b58\u5728\u4f30\u8ba1\u504f\u5dee\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u7279\u5f81\u9009\u62e9\u6280\u672f\u6765\u5904\u7406\u9ad8\u7ef4\u566a\u58f0\u7279\u5f81\u573a\u666f\u3002", "method": "\u6269\u5c55LSTD\u6846\u67b6\uff0c\u4f7f\u7528PMC\u60e9\u7f5a\u6784\u5efaBellman\u6b8b\u5dee\u76ee\u6807\u51fd\u6570\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u975e\u5355\u8c03\u5305\u542b\u95ee\u9898\uff0c\u5e76\u5e94\u7528FRBS\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5305\u542b\u5927\u91cf\u566a\u58f0\u7279\u5f81\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684PMC\u6b63\u5219\u5316LSTD\u6846\u67b6\u4e3a\u5f3a\u5316\u5b66\u4e60\u7279\u5f81\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u9645\u6709\u6548\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u7ef4\u566a\u58f0\u73af\u5883\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.15738", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.15738", "abs": "https://arxiv.org/abs/2509.15738", "authors": ["Musen Lin", "Minghao Liu", "Taoran Lu", "Lichen Yuan", "Yiwei Liu", "Haonan Xu", "Yu Miao", "Yuhao Chao", "Zhaojian Li"], "title": "GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning", "comment": null, "summary": "Graphical User Interface (GUI) Agents, powered by large language and\nvision-language models, hold promise for enabling end-to-end automation in\ndigital environments. However, their progress is fundamentally constrained by\nthe scarcity of scalable, high-quality trajectory data. Existing data\ncollection strategies either rely on costly and inconsistent manual annotations\nor on synthetic generation methods that trade off between diversity and\nmeaningful task coverage. To bridge this gap, we present GUI-ReWalk: a\nreasoning-enhanced, multi-stage framework for synthesizing realistic and\ndiverse GUI trajectories. GUI-ReWalk begins with a stochastic exploration phase\nthat emulates human trial-and-error behaviors, and progressively transitions\ninto a reasoning-guided phase where inferred goals drive coherent and\npurposeful interactions. Moreover, it supports multi-stride task generation,\nenabling the construction of long-horizon workflows across multiple\napplications. By combining randomness for diversity with goal-aware reasoning\nfor structure, GUI-ReWalk produces data that better reflects the intent-aware,\nadaptive nature of human-computer interaction. We further train Qwen2.5-VL-7B\non the GUI-ReWalk dataset and evaluate it across multiple benchmarks, including\nScreenspot-Pro, OSWorld-G, UI-Vision, AndroidControl, and GUI-Odyssey. Results\ndemonstrate that GUI-ReWalk enables superior coverage of diverse interaction\nflows, higher trajectory entropy, and more realistic user intent. These\nfindings establish GUI-ReWalk as a scalable and data-efficient framework for\nadvancing GUI agent research and enabling robust real-world automation.", "AI": {"tldr": "GUI-ReWalk\u662f\u4e00\u4e2a\u7528\u4e8e\u5408\u6210GUI\u8f68\u8ff9\u6570\u636e\u7684\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u7ed3\u5408\u968f\u673a\u63a2\u7d22\u548c\u63a8\u7406\u5f15\u5bfc\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u5316\u4e14\u771f\u5b9e\u7684\u4eba\u673a\u4ea4\u4e92\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347GUI\u667a\u80fd\u4f53\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524dGUI\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u53d7\u5230\u9ad8\u8d28\u91cf\u8f68\u8ff9\u6570\u636e\u7a00\u7f3a\u7684\u9650\u5236\uff0c\u73b0\u6709\u6570\u636e\u6536\u96c6\u65b9\u6cd5\u8981\u4e48\u6210\u672c\u9ad8\u6602\u4e14\u4e0d\u4e00\u81f4\uff0c\u8981\u4e48\u5728\u591a\u6837\u6027\u548c\u4efb\u52a1\u8986\u76d6\u5ea6\u4e4b\u95f4\u96be\u4ee5\u5e73\u8861\u3002", "method": "GUI-ReWalk\u91c7\u7528\u63a8\u7406\u589e\u5f3a\u7684\u591a\u9636\u6bb5\u6846\u67b6\uff1a\u9996\u5148\u8fdb\u884c\u968f\u673a\u63a2\u7d22\u6a21\u62df\u4eba\u7c7b\u8bd5\u9519\u884c\u4e3a\uff0c\u7136\u540e\u8fc7\u6e21\u5230\u63a8\u7406\u5f15\u5bfc\u9636\u6bb5\uff0c\u901a\u8fc7\u63a8\u65ad\u76ee\u6807\u9a71\u52a8\u8fde\u8d2f\u7684\u4ea4\u4e92\u3002\u652f\u6301\u591a\u6b65\u4efb\u52a1\u751f\u6210\uff0c\u6784\u5efa\u8de8\u5e94\u7528\u7684\u957f\u6d41\u7a0b\u5de5\u4f5c\u6d41\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08Screenspot-Pro\u3001OSWorld-G\u7b49\uff09\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cGUI-ReWalk\u80fd\u591f\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u4ea4\u4e92\u6d41\u7a0b\u8986\u76d6\u3001\u66f4\u9ad8\u7684\u8f68\u8ff9\u71b5\u548c\u66f4\u771f\u5b9e\u7684\u7528\u6237\u610f\u56fe\u8868\u8fbe\u3002", "conclusion": "GUI-ReWalk\u4e3aGUI\u667a\u80fd\u4f53\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6570\u636e\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u80fd\u591f\u63a8\u52a8\u7a33\u5065\u7684\u5b9e\u65f6\u81ea\u52a8\u5316\u5e94\u7528\u53d1\u5c55\u3002", "topic": "agent analysis"}}
{"id": "2509.16028", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.16028", "abs": "https://arxiv.org/abs/2509.16028", "authors": ["Sang Hoon Woo", "Sehun Lee", "Kang-wook Kim", "Gunhee Kim"], "title": "Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech", "comment": "EMNLP 2025 Main. Project page: https://yhytoto12.github.io/TVS-ReVerT", "summary": "Spoken dialogue systems increasingly employ large language models (LLMs) to\nleverage their advanced reasoning capabilities. However, direct application of\nLLMs in spoken communication often yield suboptimal results due to mismatches\nbetween optimal textual and verbal delivery. While existing approaches adapt\nLLMs to produce speech-friendly outputs, their impact on reasoning performance\nremains underexplored. In this work, we propose Think-Verbalize-Speak, a\nframework that decouples reasoning from spoken delivery to preserve the full\nreasoning capacity of LLMs. Central to our method is verbalizing, an\nintermediate step that translates thoughts into natural, speech-ready text. We\nalso introduce ReVerT, a latency-efficient verbalizer based on incremental and\nasynchronous summarization. Experiments across multiple benchmarks show that\nour method enhances speech naturalness and conciseness with minimal impact on\nreasoning. The project page with the dataset and the source code is available\nat https://yhytoto12.github.io/TVS-ReVerT", "AI": {"tldr": "\u63d0\u51fa\u4e86Think-Verbalize-Speak\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u63a8\u7406\u4e0e\u8bed\u97f3\u8f93\u51fa\u89e3\u8026\u6765\u4fdd\u7559LLMs\u7684\u5b8c\u6574\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5f15\u5165ReVerT\u4f5c\u4e3a\u5ef6\u8fdf\u9ad8\u6548\u7684\u8a00\u8bed\u5316\u5668\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5c06LLMs\u5e94\u7528\u4e8e\u8bed\u97f3\u5bf9\u8bdd\u65f6\uff0c\u7531\u4e8e\u6587\u672c\u548c\u8bed\u97f3\u4f20\u9012\u65b9\u5f0f\u7684\u4e0d\u5339\u914d\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u5bf9\u63a8\u7406\u6027\u80fd\u7684\u5f71\u54cd\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u601d\u8003\uff08\u63a8\u7406\uff09-\u8a00\u8bed\u5316\uff08\u8f6c\u6362\u4e3a\u8bed\u97f3\u53cb\u597d\u6587\u672c\uff09-\u8bf4\u8bdd\uff08\u8bed\u97f3\u8f93\u51fa\uff09\uff0c\u6838\u5fc3\u662fReVerT\u8a00\u8bed\u5316\u5668\uff0c\u57fa\u4e8e\u589e\u91cf\u5f02\u6b65\u6458\u8981\u6280\u672f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bed\u97f3\u81ea\u7136\u5ea6\u548c\u7b80\u6d01\u6027\uff0c\u540c\u65f6\u5bf9\u63a8\u7406\u6027\u80fd\u5f71\u54cd\u6700\u5c0f\u3002", "conclusion": "\u89e3\u8026\u63a8\u7406\u548c\u8bed\u97f3\u4f20\u9012\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5e73\u8861LLMs\u7684\u63a8\u7406\u80fd\u529b\u548c\u8bed\u97f3\u8f93\u51fa\u8d28\u91cf\u3002", "topic": "agent analysis"}}
{"id": "2509.15927", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.15927", "abs": "https://arxiv.org/abs/2509.15927", "authors": ["Zhiyu Mou", "Yiqin Lv", "Miao Xu", "Cheems Wang", "Yixiu Mao", "Qichen Ye", "Chao Li", "Rongquan Bai", "Chuan Yu", "Jian Xu", "Bo Zheng"], "title": "Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search", "comment": null, "summary": "Auto-bidding is an essential tool for advertisers to enhance their\nadvertising performance. Recent progress has shown that AI-Generated Bidding\n(AIGB), which formulates the auto-bidding as a trajectory generation task and\ntrains a conditional diffusion-based planner on offline data, achieves superior\nand stable performance compared to typical offline reinforcement learning\n(RL)-based auto-bidding methods. However, existing AIGB methods still encounter\na performance bottleneck due to their neglect of fine-grained generation\nquality evaluation and inability to explore beyond static datasets. To address\nthis, we propose AIGB-Pearl (\\emph{Planning with EvAluator via RL}), a novel\nmethod that integrates generative planning and policy optimization. The key to\nAIGB-Pearl is to construct a non-bootstrapped \\emph{trajectory evaluator} to\nassign rewards and guide policy search, enabling the planner to optimize its\ngeneration quality iteratively through interaction. Furthermore, to enhance\ntrajectory evaluator accuracy in offline settings, we incorporate three key\ntechniques: (i) a Large Language Model (LLM)-based architecture for better\nrepresentational capacity, (ii) hybrid point-wise and pair-wise losses for\nbetter score learning, and (iii) adaptive integration of expert feedback for\nbetter generalization ability. Extensive experiments on both simulated and\nreal-world advertising systems demonstrate the state-of-the-art performance of\nour approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAIGB-Pearl\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u751f\u6210\u5f0f\u89c4\u5212\u548c\u7b56\u7565\u4f18\u5316\u6765\u89e3\u51b3\u73b0\u6709AI\u751f\u6210\u7ade\u4ef7\u65b9\u6cd5\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u751f\u6210\u7ade\u4ef7\u65b9\u6cd5\u56e0\u5ffd\u89c6\u7ec6\u7c92\u5ea6\u751f\u6210\u8d28\u91cf\u8bc4\u4f30\u548c\u65e0\u6cd5\u8d85\u8d8a\u9759\u6001\u6570\u636e\u96c6\u63a2\u7d22\u800c\u9047\u5230\u6027\u80fd\u74f6\u9888\u3002", "method": "\u6784\u5efa\u975e\u81ea\u4e3e\u7684\u8f68\u8ff9\u8bc4\u4f30\u5668\u6765\u5206\u914d\u5956\u52b1\u548c\u6307\u5bfc\u7b56\u7565\u641c\u7d22\uff0c\u901a\u8fc7\u4ea4\u4e92\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u8d28\u91cf\u3002\u91c7\u7528LLM\u67b6\u6784\u3001\u6df7\u5408\u70b9\u5bf9\u548c\u914d\u5bf9\u635f\u5931\u3001\u4e13\u5bb6\u53cd\u9988\u81ea\u9002\u5e94\u96c6\u6210\u4e09\u9879\u5173\u952e\u6280\u672f\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u5e7f\u544a\u7cfb\u7edf\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "AIGB-Pearl\u901a\u8fc7\u96c6\u6210\u751f\u6210\u89c4\u5212\u548c\u7b56\u7565\u4f18\u5316\uff0c\u5728\u81ea\u52a8\u7ade\u4ef7\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.15965", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.15965", "abs": "https://arxiv.org/abs/2509.15965", "authors": ["Chao Yu", "Yuanqing Wang", "Zhen Guo", "Hao Lin", "Si Xu", "Hongzhi Zang", "Quanlu Zhang", "Yongji Wu", "Chunyang Zhu", "Junhao Hu", "Zixiao Huang", "Mingjie Wei", "Yuqing Xie", "Ke Yang", "Bo Dai", "Zhexuan Xu", "Xiangyuan Wang", "Xu Fu", "Zhihao Liu", "Kang Chen", "Weilin Liu", "Gang Liu", "Boxun Li", "Jianlei Yang", "Zhi Yang", "Guohao Dai", "Yu Wang"], "title": "RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation", "comment": "GitHub Repo: https://github.com/RLinf/RLinf", "summary": "Reinforcement learning (RL) has demonstrated immense potential in advancing\nartificial general intelligence, agentic intelligence, and embodied\nintelligence. However, the inherent heterogeneity and dynamicity of RL\nworkflows often lead to low hardware utilization and slow training on existing\nsystems. In this paper, we present RLinf, a high-performance RL training system\nbased on our key observation that the major roadblock to efficient RL training\nlies in system flexibility. To maximize flexibility and efficiency, RLinf is\nbuilt atop a novel RL system design paradigm called macro-to-micro flow\ntransformation (M2Flow), which automatically breaks down high-level,\neasy-to-compose RL workflows at both the temporal and spatial dimensions, and\nrecomposes them into optimized execution flows. Supported by RLinf worker's\nadaptive communication capability, we devise context switching and elastic\npipelining to realize M2Flow transformation, and a profiling-guided scheduling\npolicy to generate optimal execution plans. Extensive evaluations on both\nreasoning RL and embodied RL tasks demonstrate that RLinf consistently\noutperforms state-of-the-art systems, achieving 1.1x-2.13x speedup in\nend-to-end training throughput.", "AI": {"tldr": "RLinf\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b8f\u5fae\u89c2\u6d41\u8f6c\u6362\uff08M2Flow\uff09\u7684\u9ad8\u6027\u80fd\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u52a8\u5206\u89e3\u548c\u91cd\u7ec4RL\u5de5\u4f5c\u6d41\u6765\u63d0\u5347\u786c\u4ef6\u5229\u7528\u7387\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u5728\u63a8\u7406RL\u548c\u5177\u8eabRL\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e861.1x-2.13x\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u52a0\u901f\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5de5\u4f5c\u6d41\u7684\u5f02\u6784\u6027\u548c\u52a8\u6001\u6027\u5bfc\u81f4\u73b0\u6709\u7cfb\u7edf\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u3001\u8bad\u7ec3\u901f\u5ea6\u6162\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u7cfb\u7edf\u7075\u6d3b\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faM2Flow\u8bbe\u8ba1\u8303\u5f0f\uff0c\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u7ef4\u5ea6\u81ea\u52a8\u5206\u89e3\u9ad8\u7ea7RL\u5de5\u4f5c\u6d41\u5e76\u91cd\u7ec4\u4e3a\u4f18\u5316\u6267\u884c\u6d41\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u901a\u4fe1\u3001\u4e0a\u4e0b\u6587\u5207\u6362\u3001\u5f39\u6027\u6d41\u6c34\u7ebf\u548c\u57fa\u4e8e\u6027\u80fd\u5206\u6790\u7684\u8c03\u5ea6\u7b56\u7565\u3002", "result": "\u5728\u63a8\u7406RL\u548c\u5177\u8eabRL\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u663e\u793a\uff0cRLinf\u6301\u7eed\u4f18\u4e8e\u6700\u5148\u8fdb\u7cfb\u7edf\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u53471.1x-2.13x\u3002", "conclusion": "RLinf\u901a\u8fc7M2Flow\u8303\u5f0f\u6709\u6548\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684\u7cfb\u7edf\u7075\u6d3b\u6027\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u786c\u4ef6\u5229\u7528\u7387\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.15981", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.15981", "abs": "https://arxiv.org/abs/2509.15981", "authors": ["Yujie Zhu", "Charles A. Hepburn", "Matthew Thorpe", "Giovanni Montana"], "title": "Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations", "comment": null, "summary": "In reinforcement learning with sparse rewards, demonstrations can accelerate\nlearning, but determining when to imitate them remains challenging. We propose\nSmooth Policy Regularisation from Demonstrations (SPReD), a framework that\naddresses the fundamental question: when should an agent imitate a\ndemonstration versus follow its own policy? SPReD uses ensemble methods to\nexplicitly model Q-value distributions for both demonstration and policy\nactions, quantifying uncertainty for comparisons. We develop two complementary\nuncertainty-aware methods: a probabilistic approach estimating the likelihood\nof demonstration superiority, and an advantage-based approach scaling imitation\nby statistical significance. Unlike prevailing methods (e.g. Q-filter) that\nmake binary imitation decisions, SPReD applies continuous,\nuncertainty-proportional regularisation weights, reducing gradient variance\nduring training. Despite its computational simplicity, SPReD achieves\nremarkable gains in experiments across eight robotics tasks, outperforming\nexisting approaches by up to a factor of 14 in complex tasks while maintaining\nrobustness to demonstration quality and quantity. Our code is available at\nhttps://github.com/YujieZhu7/SPReD.", "AI": {"tldr": "SPReD\u662f\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u65b9\u6cd5\u5efa\u6a21Q\u503c\u5206\u5e03\uff0c\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u65b9\u6cd5\u51b3\u5b9a\u4f55\u65f6\u6a21\u4eff\u6f14\u793a\u800c\u975e\u9075\u5faa\u81ea\u8eab\u7b56\u7565\uff0c\u5b9e\u73b0\u8fde\u7eed\u800c\u975e\u4e8c\u8fdb\u5236\u7684\u6a21\u4eff\u51b3\u7b56\u3002", "motivation": "\u5728\u7a00\u758f\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u6f14\u793a\u53ef\u4ee5\u52a0\u901f\u5b66\u4e60\uff0c\u4f46\u786e\u5b9a\u4f55\u65f6\u6a21\u4eff\u6f14\u793a\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\uff08\u5982Q-filter\uff09\u505a\u51fa\u4e8c\u8fdb\u5236\u6a21\u4eff\u51b3\u7b56\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u96c6\u6210\u65b9\u6cd5\u663e\u5f0f\u5efa\u6a21\u6f14\u793a\u548c\u7b56\u7565\u52a8\u4f5c\u7684Q\u503c\u5206\u5e03\uff0c\u5f00\u53d1\u4e24\u79cd\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u65b9\u6cd5\uff1a\u6982\u7387\u65b9\u6cd5\u4f30\u8ba1\u6f14\u793a\u4f18\u8d8a\u6027\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u53ca\u57fa\u4e8e\u4f18\u52bf\u7684\u65b9\u6cd5\u6309\u7edf\u8ba1\u663e\u8457\u6027\u7f29\u653e\u6a21\u4eff\u3002", "result": "\u5728\u516b\u4e2a\u673a\u5668\u4eba\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cSPReD\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u8fbe14\u500d\uff0c\u540c\u65f6\u5bf9\u6f14\u793a\u8d28\u91cf\u548c\u6570\u91cf\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "SPReD\u901a\u8fc7\u8fde\u7eed\u3001\u4e0d\u786e\u5b9a\u6027\u6bd4\u4f8b\u7684\u6b63\u5219\u5316\u6743\u91cd\u51cf\u5c11\u4e86\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u65b9\u5dee\uff0c\u5c3d\u7ba1\u8ba1\u7b97\u7b80\u5355\u4f46\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.15828", "categories": ["cs.LG", "cs.DM"], "pdf": "https://arxiv.org/pdf/2509.15828", "abs": "https://arxiv.org/abs/2509.15828", "authors": ["Ning Xu", "Junkai Zhang", "Yang Wu", "Huigen Ye", "Hua Xu", "Huiling Xu", "Yifan Zhang"], "title": "HyP-ASO: A Hybrid Policy-based Adaptive Search Optimization Framework for Large-Scale Integer Linear Programs", "comment": null, "summary": "Directly solving large-scale Integer Linear Programs (ILPs) using traditional\nsolvers is slow due to their NP-hard nature. While recent frameworks based on\nLarge Neighborhood Search (LNS) can accelerate the solving process, their\nperformance is often constrained by the difficulty in generating sufficiently\neffective neighborhoods. To address this challenge, we propose HyP-ASO, a\nhybrid policy-based adaptive search optimization framework that combines a\ncustomized formula with deep Reinforcement Learning (RL). The formula leverages\nfeasible solutions to calculate the selection probabilities for each variable\nin the neighborhood generation process, and the RL policy network predicts the\nneighborhood size. Extensive experiments demonstrate that HyP-ASO significantly\noutperforms existing LNS-based approaches for large-scale ILPs. Additional\nexperiments show it is lightweight and highly scalable, making it well-suited\nfor solving large-scale ILPs.", "AI": {"tldr": "HyP-ASO\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df7\u5408\u7b56\u7565\u7684\u81ea\u9002\u5e94\u641c\u7d22\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u5b9a\u5236\u516c\u5f0f\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6765\u52a0\u901f\u5927\u89c4\u6a21\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u7684\u6c42\u89e3\u3002", "motivation": "\u4f20\u7edf\u6c42\u89e3\u5668\u89e3\u51b3\u5927\u89c4\u6a21\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u901f\u5ea6\u6162\uff0c\u800c\u73b0\u6709\u7684\u5927\u90bb\u57df\u641c\u7d22\u6846\u67b6\u6027\u80fd\u53d7\u9650\u4e8e\u96be\u4ee5\u751f\u6210\u8db3\u591f\u6709\u6548\u7684\u90bb\u57df\u3002", "method": "\u63d0\u51faHyP-ASO\u6846\u67b6\uff0c\u4f7f\u7528\u5b9a\u5236\u516c\u5f0f\u8ba1\u7b97\u53d8\u91cf\u9009\u62e9\u6982\u7387\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7f51\u7edc\u9884\u6d4b\u90bb\u57df\u5927\u5c0f\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHyP-ASO\u5728\u5927\u89c4\u6a21\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8eLNS\u7684\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u8f7b\u91cf\u7ea7\u548c\u9ad8\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "HyP-ASO\u662f\u89e3\u51b3\u5927\u89c4\u6a21\u6574\u6570\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u7684\u6709\u6548\u6846\u67b6\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u53ef\u6269\u5c55\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.16060", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.16060", "abs": "https://arxiv.org/abs/2509.16060", "authors": ["Maithili Joshi", "Palash Nandi", "Tanmoy Chakraborty"], "title": "SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection", "comment": "Accepted in EMNLP'25 Main", "summary": "Large Language Models (LLMs) with safe-alignment training are powerful\ninstruments with robust language comprehension capabilities. These models\ntypically undergo meticulous alignment procedures involving human feedback to\nensure the acceptance of safe inputs while rejecting harmful or unsafe ones.\nHowever, despite their massive scale and alignment efforts, LLMs remain\nvulnerable to jailbreak attacks, where malicious users manipulate the model to\nproduce harmful outputs that it was explicitly trained to avoid. In this study,\nwe find that the safety mechanisms in LLMs are predominantly embedded in the\nmiddle-to-late layers. Building on this insight, we introduce a novel white-box\njailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which\nconnects two intermediate layers $s$ and $e$ such that $s < e$, through a\nresidual connection. Our approach achieves a 51% improvement over the\nbest-performing baseline on the HarmBench test set. Furthermore, SABER induces\nonly a marginal shift in perplexity when evaluated on the HarmBench validation\nset. The source code is publicly available at\nhttps://github.com/PalGitts/SABER.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSABER\u7684\u767d\u76d2\u8d8a\u72f1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728LLM\u4e2d\u95f4\u5c42\u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5\u6765\u7ed5\u8fc7\u5b89\u5168\u5bf9\u9f50\u673a\u5236\uff0c\u5728HarmBench\u6d4b\u8bd5\u96c6\u4e0a\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e8651%\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1LLMs\u7ecf\u8fc7\u4e25\u683c\u7684\u5b89\u5168\u5bf9\u9f50\u8bad\u7ec3\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\u3002\u7814\u7a76\u53d1\u73b0LLMs\u7684\u5b89\u5168\u673a\u5236\u4e3b\u8981\u5d4c\u5165\u5728\u4e2d\u540e\u5c42\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u9488\u5bf9\u6027\u653b\u51fb\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "SABER\u65b9\u6cd5\u901a\u8fc7\u5728\u4e24\u4e2a\u4e2d\u95f4\u5c42s\u548ce\uff08s < e\uff09\u4e4b\u95f4\u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5\uff0c\u76f4\u63a5\u7ed5\u8fc7\u5b89\u5168\u5bf9\u9f50\u673a\u5236\uff0c\u662f\u4e00\u79cd\u767d\u76d2\u653b\u51fb\u65b9\u6cd5\u3002", "result": "\u5728HarmBench\u6d4b\u8bd5\u96c6\u4e0a\uff0cSABER\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u4e8651%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u5728\u9a8c\u8bc1\u96c6\u4e0a\u4ec5\u5f15\u8d77\u8fb9\u9645\u56f0\u60d1\u5ea6\u53d8\u5316\u3002", "conclusion": "SABER\u8bc1\u660e\u4e86LLMs\u5b89\u5168\u673a\u5236\u7684\u8106\u5f31\u6027\uff0c\u7279\u522b\u662f\u5728\u4e2d\u95f4\u5c42\uff0c\u4e3a\u6539\u8fdbLLM\u5b89\u5168\u5bf9\u9f50\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002", "topic": "agent analysis"}}
{"id": "2509.16117", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.16117", "abs": "https://arxiv.org/abs/2509.16117", "authors": ["Kaiwen Zheng", "Huayu Chen", "Haotian Ye", "Haoxiang Wang", "Qinsheng Zhang", "Kai Jiang", "Hang Su", "Stefano Ermon", "Jun Zhu", "Ming-Yu Liu"], "title": "DiffusionNFT: Online Diffusion Reinforcement with Forward Process", "comment": null, "summary": "Online reinforcement learning (RL) has been central to post-training language\nmodels, but its extension to diffusion models remains challenging due to\nintractable likelihoods. Recent works discretize the reverse sampling process\nto enable GRPO-style training, yet they inherit fundamental drawbacks,\nincluding solver restrictions, forward-reverse inconsistency, and complicated\nintegration with classifier-free guidance (CFG). We introduce Diffusion\nNegative-aware FineTuning (DiffusionNFT), a new online RL paradigm that\noptimizes diffusion models directly on the forward process via flow matching.\nDiffusionNFT contrasts positive and negative generations to define an implicit\npolicy improvement direction, naturally incorporating reinforcement signals\ninto the supervised learning objective. This formulation enables training with\narbitrary black-box solvers, eliminates the need for likelihood estimation, and\nrequires only clean images rather than sampling trajectories for policy\noptimization. DiffusionNFT is up to $25\\times$ more efficient than FlowGRPO in\nhead-to-head comparisons, while being CFG-free. For instance, DiffusionNFT\nimproves the GenEval score from 0.24 to 0.98 within 1k steps, while FlowGRPO\nachieves 0.95 with over 5k steps and additional CFG employment. By leveraging\nmultiple reward models, DiffusionNFT significantly boosts the performance of\nSD3.5-Medium in every benchmark tested.", "AI": {"tldr": "DiffusionNFT\u662f\u4e00\u79cd\u65b0\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u76f4\u63a5\u5728\u6b63\u5411\u8fc7\u7a0b\u4e2d\u4f18\u5316\u6269\u6563\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6269\u6563\u6a21\u578b\u4e2d\u5e94\u7528RL\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u6269\u6563\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u56f0\u96be\uff0c\u5305\u62ec\u6c42\u89e3\u5668\u9650\u5236\u3001\u6b63\u5411-\u53cd\u5411\u4e0d\u4e00\u81f4\u6027\u4ee5\u53ca\u4e0e\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\u7684\u590d\u6742\u96c6\u6210\u95ee\u9898\u3002", "method": "DiffusionNFT\u901a\u8fc7\u6d41\u5339\u914d\u5728\u6b63\u5411\u8fc7\u7a0b\u4e2d\u4f18\u5316\u6269\u6563\u6a21\u578b\uff0c\u5bf9\u6bd4\u6b63\u8d1f\u751f\u6210\u6765\u5b9a\u4e49\u9690\u5f0f\u7b56\u7565\u6539\u8fdb\u65b9\u5411\uff0c\u5c06\u5f3a\u5316\u4fe1\u53f7\u81ea\u7136\u878d\u5165\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u3002", "result": "DiffusionNFT\u6bd4FlowGRPO\u6548\u7387\u63d0\u534725\u500d\uff0c\u57281k\u6b65\u5185\u5c06GenEval\u5206\u6570\u4ece0.24\u63d0\u5347\u52300.98\uff0c\u800cFlowGRPO\u9700\u8981\u8d85\u8fc75k\u6b65\u548c\u989d\u5916CFG\u624d\u80fd\u8fbe\u52300.95\u3002\u4f7f\u7528\u591a\u4e2a\u5956\u52b1\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86SD3.5-Medium\u5728\u6240\u6709\u6d4b\u8bd5\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "DiffusionNFT\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001CFG-free\u7684\u6269\u6563\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u6839\u672c\u7f3a\u9677\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2509.16151", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.16151", "abs": "https://arxiv.org/abs/2509.16151", "authors": ["Isaiah J. King", "Benjamin Bowman", "H. Howie Huang"], "title": "Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents", "comment": null, "summary": "Deep reinforcement learning (RL) is emerging as a viable strategy for\nautomated cyber defense (ACD). The traditional RL approach represents networks\nas a list of computers in various states of safety or threat. Unfortunately,\nthese models are forced to overfit to specific network topologies, rendering\nthem ineffective when faced with even small environmental perturbations. In\nthis work, we frame ACD as a two-player context-based partially observable\nMarkov decision problem with observations represented as attributed graphs.\nThis approach allows our agents to reason through the lens of relational\ninductive bias. Agents learn how to reason about hosts interacting with other\nsystem entities in a more general manner, and their actions are understood as\nedits to the graph representing the environment. By introducing this bias, we\nwill show that our agents can better reason about the states of networks and\nzero-shot adapt to new ones. We show that this approach outperforms the\nstate-of-the-art by a wide margin, and makes our agents capable of defending\nnever-before-seen networks against a wide range of adversaries in a variety of\ncomplex, and multi-agent environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u8868\u793a\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u7f51\u7edc\u9632\u5fa1\uff0c\u901a\u8fc7\u5173\u7cfb\u5f52\u7eb3\u504f\u7f6e\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u96f6\u6837\u672c\u9002\u5e94\u65b0\u7f51\u7edc\u62d3\u6251\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u7f51\u7edc\u9632\u5fa1\u4e2d\u8fc7\u5ea6\u62df\u5408\u7279\u5b9a\u7f51\u7edc\u62d3\u6251\uff0c\u65e0\u6cd5\u5e94\u5bf9\u73af\u5883\u6270\u52a8\u3002\u9700\u8981\u4e00\u79cd\u66f4\u901a\u7528\u7684\u8868\u793a\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5c06\u81ea\u52a8\u5316\u7f51\u7edc\u9632\u5fa1\u5efa\u6a21\u4e3a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u95ee\u9898\uff0c\u4f7f\u7528\u5c5e\u6027\u56fe\u8868\u793a\u89c2\u6d4b\uff0c\u667a\u80fd\u4f53\u901a\u8fc7\u56fe\u7f16\u8f91\u52a8\u4f5c\u8fdb\u884c\u9632\u5fa1\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u590d\u6742\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u6280\u672f\uff0c\u80fd\u591f\u9632\u5fa1\u4ece\u672a\u89c1\u8fc7\u7684\u7f51\u7edc\u5bf9\u6297\u5404\u79cd\u653b\u51fb\u8005\u3002", "conclusion": "\u57fa\u4e8e\u56fe\u8868\u793a\u7684\u5173\u7cfb\u5f52\u7eb3\u504f\u7f6e\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7f51\u7edc\u9632\u5fa1\u667a\u80fd\u4f53\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9002\u5e94\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2509.e2181403", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Felma.dev%2Fnotes%2Fai-makes-seniors-stronger%2F%3Futm_source=tldrdata/1/0100019970e3d754-1f14bda1-e012-403a-bce4-3faf7f0b0e16-000000/ceIVN-mjGXM52OA6lyAHx20AyOOcvvGgEdmpJJ-DuAM=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Felma.dev%2Fnotes%2Fai-makes-seniors-stronger%2F%3Futm_source=tldrdata/1/0100019970e3d754-1f14bda1-e012-403a-bce4-3faf7f0b0e16-000000/ceIVN-mjGXM52OA6lyAHx20AyOOcvvGgEdmpJJ-DuAM=423", "authors": ["TLDR Newsletter"], "title": "AI Was Supposed to Help Juniors Shine. Why Does It Mostly Make Seniors Stronger?", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Felma.dev%2Fnotes%2Fai-makes-seniors-stronger%2F%3Futm_source=tldrdata/1/0100019970e3d754-1f14bda1-e012-403a-bce4-3faf7f0b0e16-000000/ceIVN-mjGXM52OA6lyAHx20AyOOcvvGgEdmpJJ-DuAM=423", "summary": "AI Was Supposed to Help Juniors Shine. Why Does It Mostly Make Seniors Stronger? (4 minute read) AI currently enhances the productivity of senior developers more than juniors, as it excels in automating repetitive tasks and fast prototyping, but struggles with code quality, architecture, and security. The expectation that AI would empower juniors has proven unrealistic, highlighting the need for experienced engineers to guide and interpret AI outputs to avoid potential pitfalls in software de...", "source": "tldr", "AI": {"tldr": "AI\u76ee\u524d\u66f4\u591a\u589e\u5f3a\u8d44\u6df1\u5f00\u53d1\u8005\u7684\u751f\u4ea7\u529b\u800c\u975e\u521d\u7ea7\u5f00\u53d1\u8005\uff0c\u4e3b\u8981\u64c5\u957f\u81ea\u52a8\u5316\u91cd\u590d\u4efb\u52a1\u548c\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\uff0c\u4f46\u5728\u4ee3\u7801\u8d28\u91cf\u3001\u67b6\u6784\u548c\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3", "motivation": "\u63a2\u8ba8AI\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5bf9\u521d\u7ea7\u548c\u8d44\u6df1\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5dee\u5f02\u5316\u5f71\u54cd", "method": "\u5206\u6790AI\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u5404\u73af\u8282\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u6bd4\u8f83\u5176\u5bf9\u4e0d\u540c\u7ecf\u9a8c\u6c34\u5e73\u5f00\u53d1\u8005\u7684\u5e2e\u52a9\u7a0b\u5ea6", "result": "AI\u4e3b\u8981\u589e\u5f3a\u8d44\u6df1\u5f00\u53d1\u8005\u7684\u751f\u4ea7\u529b\uff0c\u5bf9\u521d\u7ea7\u5f00\u53d1\u8005\u7684\u5e2e\u52a9\u6709\u9650\uff0c\u9700\u8981\u8d44\u6df1\u5de5\u7a0b\u5e08\u6307\u5bfcAI\u8f93\u51fa\u4ee5\u907f\u514d\u6f5c\u5728\u95ee\u9898", "conclusion": "AI\u5e76\u672a\u5982\u9884\u671f\u90a3\u6837\u8d4b\u80fd\u521d\u7ea7\u5f00\u53d1\u8005\uff0c\u53cd\u800c\u5f3a\u5316\u4e86\u8d44\u6df1\u5f00\u53d1\u8005\u7684\u4f18\u52bf\u5730\u4f4d\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u5728\u56e2\u961f\u4e2d\u7684\u89d2\u8272\u5b9a\u4f4d", "topic": "agent analysis"}}
{"id": "tldr.2509.7db8e367", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.galois.com%2Farticles%2Fclaude-can-sometimes-prove-it%3Futm_source=tldrwebdev/1/01000199712f9275-e0609338-0204-4d9f-9595-4fedb2997d27-000000/pVvOyrPA1jtn5z7WD058jajzSJ2Gw0xbw9QnOpI_4W4=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.galois.com%2Farticles%2Fclaude-can-sometimes-prove-it%3Futm_source=tldrwebdev/1/01000199712f9275-e0609338-0204-4d9f-9595-4fedb2997d27-000000/pVvOyrPA1jtn5z7WD058jajzSJ2Gw0xbw9QnOpI_4W4=423", "authors": ["TLDR Newsletter"], "title": "Claude Can Prove It", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Reading time: 19 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.galois.com%2Farticles%2Fclaude-can-sometimes-prove-it%3Futm_source=tldrwebdev/1/01000199712f9275-e0609338-0204-4d9f-9595-4fedb2997d27-000000/pVvOyrPA1jtn5z7WD058jajzSJ2Gw0xbw9QnOpI_4W4=423", "summary": "Claude Can (Sometimes) Prove It (19 minute read) Claude Code is quite good at interactive theorem proving (ITP), a difficult formal method used to verify critical systems. Claude Code can complete complex proof steps independently, but still requires human guidance for the overall formalization. This points towards a future where ITP is more accessible and doesn't require expert knowledge.", "source": "tldr", "AI": {"tldr": "Claude Code\u5728\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\uff08ITP\uff09\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u72ec\u7acb\u5b8c\u6210\u590d\u6742\u8bc1\u660e\u6b65\u9aa4\uff0c\u4f46\u4ecd\u9700\u4eba\u7c7b\u6307\u5bfc\u6574\u4f53\u5f62\u5f0f\u5316\u8fc7\u7a0b\u3002", "motivation": "\u63a2\u7d22AI\u5728\u5f62\u5f0f\u5316\u65b9\u6cd5\u9886\u57df\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5982\u4f55\u8ba9\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u8fd9\u4e00\u9ad8\u96be\u5ea6\u6280\u672f\u53d8\u5f97\u66f4\u52a0\u6613\u4e8e\u4f7f\u7528\uff0c\u964d\u4f4e\u5bf9\u4e13\u5bb6\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002", "method": "\u4f7f\u7528Claude Code\u8fdb\u884c\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5176\u5728\u72ec\u7acb\u5b8c\u6210\u8bc1\u660e\u6b65\u9aa4\u548c\u9700\u8981\u4eba\u7c7b\u6307\u5bfc\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "Claude Code\u5728\u5b8c\u6210\u590d\u6742\u8bc1\u660e\u6b65\u9aa4\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6574\u4f53\u5f62\u5f0f\u5316\u8fc7\u7a0b\u4e2d\u4ecd\u9700\u8981\u4eba\u7c7b\u4e13\u5bb6\u7684\u6307\u5bfc\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660eAI\u6709\u6f5c\u529b\u8ba9\u4ea4\u4e92\u5f0f\u5b9a\u7406\u8bc1\u660e\u6280\u672f\u66f4\u52a0\u666e\u53ca\u548c\u6613\u7528\uff0c\u4f46\u5b8c\u5168\u81ea\u52a8\u5316\u4ecd\u9762\u4e34\u6311\u6218\u3002", "topic": "agent analysis"}}
{"id": "tldr.2509.db2fdbfe", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.codeintegrity.ai%2Fblog%2Fnotion%3Futm_source=tldrwebdev/1/01000199712f9275-e0609338-0204-4d9f-9595-4fedb2997d27-000000/Wbm2Cq1272G6OygV4bNCxV2IAE9a-oDDXioP2ZXed28=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.codeintegrity.ai%2Fblog%2Fnotion%3Futm_source=tldrwebdev/1/01000199712f9275-e0609338-0204-4d9f-9595-4fedb2997d27-000000/Wbm2Cq1272G6OygV4bNCxV2IAE9a-oDDXioP2ZXed28=423", "authors": ["TLDR Newsletter"], "title": "The Hidden Risk in Notion 3.0 AI Agents: Web Search Tool Abuse for Data Exfiltration", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Reading time: 6 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.codeintegrity.ai%2Fblog%2Fnotion%3Futm_source=tldrwebdev/1/01000199712f9275-e0609338-0204-4d9f-9595-4fedb2997d27-000000/Wbm2Cq1272G6OygV4bNCxV2IAE9a-oDDXioP2ZXed28=423", "summary": "The Hidden Risk in Notion 3.0 AI Agents: Web Search Tool Abuse for Data Exfiltration (6 minute read) CodeIntegrity discovered a vulnerability in Notion 3.0's AI Agents related to its web search tool that allows for data exfiltration. By embedding a malicious prompt within a seemingly harmless PDF, attackers can trick the AI agent into querying a controlled server with sensitive data extracted from the user's Notion pages. This indirect prompt injection attack exploits the agent's tool access.", "source": "tldr", "AI": {"tldr": "Notion 3.0 AI\u4ee3\u7406\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u6076\u610fPDF\u6587\u4ef6\u95f4\u63a5\u6ce8\u5165\u63d0\u793a\uff0c\u5229\u7528\u7f51\u7edc\u641c\u7d22\u5de5\u5177\u8fdb\u884c\u6570\u636e\u6cc4\u9732\u3002", "motivation": "\u53d1\u73b0Notion 3.0 AI\u4ee3\u7406\u5728\u7f51\u7edc\u641c\u7d22\u5de5\u5177\u4f7f\u7528\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63ed\u793a\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5bf9\u7528\u6237\u654f\u611f\u6570\u636e\u7684\u5a01\u80c1\u3002", "method": "\u901a\u8fc7\u5728\u770b\u4f3c\u65e0\u5bb3\u7684PDF\u6587\u4ef6\u4e2d\u5d4c\u5165\u6076\u610f\u63d0\u793a\uff0c\u8bf1\u4f7fAI\u4ee3\u7406\u5411\u653b\u51fb\u8005\u63a7\u5236\u7684\u670d\u52a1\u5668\u67e5\u8be2\u4ece\u7528\u6237Notion\u9875\u9762\u63d0\u53d6\u7684\u654f\u611f\u6570\u636e\u3002", "result": "\u6210\u529f\u6f14\u793a\u4e86\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u6b64\u6f0f\u6d1e\u7a83\u53d6\u7528\u6237Notion\u9875\u9762\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u3002", "conclusion": "Notion 3.0 AI\u4ee3\u7406\u7684\u7f51\u7edc\u641c\u7d22\u5de5\u5177\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u52a0\u5f3a\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u9632\u6b62\u6570\u636e\u6cc4\u9732\u3002", "topic": "agent analysis"}}
{"id": "tldr.2509.0e0b0807", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fuxmag.com%2Farticles%2Fthe-nervous-system-for-ai-why-every-product-manager-and-designer-needs-an-agent-runtime-environment%3Futm_source=tldrdesign/1/0100019971518921-7d9b81e5-6072-430c-9062-77f08a1850d6-000000/BqhQNaNqQDSWQcqS9g6u9VNPac8DBLLvZqrkfqhsad0=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fuxmag.com%2Farticles%2Fthe-nervous-system-for-ai-why-every-product-manager-and-designer-needs-an-agent-runtime-environment%3Futm_source=tldrdesign/1/0100019971518921-7d9b81e5-6072-430c-9062-77f08a1850d6-000000/BqhQNaNqQDSWQcqS9g6u9VNPac8DBLLvZqrkfqhsad0=423", "authors": ["TLDR Newsletter"], "title": "The Nervous System for AI: Why Every Product Manager and Designer Needs an Agent Runtime Environment", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Reading time: 6 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fuxmag.com%2Farticles%2Fthe-nervous-system-for-ai-why-every-product-manager-and-designer-needs-an-agent-runtime-environment%3Futm_source=tldrdesign/1/0100019971518921-7d9b81e5-6072-430c-9062-77f08a1850d6-000000/BqhQNaNqQDSWQcqS9g6u9VNPac8DBLLvZqrkfqhsad0=423", "summary": "The Nervous System for AI: Why Every Product Manager and Designer Needs an Agent Runtime Environment (6 minute read) AI agents are failing to move from prototypes to production at a 95% rate, primarily due to a lack of a proper AI agent runtime environment that provides memory, orchestration, observability, and guardrails. While experts recommend defining problems clearly and integrating AI into workflows, these efforts collapse without the foundational runtime infrastructure that serves as t...", "source": "tldr", "AI": {"tldr": "AI\u4ee3\u7406\u4ece\u539f\u578b\u5230\u751f\u4ea7\u7684\u5931\u8d25\u7387\u9ad8\u8fbe95%\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u5408\u9002\u7684AI\u4ee3\u7406\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u8be5\u73af\u5883\u5e94\u63d0\u4f9b\u5185\u5b58\u3001\u7f16\u6392\u3001\u53ef\u89c2\u6d4b\u6027\u548c\u9632\u62a4\u673a\u5236\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5728\u4ece\u539f\u578b\u8f6c\u5411\u751f\u4ea7\u8fc7\u7a0b\u4e2d\u9ad8\u5931\u8d25\u7387\u7684\u95ee\u9898\uff0c\u5f3a\u8c03\u8fd0\u884c\u65f6\u57fa\u7840\u8bbe\u65bd\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51fa\u6784\u5efaAI\u4ee3\u7406\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u8be5\u73af\u5883\u5e94\u5305\u542b\u5185\u5b58\u7ba1\u7406\u3001\u5de5\u4f5c\u6d41\u7f16\u6392\u3001\u7cfb\u7edf\u53ef\u89c2\u6d4b\u6027\u548c\u5b89\u5168\u9632\u62a4\u7b49\u6838\u5fc3\u529f\u80fd\u3002", "result": "\u6307\u51fa\u5f53\u524d95%\u7684AI\u4ee3\u7406\u9879\u76ee\u65e0\u6cd5\u6210\u529f\u90e8\u7f72\u5230\u751f\u4ea7\u73af\u5883\uff0c\u51f8\u663e\u4e86\u8fd0\u884c\u65f6\u73af\u5883\u7f3a\u5931\u7684\u4e25\u91cd\u6027\u3002", "conclusion": "\u4ea7\u54c1\u7ecf\u7406\u548c\u8bbe\u8ba1\u5e08\u9700\u8981\u4e3aAI\u4ee3\u7406\u5efa\u7acb\u7c7b\u4f3c\u795e\u7ecf\u7cfb\u7edf\u7684\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u8fd9\u662fAI\u4ee3\u7406\u6210\u529f\u90e8\u7f72\u7684\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u3002", "topic": "agent analysis"}}
{"id": "tldr.2509.c49bd7de", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.atla-ai.com%2F%3Futm_source=tldrfounders/1/0100019971528643-bf07fea5-b7e0-4067-bd56-be66060ae1cc-000000/fDPEL2VysYMHABthScHEK5eP5dioU6lQ2I3d06zyZ54=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.atla-ai.com%2F%3Futm_source=tldrfounders/1/0100019971528643-bf07fea5-b7e0-4067-bd56-be66060ae1cc-000000/fDPEL2VysYMHABthScHEK5eP5dioU6lQ2I3d06zyZ54=423", "authors": ["TLDR Newsletter"], "title": "Atla", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.atla-ai.com%2F%3Futm_source=tldrfounders/1/0100019971528643-bf07fea5-b7e0-4067-bd56-be66060ae1cc-000000/fDPEL2VysYMHABthScHEK5eP5dioU6lQ2I3d06zyZ54=423", "summary": "Atla (Tool) Find and fix AI agent failures.", "source": "tldr", "AI": {"tldr": "Atla\u662f\u4e00\u4e2a\u7528\u4e8e\u53d1\u73b0\u548c\u4fee\u590dAI\u4ee3\u7406\u5931\u8d25\u7684\u5de5\u5177\u3002", "motivation": "\u5f00\u53d1Atla\u7684\u52a8\u673a\u662f\u4e3a\u4e86\u89e3\u51b3AI\u4ee3\u7406\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u5931\u8d25\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u4fee\u590d\u8fd9\u4e9b\u5931\u8d25\uff0c\u4ece\u800c\u63d0\u9ad8AI\u4ee3\u7406\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002", "method": "Atla\u901a\u8fc7\u5206\u6790AI\u4ee3\u7406\u7684\u884c\u4e3a\u548c\u8f93\u51fa\uff0c\u8bc6\u522b\u6f5c\u5728\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u4fee\u590d\u5efa\u8bae\u6216\u81ea\u52a8\u4fee\u590d\u673a\u5236\u3002", "result": "Atla\u80fd\u591f\u6709\u6548\u8bc6\u522bAI\u4ee3\u7406\u7684\u591a\u79cd\u5931\u8d25\u7c7b\u578b\uff0c\u5e76\u63d0\u4f9b\u76f8\u5e94\u7684\u4fee\u590d\u65b9\u6848\uff0c\u63d0\u5347\u4ee3\u7406\u7684\u7a33\u5b9a\u6027\u548c\u6548\u7387\u3002", "conclusion": "Atla\u4f5c\u4e3a\u4e00\u4e2a\u5de5\u5177\uff0c\u4e3aAI\u4ee3\u7406\u7684\u6545\u969c\u8bca\u65ad\u548c\u4fee\u590d\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u4ee3\u7406\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u90e8\u7f72\u3002", "topic": "agent analysis"}}
{"id": "tldr.2509.93994dde", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcommoncog.com%2Fhow-to-use-ai-without-becoming-stupid%3Futm_source=tldrfounders/1/0100019971528643-bf07fea5-b7e0-4067-bd56-be66060ae1cc-000000/xgQwn3gOl0wdiS7o-HZ8SfmqXV099NRxGRI9hpPYMbc=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcommoncog.com%2Fhow-to-use-ai-without-becoming-stupid%3Futm_source=tldrfounders/1/0100019971528643-bf07fea5-b7e0-4067-bd56-be66060ae1cc-000000/xgQwn3gOl0wdiS7o-HZ8SfmqXV099NRxGRI9hpPYMbc=423", "authors": ["TLDR Newsletter"], "title": "How to Use AI Without Becoming Stupid", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Reading time: 6 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcommoncog.com%2Fhow-to-use-ai-without-becoming-stupid%3Futm_source=tldrfounders/1/0100019971528643-bf07fea5-b7e0-4067-bd56-be66060ae1cc-000000/xgQwn3gOl0wdiS7o-HZ8SfmqXV099NRxGRI9hpPYMbc=423", "summary": "How to Use AI Without Becoming Stupid (6 minute read) We trust AI to draft emails, schedule calls, even write code, but the real danger isn't mistakes \u2014 it's letting it choose for us. A simple rule has quietly emerged across classrooms, trading desks, and dev teams: never give up your value judgments. The paradox is that automation works best when it leaves humans more room to decide.", "source": "tldr", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error", "topics": "Error"}}
{"id": "tldr.2509.dfa51481", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.tobyord.com%2Fwriting%2Finefficiency-of-reinforcement-learning%3Futm_source=tldrai/1/0100019971936ea2-b8d0717c-c988-467d-bd3c-df4d52df062a-000000/OEv-gPuYqNi4V4zQDDOnZ_Q9tj74_VKKVt70JBfgAH0=423", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.tobyord.com%2Fwriting%2Finefficiency-of-reinforcement-learning%3Futm_source=tldrai/1/0100019971936ea2-b8d0717c-c988-467d-bd3c-df4d52df062a-000000/OEv-gPuYqNi4V4zQDDOnZ_Q9tj74_VKKVt70JBfgAH0=423", "authors": ["TLDR Newsletter"], "title": "The Extreme Inefficiency of RL for Frontier Models", "comment": "Source: TLDR Newsletter, Date: 2025-09-22, Reading time: 15 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.tobyord.com%2Fwriting%2Finefficiency-of-reinforcement-learning%3Futm_source=tldrai/1/0100019971936ea2-b8d0717c-c988-467d-bd3c-df4d52df062a-000000/OEv-gPuYqNi4V4zQDDOnZ_Q9tj74_VKKVt70JBfgAH0=423", "summary": "The Extreme Inefficiency of RL for Frontier Models (15 minute read) A key difference between pre-training and reinforcement learning (RL) is their information efficiency. Pre-training via next-token-prediction provides models with a token worth of information to learn from for every token the model produces during training, while RL requires a long chain of thousands and even millions of tokens before revealing to the model a single bit of information. RL provides models with much less inform...", "source": "tldr", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u524d\u6cbf\u6a21\u578b\u4e2d\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7684\u6781\u7aef\u4f4e\u6548\u6027\u95ee\u9898\uff0c\u6307\u51fa\u9884\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u4fe1\u606f\u6548\u7387\u4e0a\u7684\u663e\u8457\u5dee\u5f02", "motivation": "\u7814\u7a76\u524d\u6cbf\u6a21\u578b\u8bad\u7ec3\u4e2d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u6548\u7387\u95ee\u9898\uff0c\u63ed\u793a\u9884\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u5728\u4fe1\u606f\u83b7\u53d6\u6548\u7387\u4e0a\u7684\u6839\u672c\u5dee\u5f02", "method": "\u901a\u8fc7\u6bd4\u8f83\u9884\u8bad\u7ec3\u7684\u9010\u6807\u8bb0\u9884\u6d4b\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u6807\u8bb0\u5e8f\u5217\u53cd\u9988\u673a\u5236\uff0c\u5206\u6790\u4e24\u8005\u7684\u4fe1\u606f\u6548\u7387\u5dee\u5f02", "result": "\u53d1\u73b0\u5f3a\u5316\u5b66\u4e60\u9700\u8981\u6570\u5343\u751a\u81f3\u6570\u767e\u4e07\u4e2a\u6807\u8bb0\u624d\u80fd\u5411\u6a21\u578b\u63d0\u4f9b\u5355\u4e2a\u6bd4\u7279\u7684\u4fe1\u606f\uff0c\u800c\u9884\u8bad\u7ec3\u6bcf\u4e2a\u6807\u8bb0\u90fd\u80fd\u63d0\u4f9b\u5b66\u4e60\u4fe1\u606f", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5728\u524d\u6cbf\u6a21\u578b\u8bad\u7ec3\u4e2d\u5b58\u5728\u4e25\u91cd\u7684\u4fe1\u606f\u6548\u7387\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\u6548\u679c", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.f6a40d89", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA5MDMwMTIyNQ==&mid=2649427805&idx=1&sn=37b41521c81d7d9ba572b6bea1a67e88&chksm=89c3803b3975d59f92655957e6289e313a31d5d96ec64610ce8925608800cddaecc9083990e3#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA5MDMwMTIyNQ==&mid=2649427805&idx=1&sn=37b41521c81d7d9ba572b6bea1a67e88&chksm=89c3803b3975d59f92655957e6289e313a31d5d96ec64610ce8925608800cddaecc9083990e3#rd", "authors": ["CreateAMind"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u5728\u81ea\u52a8\u5316\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u7efc\u8ff0", "comment": "Source: WeChat, Published: 2025-09-22 16:03:43", "summary": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u4e2d\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u6307\u51fa\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u4e2d\u666e\u904d\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u6837\u672c\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff1b\u5b89\u5168\u6027\u4e0e\u9c81\u68d2\u6027\u95ee\u9898\uff1b", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u4e2d\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u6307\u51fa\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u4e2d\u666e\u904d\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u6837\u672c\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff1b\u5b89\u5168\u6027\u4e0e\u9c81\u68d2\u6027\u95ee\u9898\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.3fda2b95", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg2NzY0MTkzOQ==&mid=2247493655&idx=1&sn=cbbc6b6bca3b6a5663004fcfe421a7a5&chksm=cfc0e57d7e184a5939935f5d87698b7e0e1ccdc6c7a38d1e572722d0f4358be96c3215f2e281#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg2NzY0MTkzOQ==&mid=2247493655&idx=1&sn=cbbc6b6bca3b6a5663004fcfe421a7a5&chksm=cfc0e57d7e184a5939935f5d87698b7e0e1ccdc6c7a38d1e572722d0f4358be96c3215f2e281#rd", "authors": ["\u6570\u5b57\u5f00\u7269"], "title": "AI Agent\u7684\u6700\u7ec8\u76ee\u6807\uff5c<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u4e4b\u7236Rich Sutton\u6700\u65b0\u4e07\u5b57\u6f14\u8bb2", "comment": "Source: WeChat, Published: 2025-09-22 11:07:16", "summary": "\u5728\u5f3a\u5316\u5b66\u4e60\u9886\u57df\uff0c\u6211\u4eec\u5c31\u662f\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u6765\u601d\u8003\u201c\u7406\u89e3\u201d\u548c\u201c\u77e5\u8bc6\u201d\u7684\u3002\u800c\u8981\u5728\u66f4\u9ad8\u7684\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5efa\u7acb\u8f6c\u79fb\u6a21\u578b\uff0c\u6bd4\u5982\u201c\u62ff\u8d77\u4e00\u4e2a\u7269\u4f53\u201d\u3001\u201c\u8d70\u8def\u4e0a\u73ed\u201d\u6216\u201c\u63a5\u53d7\u4e00\u4efd\u5de5\u4f5c\u201d\uff0c\u5c31\u9700\u8981\u4e00\u79cd\u6211\u4eec\u79f0\u4e4b\u4e3a\u201c\u9009\u9879\u201d\u7684\u673a\u5236\u3002", "AI": {"tldr": "\u5728\u5f3a\u5316\u5b66\u4e60\u9886\u57df\uff0c\u6211\u4eec\u5c31\u662f\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u6765\u601d\u8003\u201c\u7406\u89e3\u201d\u548c\u201c\u77e5\u8bc6\u201d\u7684\u3002\u800c\u8981\u5728\u66f4\u9ad8\u7684\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5efa\u7acb\u8f6c\u79fb\u6a21\u578b\uff0c\u6bd4\u5982\u201c\u62ff\u8d77\u4e00\u4e2a\u7269\u4f53\u201d\u3001\u201c\u8d70\u8def\u4e0a\u73ed\u201d\u6216\u201c\u63a5\u53d7\u4e00\u4efd\u5de5\u4f5c\u201d\uff0c\u5c31\u9700\u8981\u4e00\u79cd\u6211\u4eec\u79f0\u4e4b\u4e3a\u201c\u9009\u9879\u201d\u7684\u673a\u5236\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.ed23cab0", "categories": ["wechat.article", "wechat.ai", "wechat.rl", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3NDk5NDA5OA==&mid=2454860655&idx=2&sn=49326a94d15586f73ff7441d08966e91&chksm=890e4fc6de9e935068f36242c15fdd8cd1b13cddc55edf83cab6266445531720595777c67077#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3NDk5NDA5OA==&mid=2454860655&idx=2&sn=49326a94d15586f73ff7441d08966e91&chksm=890e4fc6de9e935068f36242c15fdd8cd1b13cddc55edf83cab6266445531720595777c67077#rd", "authors": ["\u8ba1\u7b97\u6750\u6599\u5b66"], "title": "\u6881\u6587\u950b\u53d1\u8868Nature\u5c01\u9762\u8bba\u6587\uff1a\u63ed\u5f00DeepSeek-R1\u80cc\u540e\u7684\u79d1\u5b66\u539f\u7406\u2014\u2014<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6fc0\u52b1\u5927\u6a21\u578b\u63a8\u7406\u80fd\u529b", "comment": "Source: WeChat, Published: 2025-09-22 10:49:21", "summary": "\u7eaf\u5f3a\u5316\u5b66\u4e60\uff1a\u8ba9\u6a21\u578b\u81ea\u4e3b\u63a2\u7d22\u63a8\u7406\u8def\u5f84 \u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\uff0cDeepSeek\u56e2\u961f\u65e8\u5728\u63a2\u7d22\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u81ea\u6211\u6f14\u8fdb\u7684\u65b9\u5f0f\u53d1\u5c55\u63a8\u7406\u80fd\u529b\uff0c\u6700\u5c0f\u5316\u5bf9\u4eba\u7c7b\u6807\u6ce8\u7684\u4f9d\u8d56\u3002", "AI": {"tldr": "\u7eaf\u5f3a\u5316\u5b66\u4e60\uff1a\u8ba9\u6a21\u578b\u81ea\u4e3b\u63a2\u7d22\u63a8\u7406\u8def\u5f84 \u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\uff0cDeepSeek\u56e2\u961f\u65e8\u5728\u63a2\u7d22\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u81ea\u6211\u6f14\u8fdb\u7684\u65b9\u5f0f\u53d1\u5c55\u63a8\u7406\u80fd\u529b\uff0c\u6700\u5c0f\u5316\u5bf9\u4eba\u7c7b\u6807\u6ce8\u7684\u4f9d\u8d56\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.ef4fb4bb", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzUyNjg4NDA3Mw==&mid=2247492528&idx=1&sn=cb29c9c52ccacd66c4e4b9a669b6d8a1&chksm=fb9c52154405bf45e21fb866ee280bf272fb16be5eab8b7b1f804aabdbc9902708592c59d15b#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzUyNjg4NDA3Mw==&mid=2247492528&idx=1&sn=cb29c9c52ccacd66c4e4b9a669b6d8a1&chksm=fb9c52154405bf45e21fb866ee280bf272fb16be5eab8b7b1f804aabdbc9902708592c59d15b#rd", "authors": ["Python\u5e72\u8d27\u94fa\u5b50"], "title": "\u6df1\u5ea6<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u4e0e\u5206\u652f\u5b9a\u754c\u6cd5\u76f8\u7ed3\u5408", "comment": "Source: WeChat, Published: 2025-09-22 10:12:44", "summary": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u5174\u8d77\uff1a \u5c3d\u7ba1\u76d1\u7763\u6a21\u4eff\u53d6\u5f97\u6210\u529f\uff0c\u5176\u6027\u80fd\u4e0a\u9650\u53d7\u5236\u4e8e\u4e13\u5bb6\u7b56\u7565\u672c\u8eab\uff0c\u4e14\u9700\u8981\u6602\u8d35\u7684\u6807\u6ce8\u8fc7\u7a0b\u3002\u4e3a\u6b64\uff0c\u8fd1\u5e74\u6d8c\u73b0\u51fa\u5927\u91cf\u5c1d\u8bd5**\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09**\u6765\u76f4\u63a5\u4f18\u5316BnB\u51b3\u7b56\u7b56\u7565\uff1a", "AI": {"tldr": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u5174\u8d77\uff1a \u5c3d\u7ba1\u76d1\u7763\u6a21\u4eff\u53d6\u5f97\u6210\u529f\uff0c\u5176\u6027\u80fd\u4e0a\u9650\u53d7\u5236\u4e8e\u4e13\u5bb6\u7b56\u7565\u672c\u8eab\uff0c\u4e14\u9700\u8981\u6602\u8d35\u7684\u6807\u6ce8\u8fc7\u7a0b\u3002\u4e3a\u6b64\uff0c\u8fd1\u5e74\u6d8c\u73b0\u51fa\u5927\u91cf\u5c1d\u8bd5**\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09**\u6765\u76f4\u63a5\u4f18\u5316BnB\u51b3\u7b56\u7b56\u7565\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.e786c5ac", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYyNTA2NzMyOQ==&mid=2247483774&idx=1&sn=52b24e398acecc1dcfb5eee04679cc6b&chksm=f1a711d894031916f418df07d40ba2e2802249cb200880f7bf3a73dcce9dd5e06c9e4967a730#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYyNTA2NzMyOQ==&mid=2247483774&idx=1&sn=52b24e398acecc1dcfb5eee04679cc6b&chksm=f1a711d894031916f418df07d40ba2e2802249cb200880f7bf3a73dcce9dd5e06c9e4967a730#rd", "authors": ["IDMCSP"], "title": "\u667a\u80fd\u4f53<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\uff08Agentic RL\uff09\u7406\u8bba\u6846\u67b6\u4e0e\u4e2d\u56fd\u7814\u7a76\u8fdb\u5c55\u6df1\u5ea6\u62a5\u544a", "comment": "Source: WeChat, Published: 2025-09-22 08:41:21", "summary": "\u725b\u6d25\u5927\u5b66\u7b49\u56fd\u5185\u5916\u9ad8\u6821\u5b66\u8005\u53d1\u5e03\u4e86\u4e00\u4efd\u5173\u4e8e\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u7efc\u8ff0\u6027\u8bba\u6587\u300aThe Landscape of Agentic Reinforcement Learning for LLMs\uff1a A Survey\u300b\uff0c\u901a\u8fc7\u603b\u7ed3500\u4f59\u7bc7\u8fd1\u671f\u5de5\u4f5c\uff0c\u4ece\u81ea\u4e3b\u80fd\u529b\u548c\u591a\u6837\u5316\u4efb\u52a1\u5e94\u7528\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8be6\u7ec6\u9610\u8ff0\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u5f00", "AI": {"tldr": "\u725b\u6d25\u5927\u5b66\u7b49\u56fd\u5185\u5916\u9ad8\u6821\u5b66\u8005\u53d1\u5e03\u4e86\u4e00\u4efd\u5173\u4e8e\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u7efc\u8ff0\u6027\u8bba\u6587\u300aThe Landscape of Agentic Reinforcement Learning for LLMs\uff1a A Survey\u300b\uff0c\u901a\u8fc7\u603b\u7ed3500\u4f59\u7bc7\u8fd1\u671f\u5de5\u4f5c\uff0c\u4ece\u81ea\u4e3b\u80fd\u529b\u548c\u591a\u6837\u5316\u4efb\u52a1\u5e94\u7528\u4e24\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8be6\u7ec6\u9610\u8ff0\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u5f00", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.ef511669", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU5OTI0ODY2Mg==&mid=2247625768&idx=2&sn=70eb861501f30ceb7f755edf368cd022&chksm=ff727cdf530230f1fbd7f1173b6d2b9cff3ab840225ccef0eb7ac7eb9e54be6b5cb56de5d265#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU5OTI0ODY2Mg==&mid=2247625768&idx=2&sn=70eb861501f30ceb7f755edf368cd022&chksm=ff727cdf530230f1fbd7f1173b6d2b9cff3ab840225ccef0eb7ac7eb9e54be6b5cb56de5d265#rd", "authors": ["\u9655\u897f\u7701\u56fd\u751f\u5546\u4f1a"], "title": "\u3010\u4eba\u5de5\u667a\u80fd\u3011|Nature\u5c01\u9762\u805a\u7126DeepSeek-R1\uff1a<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u5982\u4f55\u201c\u6559\u4f1a\u201d\u5927\u6a21\u578b\u81ea\u4e3b\u63a8\u7406\uff1f", "comment": "Source: WeChat, Published: 2025-09-22 06:21:08", "summary": "grpo\uff09\u7684\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u5176\u8bad\u7ec3\u7684\u5173\u952e\u5728\u4e8e\u5956\u52b1\u4fe1\u53f7\u7684\u8bbe\u8ba1\uff1a\u5956\u52b1\u4ec5\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u800c\u4e0d\u5bf9\u4e2d\u95f4\u7684\u63a8\u7406\u8fc7\u7a0b\u65bd\u52a0\u4efb\u4f55\u7ea6\u675f\u3002\u8fd9\u76f8\u5f53\u4e8e\u53ea\u544a\u8bc9\u6a21\u578b\u201c\u76ee\u6807\u662f\u4ec0\u4e48\u201d\uff0c\u800c\u4e0d\u544a\u8bc9\u5b83\u201c\u600e\u4e48\u8d70\u201d\u3002", "AI": {"tldr": "grpo\uff09\u7684\u9ad8\u6548\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u5176\u8bad\u7ec3\u7684\u5173\u952e\u5728\u4e8e\u5956\u52b1\u4fe1\u53f7\u7684\u8bbe\u8ba1\uff1a\u5956\u52b1\u4ec5\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u800c\u4e0d\u5bf9\u4e2d\u95f4\u7684\u63a8\u7406\u8fc7\u7a0b\u65bd\u52a0\u4efb\u4f55\u7ea6\u675f\u3002\u8fd9\u76f8\u5f53\u4e8e\u53ea\u544a\u8bc9\u6a21\u578b\u201c\u76ee\u6807\u662f\u4ec0\u4e48\u201d\uff0c\u800c\u4e0d\u544a\u8bc9\u5b83\u201c\u600e\u4e48\u8d70\u201d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.83610edd", "categories": ["wechat.article", "wechat.ai", "wechat.rl", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAwNTAyMDY0MQ==&mid=2652723537&idx=4&sn=dc259480691d7514b5a7eee397104a5f&chksm=8164014f2dbe0e5f32f81a98c7066b73f35613b83174f5ee91fa4eca19e7aa60854b7d3be033#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAwNTAyMDY0MQ==&mid=2652723537&idx=4&sn=dc259480691d7514b5a7eee397104a5f&chksm=8164014f2dbe0e5f32f81a98c7066b73f35613b83174f5ee91fa4eca19e7aa60854b7d3be033#rd", "authors": ["\u81ea\u7136\u7cfb\u5217"], "title": "DeepSeek-R1\u901a\u8fc7<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6fc0\u52b1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b |\u300a\u81ea\u7136\u300b\u8bba\u6587", "comment": "Source: WeChat, Published: 2025-09-22 04:41:15", "summary": "\u4ed6\u4eec\u6240\u63d0\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u4fc3\u751f\u51fa\u9ad8\u7ea7\u63a8\u7406\u6a21\u5f0f\uff0c\u4f8b\u5982\u81ea\u6211\u53cd\u601d\u3001\u9a8c\u8bc1\u4ee5\u53ca\u52a8\u6001\u7b56\u7565\u8c03\u6574\u3002\u56e0\u6b64\uff0c\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u7ade\u8d5b\u4ee5\u53caSTEM\u9886\u57df\u7b49\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e86\u66f4\u4f18\u6027\u80fd\uff0c\u5176\u8868\u73b0\u8d85\u8d8a\u4e86\u901a\u8fc7\u57fa\u4e8e\u4eba\u5de5\u793a\u8303\u7684\u4f20\u7edf\u76d1\u7763", "AI": {"tldr": "\u4ed6\u4eec\u6240\u63d0\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u4fc3\u751f\u51fa\u9ad8\u7ea7\u63a8\u7406\u6a21\u5f0f\uff0c\u4f8b\u5982\u81ea\u6211\u53cd\u601d\u3001\u9a8c\u8bc1\u4ee5\u53ca\u52a8\u6001\u7b56\u7565\u8c03\u6574\u3002\u56e0\u6b64\uff0c\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u5728\u6570\u5b66\u3001\u7f16\u7a0b\u7ade\u8d5b\u4ee5\u53caSTEM\u9886\u57df\u7b49\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e86\u66f4\u4f18\u6027\u80fd\uff0c\u5176\u8868\u73b0\u8d85\u8d8a\u4e86\u901a\u8fc7\u57fa\u4e8e\u4eba\u5de5\u793a\u8303\u7684\u4f20\u7edf\u76d1\u7763", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2509.e04e8631", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA5MzY1MTQ4Mw==&mid=2247484352&idx=1&sn=3545da2c960a375f99d35b59da3aeba6&chksm=916b75a5288b3512e267e2fafd4695e29a3be4b82809a86f3162200fbbfa84b1aaf42cafb293#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA5MzY1MTQ4Mw==&mid=2247484352&idx=1&sn=3545da2c960a375f99d35b59da3aeba6&chksm=916b75a5288b3512e267e2fafd4695e29a3be4b82809a86f3162200fbbfa84b1aaf42cafb293#rd", "authors": ["Wonderful\u4eff\u771f"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u4e4bQ-Learning\u8ba9\u673a\u5668\u50cf\u4eba\u4e00\u6837\u5b66\u4f1a\u505a\u51b3\u7b56", "comment": "Source: WeChat, Published: 2025-09-22 04:21:22", "summary": "\u8fd9\u4e2a\u5b66\u4e60\u8fc7\u7a0b\u5c31\u5f88\u50cf\u4eca\u5929\u8981\u4ecb\u7ecd\u7684Q-Learning\u7b97\u6cd5\u2014\u2014\u4e00\u79cd\u8ba9\u673a\u5668\u901a\u8fc7\u8bd5\u9519\u6765\u5b66\u4e60\u6700\u4f18\u51b3\u7b56\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u4ec0\u4e48\u662fQ-Learning\uff1fQ-Learning\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d\u6700\u7ecf\u5178\u7684\u7b97\u6cd5\u4e4b\u4e00\uff0c\u7531Christopher Watkins\u57281989\u5e74\u63d0\u51fa\u3002", "AI": {"tldr": "\u8fd9\u4e2a\u5b66\u4e60\u8fc7\u7a0b\u5c31\u5f88\u50cf\u4eca\u5929\u8981\u4ecb\u7ecd\u7684Q-Learning\u7b97\u6cd5\u2014\u2014\u4e00\u79cd\u8ba9\u673a\u5668\u901a\u8fc7\u8bd5\u9519\u6765\u5b66\u4e60\u6700\u4f18\u51b3\u7b56\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u4ec0\u4e48\u662fQ-Learning\uff1fQ-Learning\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d\u6700\u7ecf\u5178\u7684\u7b97\u6cd5\u4e4b\u4e00\uff0c\u7531Christopher Watkins\u57281989\u5e74\u63d0\u51fa\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.41480bf7", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5MzU2NzM5MA==&mid=2649679058&idx=1&sn=cbb482d6c0543f7e7e11b537c6190e75&chksm=bf97f26cfdd38a28d5a20a2c98e09d60167627815a578b295023c946d2b029a854c100598a1f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5MzU2NzM5MA==&mid=2649679058&idx=1&sn=cbb482d6c0543f7e7e11b537c6190e75&chksm=bf97f26cfdd38a28d5a20a2c98e09d60167627815a578b295023c946d2b029a854c100598a1f#rd", "authors": ["\u4fe1\u606f\u7f51\u7edc\u5de5\u7a0b\u7814\u7a76\u4e2d\u5fc3"], "title": "\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u57fa\u7840\uff1a\u7efc\u8ff0", "comment": "Source: WeChat, Published: 2025-09-22 02:32:12", "summary": "\u636e\u6211\u4eec\u6240\u77e5\uff0c\u672c\u7efc\u8ff0\u662f\u9996\u4e2a\u4e13\u95e8\u805a\u7126\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7684\u5de5\u4f5c\u3002\u672c\u6587\u6cbf\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5316\u4e86 DeepSeek-R1 \u4e4b\u540e\u7684\u7814\u7a76\uff1a\uff08i\uff09 \u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u6574\u7406\uff1b", "AI": {"tldr": "\u636e\u6211\u4eec\u6240\u77e5\uff0c\u672c\u7efc\u8ff0\u662f\u9996\u4e2a\u4e13\u95e8\u805a\u7126\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7684\u5de5\u4f5c\u3002\u672c\u6587\u6cbf\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5316\u4e86 DeepSeek-R1 \u4e4b\u540e\u7684\u7814\u7a76\uff1a\uff08i\uff09 \u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u6574\u7406\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.e068b9e1", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzUyNTc2NDA2Mg==&mid=2247494075&idx=1&sn=7dc797715f961c9e50383f89da4ec601&chksm=fbeacdb6b7a8e9d1f4e715d9cf8509f7c637b9beb46c956fe179252216cf01077406a45044a3#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzUyNTc2NDA2Mg==&mid=2247494075&idx=1&sn=7dc797715f961c9e50383f89da4ec601&chksm=fbeacdb6b7a8e9d1f4e715d9cf8509f7c637b9beb46c956fe179252216cf01077406a45044a3#rd", "authors": ["\u5783\u573e\u5206\u7c7b\u7ad9"], "title": "\u4f7f\u7528<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u89e3\u51b3\u9910\u996e\u914d\u9001\u670d\u52a1\u4e2d\u7684\u9a91\u624b\u8def\u5f84\u89c4\u5212\u4e0e\u5206\u914d\u95ee\u9898", "comment": "Source: WeChat, Published: 2025-09-22 00:01:40", "summary": "\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7\u8ba9\u667a\u80fd\u4f53\uff08agent\uff09\u5728\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u4e2d\u5b66\u4e60\u6700\u4f18\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u9884\u671f\u7684\u7d2f\u8ba1\u5956\u52b1\uff0c\u4e3a\u89e3\u51b3\u8fd9\u79cd\u590d\u6742\u7684\u52a8\u6001\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002\u7814\u7a76\u95ee\u9898", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7\u8ba9\u667a\u80fd\u4f53\uff08agent\uff09\u5728\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u4e2d\u5b66\u4e60\u6700\u4f18\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u9884\u671f\u7684\u7d2f\u8ba1\u5956\u52b1\uff0c\u4e3a\u89e3\u51b3\u8fd9\u79cd\u590d\u6742\u7684\u52a8\u6001\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002\u7814\u7a76\u95ee\u9898", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.74393d65", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&mid=2247554639&idx=1&sn=5835f4030d1d5b22c14dbd779bb9e1e5&chksm=fc78ef8bcd13643b0803d53f207e7131d3a7307e2fe286593723935c32cd1c912b61c49da297#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU3NjE4NjQ4MA==&mid=2247554639&idx=1&sn=5835f4030d1d5b22c14dbd779bb9e1e5&chksm=fc78ef8bcd13643b0803d53f207e7131d3a7307e2fe286593723935c32cd1c912b61c49da297#rd", "authors": ["\u5927\u6a21\u578b\u667a\u80fd"], "title": "\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u57fa\u7840\uff1a\u7efc\u8ff0", "comment": "Source: WeChat, Published: 2025-09-21 19:00:43", "summary": "\u636e\u6211\u4eec\u6240\u77e5\uff0c\u672c\u7efc\u8ff0\u662f\u9996\u4e2a\u4e13\u95e8\u805a\u7126\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7684\u5de5\u4f5c\u3002\u672c\u6587\u6cbf\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5316\u4e86 DeepSeek-R1 \u4e4b\u540e\u7684\u7814\u7a76\uff1a\uff08i\uff09 \u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u6574\u7406\uff1b", "AI": {"tldr": "\u636e\u6211\u4eec\u6240\u77e5\uff0c\u672c\u7efc\u8ff0\u662f\u9996\u4e2a\u4e13\u95e8\u805a\u7126\u6df1\u5ea6\u7814\u7a76\u7cfb\u7edf\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7684\u5de5\u4f5c\u3002\u672c\u6587\u6cbf\u4e09\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u5316\u4e86 DeepSeek-R1 \u4e4b\u540e\u7684\u7814\u7a76\uff1a\uff08i\uff09 \u6570\u636e\u5408\u6210\u4e0e\u6570\u636e\u6574\u7406\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2509.31224023", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzUxNTg2Nzc0MA==&mid=2247507160&idx=7&sn=97393121debf129048eadbf94bd0699d&chksm=f8f9f94d1ec52698b696dd8248543de7011196033fdbd0df13b961e804ce5402187379250722#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzUxNTg2Nzc0MA==&mid=2247507160&idx=7&sn=97393121debf129048eadbf94bd0699d&chksm=f8f9f94d1ec52698b696dd8248543de7011196033fdbd0df13b961e804ce5402187379250722#rd", "authors": ["\u65b0\u80fd\u6e90\u4e0e\u80fd\u6548"], "title": "\u82b1\u65d7\u94f6\u884c\u542f\u52a8AI\u201c<em class=\"highlight\">\u4ee3\u7406</em>\u4eba\u201d\u8bd5\u70b9\uff1a\u672a\u6765\u53ef\u81ea\u52a8\u5b8c\u6210\u590d\u6742\u4efb\u52a1", "comment": "Source: WeChat, Published: 2025-09-22 15:05:17", "summary": "griffiths\u6307\u51fa\uff1a\u201c\u51e0\u5e74\u524d\uff0c\u65e9\u671f\u6a21\u578b\u5df2\u7ecf\u53ef\u4ee5\u505a\u4e00\u4e9b\u4ee3\u7406\u4eba\u5f0f\u64cd\u4f5c\uff0c\u4f46\u53ef\u9760\u6027\u6709\u9650\uff0c\u4e5f\u4e0d\u64c5\u957f\u8c03\u7528\u5de5\u5177\u3002\u73b0\u5728\u60c5\u51b5\u5df2\u7ecf\u5b8c\u5168\u4e0d\u540c\u3002\u201d \u6b64\u6b21\u8bd5\u70b9\u5c06\u8986\u76d6\u7ea65\uff0c000\u540d\u5458\u5de5\uff0c\u4e3a\u671f\u56db\u5230\u516d\u5468\u3002", "AI": {"tldr": "griffiths\u6307\u51fa\uff1a\u201c\u51e0\u5e74\u524d\uff0c\u65e9\u671f\u6a21\u578b\u5df2\u7ecf\u53ef\u4ee5\u505a\u4e00\u4e9b\u4ee3\u7406\u4eba\u5f0f\u64cd\u4f5c\uff0c\u4f46\u53ef\u9760\u6027\u6709\u9650\uff0c\u4e5f\u4e0d\u64c5\u957f\u8c03\u7528\u5de5\u5177\u3002\u73b0\u5728\u60c5\u51b5\u5df2\u7ecf\u5b8c\u5168\u4e0d\u540c\u3002\u201d \u6b64\u6b21\u8bd5\u70b9\u5c06\u8986\u76d6\u7ea65\uff0c000\u540d\u5458\u5de5\uff0c\u4e3a\u671f\u56db\u5230\u516d\u5468\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.c4d47929", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk4ODMzMzg2Ng==&mid=2247484281&idx=1&sn=034abe821b8f01b216ab6b77f1e17e37&chksm=c44b6ac00a43e064b14488c3dd0760199b603fea866621063ebb879c4161a9ab9fcfe863edfa#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk4ODMzMzg2Ng==&mid=2247484281&idx=1&sn=034abe821b8f01b216ab6b77f1e17e37&chksm=c44b6ac00a43e064b14488c3dd0760199b603fea866621063ebb879c4161a9ab9fcfe863edfa#rd", "authors": ["\u5927\u6a21\u578b\u8bfe\u4ee3\u8868"], "title": "\u5434\u6069\u8fbe\u6df1\u5ea6\u89e3\u6790\uff5c5\u79cd<em class=\"highlight\">Agent</em>icAI\u8bbe\u8ba1\u6a21\u5f0f", "comment": "Source: WeChat, Published: 2025-09-22 12:53:29", "summary": "\u6848\u4f8b\u62c6\u89e3\uff1a 5\u79cdagenticai\u8bbe\u8ba1\u6a21\u5f0f\uff0c \u4e00\u6587\u770b\u61c2\uff1a 5 most popular agentic ai design patterns agent\u30025\u79cdagentic ai\u8bbe\u8ba1\u6a21\u5f0f agentic ai \u7528\u6237\uff08user\uff09\u63d0\u51fa\u67e5\u8be2\uff08query\uff09 deepseek llm \uff08\u751f\u6210\uff09\u521b\u5efa\u521d\u59cb\u8f93\u51fa\uff08initial output\uff09 deepseek llm \uff08\u53cd\u601d\uff09\u5ba1\u67e5\u5e76\u6539\u8fdb\u8f93\u51fa", "AI": {"tldr": "\u6848\u4f8b\u62c6\u89e3\uff1a 5\u79cdagenticai\u8bbe\u8ba1\u6a21\u5f0f\uff0c \u4e00\u6587\u770b\u61c2\uff1a 5 most popular agentic ai design patterns agent\u30025\u79cdagentic ai\u8bbe\u8ba1\u6a21\u5f0f agentic ai \u7528\u6237\uff08user\uff09\u63d0\u51fa\u67e5\u8be2\uff08query\uff09 deepseek llm \uff08\u751f\u6210\uff09\u521b\u5efa\u521d\u59cb\u8f93\u51fa\uff08initial output\uff09 deepseek llm \uff08\u53cd\u601d\uff09\u5ba1\u67e5\u5e76\u6539\u8fdb\u8f93\u51fa", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.924054f5", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3NTgwMzkyMw==&mid=2650475173&idx=1&sn=a834aa12a7940cdfe8c873b0c9fa50f2&chksm=86bcbcbdab48a85b832bf1418d29e59c88b3b313c1293fca66e72e4b530fd4bae1fad6ee18f1#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3NTgwMzkyMw==&mid=2650475173&idx=1&sn=a834aa12a7940cdfe8c873b0c9fa50f2&chksm=86bcbcbdab48a85b832bf1418d29e59c88b3b313c1293fca66e72e4b530fd4bae1fad6ee18f1#rd", "authors": ["\u6613\u7c73\u4e91\u901a"], "title": "AI \u6d1e\u5bdf | 2025\u5e74<em class=\"highlight\">Agentic</em> AI\uff08<em class=\"highlight\">\u667a\u80fd\u4f53</em>AI\uff09\u7684\u7206\u53d1\u4e0e\u53d1\u5c55\u8d8b\u52bf", "comment": "Source: WeChat, Published: 2025-09-22 08:00:59", "summary": "agentic ai\u3002\u56fe\u7247\u6765\u81ea\u7f51\u7edc\u3002\u5bfc\u8a00\u3002\u5728\u4eba\u5de5\u667a\u80fd\u98de\u901f\u53d1\u5c55\u7684\u9886\u57df\u4e2d\uff0c\u4e00\u79cd\u65b0\u8303\u5f0f\u6b63\u5728 \u5d1b\u8d77\u3002 \u4e00\uff0c\u90a3\u5c31\u662f\u667a\u80fd\u4f53\u3002\u5d1b\u8d77 \u4e00\u90a3\u5c31\u662f\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\uff08Agentic AI\uff09\u3002", "AI": {"tldr": "agentic ai\u3002\u56fe\u7247\u6765\u81ea\u7f51\u7edc\u3002\u5bfc\u8a00\u3002\u5728\u4eba\u5de5\u667a\u80fd\u98de\u901f\u53d1\u5c55\u7684\u9886\u57df\u4e2d\uff0c\u4e00\u79cd\u65b0\u8303\u5f0f\u6b63\u5728 \u5d1b\u8d77\u3002 \u4e00\uff0c\u90a3\u5c31\u662f\u667a\u80fd\u4f53\u3002\u5d1b\u8d77 \u4e00\u90a3\u5c31\u662f\u667a\u80fd\u4f53\u4eba\u5de5\u667a\u80fd\uff08Agentic AI\uff09\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.f6af3a26", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIxNzI0ODE4Nw==&mid=2247497620&idx=1&sn=41f65d527e8c78d00dfa10e85f29bd29&chksm=96608b9ffb9f50863685bd182699b0ff92af2d7d84840cf9cdf530e688ac1ae781d15cd60445#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIxNzI0ODE4Nw==&mid=2247497620&idx=1&sn=41f65d527e8c78d00dfa10e85f29bd29&chksm=96608b9ffb9f50863685bd182699b0ff92af2d7d84840cf9cdf530e688ac1ae781d15cd60445#rd", "authors": ["DeeplearningAI"], "title": "\u5434\u6069\u8fbe\u6765\u4fe1\uff1a<em class=\"highlight\">Agentic</em>\u7f16\u7a0b\u4e0e<em class=\"highlight\">Agentic</em>\u8f6f\u4ef6\u6d4b\u8bd5\u534f\u540c\u5408\u4f5c", "comment": "Source: WeChat, Published: 2025-09-22 04:45:38", "summary": "* \u201c\u5956\u52b1\u4f5c\u5f0a\u201d\uff0c\u5373\u7f16\u7a0b\u667a\u80fd\u4f53\u4fee\u6539\u6d4b\u8bd5\u4ee3\u7801\uff0c\u4f7f\u6d4b\u8bd5\u66f4\u5bb9\u6613\u901a\u8fc7\u3002* \u4e00\u4e2a\u667a\u80fd\u4f53\u5728\u5de5\u4f5c\u76ee\u5f55\u4e0b\u8fd0\u884c\u4e86\u201crm \\*.py\u201d\uff0c\u5bfc\u81f4\u6574\u4e2a\u9879\u76ee\u7684\u4ee3\u7801\u88ab\u5220\u9664\uff08\u5e78\u8fd0\u7684\u662f\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u4e0a\u5907\u4efd\uff09\u3002", "AI": {"tldr": "* \u201c\u5956\u52b1\u4f5c\u5f0a\u201d\uff0c\u5373\u7f16\u7a0b\u667a\u80fd\u4f53\u4fee\u6539\u6d4b\u8bd5\u4ee3\u7801\uff0c\u4f7f\u6d4b\u8bd5\u66f4\u5bb9\u6613\u901a\u8fc7\u3002* \u4e00\u4e2a\u667a\u80fd\u4f53\u5728\u5de5\u4f5c\u76ee\u5f55\u4e0b\u8fd0\u884c\u4e86\u201crm \\*.py\u201d\uff0c\u5bfc\u81f4\u6574\u4e2a\u9879\u76ee\u7684\u4ee3\u7801\u88ab\u5220\u9664\uff08\u5e78\u8fd0\u7684\u662f\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u4e0a\u5907\u4efd\uff09\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2509.8de22a67", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIyNDkxMjQ3OA==&mid=2247485249&idx=1&sn=ee46811f756bb43805db4bd0b5278afb&chksm=e9874817aaa8ea59ba65b9ccd707ec0e4a1520ce2e21361faf0f63dc8dd3ce47478658603092#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIyNDkxMjQ3OA==&mid=2247485249&idx=1&sn=ee46811f756bb43805db4bd0b5278afb&chksm=e9874817aaa8ea59ba65b9ccd707ec0e4a1520ce2e21361faf0f63dc8dd3ce47478658603092#rd", "authors": ["\u673a\u5668\u4e4b\u9b42"], "title": "10 \u500d\u6548\u7387\u30010 \u4eba\u5de5\u5e72\u9884\uff01\u4f01\u4e1a\u7ea7\u201c<em class=\"highlight\">Agentic</em> AI \u751f\u547d\u5468\u671f\u201d\u9996\u6b21\u66dd\u5149\uff0c\u6253\u5de5\u4eba\u770b\u5b8c\u76f4\u63a5\u6c89\u9ed8", "comment": "Source: WeChat, Published: 2025-09-22 03:03:16", "summary": "\u4f8b\u5982\uff0cAgent2Agent\uff08A2A\uff09\u534f\u8bae\u6307\u5b9a\u4e86\u667a\u80fd\u4f53\u5361\uff08\u4e00\u4e2aJSON\u6587\u6863\uff09\u7684\u6982\u5ff5\uff0c\u5b83\u5145\u5f53\u667a\u80fd\u4f53\u7684\u6570\u5b57\u201c\u540d\u7247\u201d\u3002\u5b83\u5305\u542b\u4ee5\u4e0b\u5173\u952e\u4fe1\u606f\uff1aCopyIdentity\uff1a \u540d\u79f0\u3001\u63cf\u8ff0\u3001\u63d0\u4f9b\u8005\u4fe1\u606f\u3002", "AI": {"tldr": "\u4f8b\u5982\uff0cAgent2Agent\uff08A2A\uff09\u534f\u8bae\u6307\u5b9a\u4e86\u667a\u80fd\u4f53\u5361\uff08\u4e00\u4e2aJSON\u6587\u6863\uff09\u7684\u6982\u5ff5\uff0c\u5b83\u5145\u5f53\u667a\u80fd\u4f53\u7684\u6570\u5b57\u201c\u540d\u7247\u201d\u3002\u5b83\u5305\u542b\u4ee5\u4e0b\u5173\u952e\u4fe1\u606f\uff1aCopyIdentity\uff1a \u540d\u79f0\u3001\u63cf\u8ff0\u3001\u63d0\u4f9b\u8005\u4fe1\u606f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.4bfbc40c", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU3OTc2MTUyNg==&mid=2247499966&idx=1&sn=9a0789646bb8cc31f422bb033d7750c8&chksm=fc5dfeea95223a684a955d6e13ed3ca8c28061013dbf5d7f6a6ef8b12f0021a8e4f1f1cfc677#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU3OTc2MTUyNg==&mid=2247499966&idx=1&sn=9a0789646bb8cc31f422bb033d7750c8&chksm=fc5dfeea95223a684a955d6e13ed3ca8c28061013dbf5d7f6a6ef8b12f0021a8e4f1f1cfc677#rd", "authors": ["\u5fae\u9489\u79d1\u6280"], "title": "<em class=\"highlight\">Agentic</em> AI : \u52a9\u529b\u4e2d\u56fd\u6c7d\u8f66\u96f6\u90e8\u4ef6\u4f01\u4e1a\u9ad8\u6548\u51fa\u6d77", "comment": "Source: WeChat, Published: 2025-09-22 02:27:06", "summary": "\u667a\u80fd\u5173\u52a1\u667a\u80fd\u4f53Intelligent Customs Agent\u667a\u6167\u5173\u52a1 submit\u30021\u3001\u6253\u5f00\u4fe1\u606f\u5f55\u5165\u8868\u5355\u30022\u3001\u4e0a\u4f20\u4f9b\u5e94\u5546\u5355\u636e\u30023\u3001ai\u81ea\u52a8\u586b\u5145\u4fe1\u606f\u30024\u3001\u4eba\u5de5\u4e8c\u6b21\u4fe1\u606f\u786e\u8ba4\u30025\u3001\u63d0\u4ea4\u6700\u7ec8\u5f55\u5165\u8868\u5355\u3002", "AI": {"tldr": "\u667a\u80fd\u5173\u52a1\u667a\u80fd\u4f53Intelligent Customs Agent\u667a\u6167\u5173\u52a1 submit\u30021\u3001\u6253\u5f00\u4fe1\u606f\u5f55\u5165\u8868\u5355\u30022\u3001\u4e0a\u4f20\u4f9b\u5e94\u5546\u5355\u636e\u30023\u3001ai\u81ea\u52a8\u586b\u5145\u4fe1\u606f\u30024\u3001\u4eba\u5de5\u4e8c\u6b21\u4fe1\u606f\u786e\u8ba4\u30025\u3001\u63d0\u4ea4\u6700\u7ec8\u5f55\u5165\u8868\u5355\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.b8878a22", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzODMwMzY2MA==&mid=2247483953&idx=1&sn=3b8be31236c26900a1d6907cdd83fb1b&chksm=c39e3a99171441dbcf1f900cec83b7073c9b4fff882996948bf9789db1a89fc7388438b5b4f2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzODMwMzY2MA==&mid=2247483953&idx=1&sn=3b8be31236c26900a1d6907cdd83fb1b&chksm=c39e3a99171441dbcf1f900cec83b7073c9b4fff882996948bf9789db1a89fc7388438b5b4f2#rd", "authors": ["ABCD\u542f\u793a\u5f55X"], "title": "<em class=\"highlight\">Agentic</em> AI \u5546\u4e1a\u843d\u5730\u7684\u516d\u5927\u5173\u952e\u7ecf\u9a8c-By \u9ea6\u80af\u9521", "comment": "Source: WeChat, Published: 2025-09-22 01:10:25", "summary": "The #1 mistake\uff1fthat win don't ask \"how cool is this agent\uff1f\" They ask \"how much faster can Sarah complete her entire workflow\uff1fvariance\uff1f\" if not\uff0c you're overengineering.\u30021. rule-based + structured data = use automation\uff0c not agents\u3002", "AI": {"tldr": "The #1 mistake\uff1fthat win don't ask \"how cool is this agent\uff1f\" They ask \"how much faster can Sarah complete her entire workflow\uff1fvariance\uff1f\" if not\uff0c you're overengineering.\u30021. rule-based + structured data ...", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.286f83e6", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247570486&idx=2&sn=62594d43d6392405affb1f8bfe71fdd2&chksm=96856022c2341eb2a2dbf38b406e0612383859a0d6d95f32d647a2b0145fef3219ff61525fa2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247570486&idx=2&sn=62594d43d6392405affb1f8bfe71fdd2&chksm=96856022c2341eb2a2dbf38b406e0612383859a0d6d95f32d647a2b0145fef3219ff61525fa2#rd", "authors": ["\u6df1\u5ea6\u5b66\u4e60\u4e0eNLP"], "title": "\u4e0a\u4ea4\u6700\u65b0-\u300a\u52a8\u624b\u5b66<em class=\"highlight\">\u5927\u6a21\u578b</em>\u300b\u5b9e\u6218\u6559\u7a0b\u53cappt\u5206\u4eab\uff01", "comment": "Source: WeChat, Published: 2025-09-22 16:00:00", "summary": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u5e2e\u52a9\u5b9e\u73b0AGI\uff1f\u5927\u6a21\u578b\u667a\u80fd\u4f53\u4e0e\u5b89\u5168 \u5927\u6a21\u578b\u667a\u80fd\u4f53\u8fc8\u5411\u4e86\u672a\u6765\u64cd\u4f5c\u7cfb\u7edf\u4e4b\u65c5\u3002\u7136\u800c\uff0c\u5927\u6a21\u578b\u5728\u5f00\u653e\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u80fd\u610f\u8bc6\u5230\u98ce\u9669\u5a01\u80c1\u5417\uff1f", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u5e2e\u52a9\u5b9e\u73b0AGI\uff1f\u5927\u6a21\u578b\u667a\u80fd\u4f53\u4e0e\u5b89\u5168 \u5927\u6a21\u578b\u667a\u80fd\u4f53\u8fc8\u5411\u4e86\u672a\u6765\u64cd\u4f5c\u7cfb\u7edf\u4e4b\u65c5\u3002\u7136\u800c\uff0c\u5927\u6a21\u578b\u5728\u5f00\u653e\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u80fd\u610f\u8bc6\u5230\u98ce\u9669\u5a01\u80c1\u5417\uff1f", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.90d94e29", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI1MjYwODEwNQ==&mid=2247911380&idx=3&sn=6e730bb2c3580507da0aac43f84f3cf5&chksm=e82b2c7d66240f76e91232a7a971500661e4e180bbc7c76c512dc6abd4e7236076c15dce3ac0#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI1MjYwODEwNQ==&mid=2247911380&idx=3&sn=6e730bb2c3580507da0aac43f84f3cf5&chksm=e82b2c7d66240f76e91232a7a971500661e4e180bbc7c76c512dc6abd4e7236076c15dce3ac0#rd", "authors": ["\u65e0\u5fe7\u667a\u5e93"], "title": "\u4fdd\u9669\u884c\u4e1a\u57fa\u4e8eDeepSeek AI<em class=\"highlight\">\u5927\u6a21\u578b</em>\u667a\u80fd\u4f53\u573a\u666f\u5316\u8bbe\u8ba1\u65b9\u6848\uff08WORD\uff09", "comment": "Source: WeChat, Published: 2025-09-22 16:00:00", "summary": "\u6cd5\u52a1\u5408\u89c4\u98ce\u63a7\u5e73\u53f0\u57fa\u4e8eAI\u5927\u6a21\u578b\u8bbe\u8ba1\u65b9\u6848\uff08WORD\uff09\u5927\u578b\u5236\u9020\u4f01\u4e1aIT\u84dd\u56fe\u4fe1\u606f\u5316\u6218\u7565\u89c4\u5212\u8bbe\u8ba1\u53ca\u5b9e\u65bd\u8def\u7ebf\u5927\u578b\u623f\u5730\u4ea7\u96c6\u56e2\u6218\u7565\u89c4\u5212\u4f01\u4e1a\u4fe1\u606f\u5316\u89c4\u5212\u6570\u5b57\u5316\u8f6c\u578bPMO\u9879\u76ee\u8fdb\u5ea6\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff08249\u9875PPT\uff09", "AI": {"tldr": "\u6cd5\u52a1\u5408\u89c4\u98ce\u63a7\u5e73\u53f0\u57fa\u4e8eAI\u5927\u6a21\u578b\u8bbe\u8ba1\u65b9\u6848\uff08WORD\uff09\u5927\u578b\u5236\u9020\u4f01\u4e1aIT\u84dd\u56fe\u4fe1\u606f\u5316\u6218\u7565\u89c4\u5212\u8bbe\u8ba1\u53ca\u5b9e\u65bd\u8def\u7ebf\u5927\u578b\u623f\u5730\u4ea7\u96c6\u56e2\u6218\u7565\u89c4\u5212\u4f01\u4e1a\u4fe1\u606f\u5316\u89c4\u5212\u6570\u5b57\u5316\u8f6c\u578bPMO\u9879\u76ee\u8fdb\u5ea6\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\uff08249\u9875PPT\uff09", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.614b486b", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NjI3OTUwNA==&mid=2247488063&idx=1&sn=7c982daac06be7a02dac9108fa3f8f2d&chksm=c2a153eff9a3e0c99a1d3712e3b24f2d16b7b7c515d5eca0774fa17063a3d2de7fdb35f97e38#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NjI3OTUwNA==&mid=2247488063&idx=1&sn=7c982daac06be7a02dac9108fa3f8f2d&chksm=c2a153eff9a3e0c99a1d3712e3b24f2d16b7b7c515d5eca0774fa17063a3d2de7fdb35f97e38#rd", "authors": ["Eva\u4ea7\u54c1\u6218\u7565"], "title": "DeepSeek-V3.1-Terminus\u53d1\u5e03\uff1aAI<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u53cc\u6a21\u5f0f\u65f6\u4ee3\u6b63\u5f0f\u5230\u6765", "comment": "Source: WeChat, Published: 2025-09-22 15:32:31", "summary": "DeepSeek-V3.1-Terminus\u7684\u53d1\u5e03\u6807\u5fd7\u7740\u5927\u6a21\u578b\u6280\u672f\u6b63\u4ece\u5355\u7eaf\u7684\u8bed\u8a00\u7406\u89e3\u5411\u5b9e\u7528\u5316\u667a\u80fd\u4f53\u8f6c\u578b\uff0c\u5176\u6838\u5fc3\u7a81\u7834\u4e0e\u7279\u6027\u4f18\u5316\u4e3a\u5404\u884c\u4e1a\u5e26\u6765\u4e86\u4ece\u6548\u7387\u63d0\u5347\u5230\u6a21\u5f0f\u521b\u65b0\u7684\u6df1\u8fdc\u5f71\u54cd\u3002", "AI": {"tldr": "DeepSeek-V3.1-Terminus\u7684\u53d1\u5e03\u6807\u5fd7\u7740\u5927\u6a21\u578b\u6280\u672f\u6b63\u4ece\u5355\u7eaf\u7684\u8bed\u8a00\u7406\u89e3\u5411\u5b9e\u7528\u5316\u667a\u80fd\u4f53\u8f6c\u578b\uff0c\u5176\u6838\u5fc3\u7a81\u7834\u4e0e\u7279\u6027\u4f18\u5316\u4e3a\u5404\u884c\u4e1a\u5e26\u6765\u4e86\u4ece\u6548\u7387\u63d0\u5347\u5230\u6a21\u5f0f\u521b\u65b0\u7684\u6df1\u8fdc\u5f71\u54cd\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.7cc8ab9f", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkwMDI1NzQ1MA==&mid=2247485264&idx=1&sn=56fc424c4bb001f3e36dac05e6ec735d&chksm=c18c1f4ff26fd25dd83ea5d110f32278f0597c25af619cdcfdc48bc7a532ea23f1a9004b5673#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkwMDI1NzQ1MA==&mid=2247485264&idx=1&sn=56fc424c4bb001f3e36dac05e6ec735d&chksm=c18c1f4ff26fd25dd83ea5d110f32278f0597c25af619cdcfdc48bc7a532ea23f1a9004b5673#rd", "authors": ["\u5927\u6a21\u578b101"], "title": "\u5b66\u597d\u8fd9\u4e9b\uff0c\u4f60\u7684<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5c31\u5f88\u725b\u4e86", "comment": "Source: WeChat, Published: 2025-09-22 13:56:25", "summary": "\u4e86\uff01agent\uff08\u667a\u80fd\u4f53\uff09 \u5b9a\u4e49\uff1a\u4e00\u79cd\u80fd\u591f\u611f\u77e5\u3001\u51b3\u7b56\u548c\u884c\u52a8\uff0c\u4ee5\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u81ea\u4e3b\u3002\u5b9a\u4e49\uff1a\u4e00\u79cd\u80fd\u591f\u611f\u77e5\u3001\u51b3\u7b56\u548c\u884c\u52a8\u4ee5\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u81ea\u4e3bAI \u7cfb\u7edf\u3002\u529f\u80fd\uff1a\u57fa\u4e8e\u89c2\u5bdf\u548c\u76ee\u6807\u5728\u73af\u5883\u4e2d\u91c7\u53d6\u884c\u52a8\u3002", "AI": {"tldr": "\u4e86\uff01agent\uff08\u667a\u80fd\u4f53\uff09 \u5b9a\u4e49\uff1a\u4e00\u79cd\u80fd\u591f\u611f\u77e5\u3001\u51b3\u7b56\u548c\u884c\u52a8\uff0c\u4ee5\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u81ea\u4e3b\u3002\u5b9a\u4e49\uff1a\u4e00\u79cd\u80fd\u591f\u611f\u77e5\u3001\u51b3\u7b56\u548c\u884c\u52a8\u4ee5\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u81ea\u4e3bAI \u7cfb\u7edf\u3002\u529f\u80fd\uff1a\u57fa\u4e8e\u89c2\u5bdf\u548c\u76ee\u6807\u5728\u73af\u5883\u4e2d\u91c7\u53d6\u884c\u52a8\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.13dfa805", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4MDYzNjM5OQ==&mid=2247487323&idx=1&sn=450a3a6b6ca78c40238243781d28d1d7&chksm=ce4fc5622b74675669590facc529d34572fd293006f764b1386e4320b3b4c8a83461716ae461#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4MDYzNjM5OQ==&mid=2247487323&idx=1&sn=450a3a6b6ca78c40238243781d28d1d7&chksm=ce4fc5622b74675669590facc529d34572fd293006f764b1386e4320b3b4c8a83461716ae461#rd", "authors": ["AI\u5927\u6a21\u578b\u77e5\u8bc6\u5b98"], "title": "\u7ec8\u4e8e\u5f7b\u5e95\u641e\u61c2<em class=\"highlight\">\u5927\u6a21\u578b</em>LLM\u4e86\uff01", "comment": "Source: WeChat, Published: 2025-09-22 10:08:46", "summary": "\u5f7b\u5e95\u641e\u61c2\u5927\u6a21\u578b\u3002llm\uff1a\u63d0\u793a\u5de5\u7a0b\u3001\u51fd\u6570\u8c03\u7528\u3001rag\u3001\u5fae\u8c03.\u3002pdf fine-tuning \u5b8c\u6574\u7248pdf\uff1a 666 application prompt internal/external apis function calling rag response vector embeddings documents database fine-tuned model agent foundation llm", "AI": {"tldr": "\u5f7b\u5e95\u641e\u61c2\u5927\u6a21\u578b\u3002llm\uff1a\u63d0\u793a\u5de5\u7a0b\u3001\u51fd\u6570\u8c03\u7528\u3001rag\u3001\u5fae\u8c03.\u3002pdf fine-tuning \u5b8c\u6574\u7248pdf\uff1a 666 application prompt internal/external apis function calling rag response vector embeddings documents database fine-tuned model agent foundation...", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.00def231", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxMjQ2NDg5NQ==&mid=2247487782&idx=2&sn=c7e80825de075f619e58d10d34bad182&chksm=c05a7d20bc19837085ab2a78f927d3c89b5a0ba61d4251111d3509f5d00fd8383f93525cfc8f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxMjQ2NDg5NQ==&mid=2247487782&idx=2&sn=c7e80825de075f619e58d10d34bad182&chksm=c05a7d20bc19837085ab2a78f927d3c89b5a0ba61d4251111d3509f5d00fd8383f93525cfc8f#rd", "authors": ["\u5929\u62e9\u6da8\u4e0d\u505c"], "title": "\u4ece<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5230\u667a\u80fd\u4f53\u2014\u2014\u4eba\u5de5\u667a\u80fd+\u573a\u666f\u7684\u6295\u8d44\u5c55\u671b", "comment": "Source: WeChat, Published: 2025-09-22 08:59:07", "summary": "\u25e5AI\u5927\u6a21\u578b\u5df2\u7ecf\u53ef\u4ee5\u6267\u884c\u591a\u79cd\u7c7b\u578b\u7684\u8bed\u8a00\u4efb\u52a1\uff0c\u5305\u62ec\u56de\u7b54\u95ee\u9898\u3001\u751f\u6210\u6587\u672c\u3001\u7ffb\u8bd1\u8bed\u8a00\u3001\u6587\u732e\u6458\u8981\u548c\u7d22\u5f15\u7b49\u7b49\uff0c\u501f\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f85\u52a9\uff0c\u90e8\u5206\u5176\u4ed6\u7c7b\u578b\u7684AI\u5927\u6a21\u578b\u4e5f\u6b63\u5728\u83b7\u5f97\u5feb\u901f\u53d1\u5c55\u7684\u52a8\u529b\uff0cAIGC\u5728\u591a\u4e2a\u9886\u57df\u51fa\u73b0\u7a81\u7834\u3002", "AI": {"tldr": "\u25e5AI\u5927\u6a21\u578b\u5df2\u7ecf\u53ef\u4ee5\u6267\u884c\u591a\u79cd\u7c7b\u578b\u7684\u8bed\u8a00\u4efb\u52a1\uff0c\u5305\u62ec\u56de\u7b54\u95ee\u9898\u3001\u751f\u6210\u6587\u672c\u3001\u7ffb\u8bd1\u8bed\u8a00\u3001\u6587\u732e\u6458\u8981\u548c\u7d22\u5f15\u7b49\u7b49\uff0c\u501f\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f85\u52a9\uff0c\u90e8\u5206\u5176\u4ed6\u7c7b\u578b\u7684AI\u5927\u6a21\u578b\u4e5f\u6b63\u5728\u83b7\u5f97\u5feb\u901f\u53d1\u5c55\u7684\u52a8\u529b\uff0cAIGC\u5728\u591a\u4e2a\u9886\u57df\u51fa\u73b0\u7a81\u7834\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.4ca4bbf1", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxOTQ2NzUxOQ==&mid=2651925252&idx=1&sn=3f82e99a4daabfbba0b243ebbd0251f0&chksm=81e4377838a5ac59bc03d6d3c62c63082b20741339805d8b645394def8c97d19d4493219e9c1#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxOTQ2NzUxOQ==&mid=2651925252&idx=1&sn=3f82e99a4daabfbba0b243ebbd0251f0&chksm=81e4377838a5ac59bc03d6d3c62c63082b20741339805d8b645394def8c97d19d4493219e9c1#rd", "authors": ["\u5927\u6570\u636e\u671f\u520a"], "title": "\u57fa\u4e8e\u591a\u6a21\u6001<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u8fdb\u5c55\u4e0e\u5c55\u671b", "comment": "Source: WeChat, Published: 2025-09-22 08:16:00", "summary": "\u56fe2 \u57fa\u4e8e\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7efc\u8ff0\u7684\u6574\u4f53\u6846\u67b61 \u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u5177\u8eab\u667a\u80fd\u4f53\u4e2d\uff0c\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u662f\u4e00\u79cd\u6838\u5fc3\u7684\u591a\u6a21\u6001\u6a21\u578b\u3002\u672c\u8282\u91cd\u70b9\u4ecb\u7ecd\u8fd1\u5e74\u6765\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u8109\u7edc\u53ca\u5177\u6709\u4ee3\u8868\u6027\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "AI": {"tldr": "\u56fe2 \u57fa\u4e8e\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7efc\u8ff0\u7684\u6574\u4f53\u6846\u67b61 \u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u5177\u8eab\u667a\u80fd\u4f53\u4e2d\uff0c\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u662f\u4e00\u79cd\u6838\u5fc3\u7684\u591a\u6a21\u6001\u6a21\u578b\u3002\u672c\u8282\u91cd\u70b9\u4ecb\u7ecd\u8fd1\u5e74\u6765\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u8109\u7edc\u53ca\u5177\u6709\u4ee3\u8868\u6027\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.5d83bf63", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAwNzYzMzQwMg==&mid=2651694100&idx=2&sn=9e7bd3416f69f3ef339d0aa095429b35&chksm=81c28787fd7608d9fb124e8ff138f7cddfaee619c6f2dec97a0ff9342163f5f7ebe6f37c46df#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAwNzYzMzQwMg==&mid=2651694100&idx=2&sn=9e7bd3416f69f3ef339d0aa095429b35&chksm=81c28787fd7608d9fb124e8ff138f7cddfaee619c6f2dec97a0ff9342163f5f7ebe6f37c46df#rd", "authors": ["\u7ae0\u9c7c\u5927\u6570\u636e"], "title": "\u56fe\u89e3AI\u6838\u5fc3\u6280\u672f\uff1aRAG\u3001<em class=\"highlight\">\u5927\u6a21\u578b</em>\u3001\u667a\u80fd\u4f53", "comment": "Source: WeChat, Published: 2025-09-22 08:05:54", "summary": "\u751f\u6210\uff08Generation\uff09\uff1a\u5c06\u68c0\u7d22\u7ed3\u679c\u62fc\u63a5\u4e3a\u4e0a\u4e0b\u6587\uff0c\u8f93\u5165\u5927\u6a21\u578b\u751f\u6210\u56de\u7b54\u3002\u7279\u70b9\u9759\u6001\u5904\u7406\uff1a\u68c0\u7d22\u4e0e\u751f\u6210\u5206\u79bb\uff0c\u65e0\u53cd\u9988\u5faa\u73af\u3002\u5c40\u9650\u6027\uff1a\u68c0\u7d22\u7ed3\u679c\u8d28\u91cf\u76f4\u63a5\u9650\u5236\u751f\u6210\u6548\u679c\uff1b", "AI": {"tldr": "\u751f\u6210\uff08Generation\uff09\uff1a\u5c06\u68c0\u7d22\u7ed3\u679c\u62fc\u63a5\u4e3a\u4e0a\u4e0b\u6587\uff0c\u8f93\u5165\u5927\u6a21\u578b\u751f\u6210\u56de\u7b54\u3002\u7279\u70b9\u9759\u6001\u5904\u7406\uff1a\u68c0\u7d22\u4e0e\u751f\u6210\u5206\u79bb\uff0c\u65e0\u53cd\u9988\u5faa\u73af\u3002\u5c40\u9650\u6027\uff1a\u68c0\u7d22\u7ed3\u679c\u8d28\u91cf\u76f4\u63a5\u9650\u5236\u751f\u6210\u6548\u679c\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.46acec5f", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650449986&idx=1&sn=67d62aa5bb686521a8321c769b882468&chksm=bf2493190114ba49954f768d52060ab35f39bb9d5aa46f05adc82da2995f2ee85fa0a887a2be#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650449986&idx=1&sn=67d62aa5bb686521a8321c769b882468&chksm=bf2493190114ba49954f768d52060ab35f39bb9d5aa46f05adc82da2995f2ee85fa0a887a2be#rd", "authors": ["AINLP"], "title": "\u51e0\u4e4e\u89e3\u51b3\u6240\u6709\u591a\u6a21\u6001<em class=\"highlight\">\u5927\u6a21\u578b</em>\u95ee\u9898", "comment": "Source: WeChat, Published: 2025-09-22 02:11:10", "summary": "\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411 \u591a\u6a21\u6001transformer\u7684\u4e03\u5341\u4e8c\u53d8 \u4efb\u610f\u89c6\u89c9\u63d0\u793a\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b \u591a\u6a21\u6001-lisa \uff08cvpr2024\uff09 \u6700\u65b0\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684idea \u591a\u6a21\u6001agents\u53ca\u5176\u5e94\u7528\u3002", "AI": {"tldr": "\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411 \u591a\u6a21\u6001transformer\u7684\u4e03\u5341\u4e8c\u53d8 \u4efb\u610f\u89c6\u89c9\u63d0\u793a\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b \u591a\u6a21\u6001-lisa \uff08cvpr2024\uff09 \u6700\u65b0\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684idea \u591a\u6a21\u6001agents\u53ca\u5176\u5e94\u7528\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.cbe6e863", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI2MzcxMTU5Mg==&mid=2247532970&idx=1&sn=af316b8bdb4dade0dfe17d0c3caf3d38&chksm=eb39ac92370da0d3177b4f7c4551d3b378ee62e5140a86404f6648d7849f4ee24871e5d354bb#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI2MzcxMTU5Mg==&mid=2247532970&idx=1&sn=af316b8bdb4dade0dfe17d0c3caf3d38&chksm=eb39ac92370da0d3177b4f7c4551d3b378ee62e5140a86404f6648d7849f4ee24871e5d354bb#rd", "authors": ["\u56db\u5ddd\u5174\u5408\u7530\u804c\u4e1a\u6559\u80b2\u7814\u7a76\u9662"], "title": "\u4e2d\u56fd\u4fe1\u901a\u9662\u7275\u5934\u76845\u9879<em class=\"highlight\">\u5927\u6a21\u578b</em>\u884c\u4e1a\u6807\u51c6\u6b63\u5f0f\u53d1\u5e03", "comment": "Source: WeChat, Published: 2025-09-22 01:46:55", "summary": "\u8be5\u7cfb\u5217\u6807\u51c6\u8986\u76d6\u5927\u6a21\u578b\u7684\u5f00\u53d1\u3001\u7ba1\u7406\u3001\u8fd0\u8425\u7b49\u591a\u4e2a\u9636\u6bb5\uff0c\u4e3b\u8981\u5305\u62ec\u6a21\u578b\u5f00\u53d1\u3001\u80fd\u529b\u8bc4\u4f30\u3001\u5e94\u7528\u6210\u6548\u3001\u8fd0\u8425\u7ba1\u7406\u548c\u53ef\u4fe1\u8981\u6c42\u4e94\u90e8\u5206\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u548c\u4ea7\u54c1\u7684\u7814\u53d1\u6d4b\u8bd5\u548c\u5e94\u7528\u63a8\u5e7f\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "AI": {"tldr": "\u8be5\u7cfb\u5217\u6807\u51c6\u8986\u76d6\u5927\u6a21\u578b\u7684\u5f00\u53d1\u3001\u7ba1\u7406\u3001\u8fd0\u8425\u7b49\u591a\u4e2a\u9636\u6bb5\uff0c\u4e3b\u8981\u5305\u62ec\u6a21\u578b\u5f00\u53d1\u3001\u80fd\u529b\u8bc4\u4f30\u3001\u5e94\u7528\u6210\u6548\u3001\u8fd0\u8425\u7ba1\u7406\u548c\u53ef\u4fe1\u8981\u6c42\u4e94\u90e8\u5206\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u548c\u4ea7\u54c1\u7684\u7814\u53d1\u6d4b\u8bd5\u548c\u5e94\u7528\u63a8\u5e7f\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2509.1f2aacbb", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4NTczNzg2OA==&mid=2247508784&idx=2&sn=5a6fe7a07365b015a0939c0606ebcee3&chksm=ce02cc4bce7cf02745aefa8965103b723f451e2e48eaf587de279423949c72d00db0c29186e5#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4NTczNzg2OA==&mid=2247508784&idx=2&sn=5a6fe7a07365b015a0939c0606ebcee3&chksm=ce02cc4bce7cf02745aefa8965103b723f451e2e48eaf587de279423949c72d00db0c29186e5#rd", "authors": ["\u963f\u91cc\u6280\u672f"], "title": "SGLang \u00d7 RoleBasedGroup\uff08RBG\uff09\uff1a\u6253\u901a<em class=\"highlight\">\u5927\u6a21\u578b</em>\u63a8\u7406PD\u5206\u79bb\u67b6\u6784\u89c4\u6a21\u5316\u843d\u5730\u7684\u201c\u6700\u540e\u4e00\u516c\u91cc\u201d", "comment": "Source: WeChat, Published: 2025-09-22 00:30:25", "summary": "OME\uff08Open Model Engine\uff09\u5b9a\u4f4d\uff1a\u7aef\u5230\u7aef\u7684\u300c\u5927\u6a21\u578b\u670d\u52a1\u6846\u67b6\u300d\u3002\u5b83\u628a\u201c\u6a21\u578b\u201d\u672c\u8eab\u63d0\u5347\u4e3a\u4e00\u7b49\u516c\u6c11\uff08Model \u548c Inference \u76f8\u5173 CRD\uff09\uff0c\u81ea\u52a8\u5b8c\u6210\u6a21\u578b\u4e0b\u8f7d\u3001\u89e3\u6790\u3001\u9009 runtime\u3001\u751f\u6210\u6700\u4f18\u62d3\u6251\u3001\u66b4\u9732 OpenAI \u517c\u5bb9\u63a5\u53e3\u3001\u9644\u5e26 BenchmarkJob\u3001LoRA\u3001\u52a0\u5bc6\u7b49", "AI": {"tldr": "OME\uff08Open Model Engine\uff09\u5b9a\u4f4d\uff1a\u7aef\u5230\u7aef\u7684\u300c\u5927\u6a21\u578b\u670d\u52a1\u6846\u67b6\u300d\u3002\u5b83\u628a\u201c\u6a21\u578b\u201d\u672c\u8eab\u63d0\u5347\u4e3a\u4e00\u7b49\u516c\u6c11\uff08Model \u548c Inference \u76f8\u5173 CRD\uff09\uff0c\u81ea\u52a8\u5b8c\u6210\u6a21\u578b\u4e0b\u8f7d\u3001\u89e3\u6790\u3001\u9009 runtime\u3001\u751f\u6210\u6700\u4f18\u62d3\u6251\u3001\u66b4\u9732 OpenAI \u517c\u5bb9\u63a5\u53e3\u3001\u9644\u5e26 BenchmarkJob\u3001LoRA\u3001\u52a0\u5bc6\u7b49", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2509.fe89383a", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIzODIzNzE0NQ==&mid=2654455438&idx=1&sn=232cfdc7d033d0640fcacf2a25c54c6d&chksm=f3501ab8f8123553cfb5a88c04f9410e627aa54698551d13100a473c8cf38c128d5299b1b3ec#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIzODIzNzE0NQ==&mid=2654455438&idx=1&sn=232cfdc7d033d0640fcacf2a25c54c6d&chksm=f3501ab8f8123553cfb5a88c04f9410e627aa54698551d13100a473c8cf38c128d5299b1b3ec#rd", "authors": ["\u7384\u59d0\u804aAGI"], "title": "\u4e00\u6587\u8bfb\u61c2 Go \u8bed\u8a00 AI \u667a\u80fd\u4f53\u6846\u67b6 Eino\uff1a\u7075\u6d3b\u9ad8\u6548\u7684<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5e94\u7528\u5f00\u53d1\u5de5\u5177", "comment": "Source: WeChat, Published: 2025-09-22 00:01:29", "summary": "Tool\u6269\u5c55\u5927\u6a21\u578b\u80fd\u529b\u7684\u5de5\u5177\uff08\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u3001\u6570\u636e\u5e93\u67e5\u8be2\u3001\u6587\u4ef6\u8bfb\u5199\uff09\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u3002Embedding\u628a\u6587\u672c\u8f6c\u6210\u5411\u91cf\uff08\u65b9\u4fbf\u505a\u8bed\u4e49\u641c\u7d22\uff09\u3002Retriever\u4ece\u5411\u91cf\u5e93 / \u6587\u6863\u5e93\u4e2d\u68c0\u7d22\u76f8\u5173\u5185\u5bb9\uff08\u5927\u6a21\u578b \u201c\u67e5\u8d44\u6599\u201d \u7684\u5173\u952e\uff09\u3002", "AI": {"tldr": "Tool\u6269\u5c55\u5927\u6a21\u578b\u80fd\u529b\u7684\u5de5\u5177\uff08\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u3001\u6570\u636e\u5e93\u67e5\u8be2\u3001\u6587\u4ef6\u8bfb\u5199\uff09\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u3002Embedding\u628a\u6587\u672c\u8f6c\u6210\u5411\u91cf\uff08\u65b9\u4fbf\u505a\u8bed\u4e49\u641c\u7d22\uff09\u3002Retriever\u4ece\u5411\u91cf\u5e93 / \u6587\u6863\u5e93\u4e2d\u68c0\u7d22\u76f8\u5173\u5185\u5bb9\uff08\u5927\u6a21\u578b \u201c\u67e5\u8d44\u6599\u201d \u7684\u5173\u952e\uff09\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2509.1753d725", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk2NDEyMTM1Mg==&mid=2247485492&idx=2&sn=d7abea6e005a1c4cc241d4d301ae3774&chksm=c54dde5ff4dd85716d6e0b4b75f1b8086c836699e49922fd3f8a81a1930bb1e0e414e938ffd0#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk2NDEyMTM1Mg==&mid=2247485492&idx=2&sn=d7abea6e005a1c4cc241d4d301ae3774&chksm=c54dde5ff4dd85716d6e0b4b75f1b8086c836699e49922fd3f8a81a1930bb1e0e414e938ffd0#rd", "authors": ["GPU\u90a3\u4e9b\u4e8b\u513f"], "title": "\u767d\u8bdd\u6a21\u578b-01\u4e4b<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7814\u53d1\u5168\u6d41\u7a0b\u4e00\u6587\u89e3\u8bfb", "comment": "Source: WeChat, Published: 2025-09-21 23:08:53", "summary": "\u8fd9\u662f\u8ba9\u5927\u6a21\u578b\u884c\u4e3a\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u5173\u952e\u6280\u672f\u3002\u56db\u3001\u8bc4\u4f30\u4e0e\u8fed\u4ee3 \uff08Evaluation & Iteration\uff09\u6a21\u578b\u8bad\u7ec3\u4e0d\u662f\u4e00\u8e74\u800c\u5c31\u7684\uff0c\u9700\u8981\u6301\u7eed\u8bc4\u4f30\u548c\u4f18\u5316\u3002\u8bc4\u4f30\u57fa\u51c6\uff1a \u4f7f\u7528\u4e00\u7cfb\u5217\u6807\u51c6\u5316\u7684\u5b66\u672f\u57fa\u51c6\uff08\u5982MMLU\u7528\u4e8e\u6d4b\u8bd5 Massive Multitask Language Understanding", "AI": {"tldr": "\u8fd9\u662f\u8ba9\u5927\u6a21\u578b\u884c\u4e3a\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u5bf9\u9f50\u7684\u5173\u952e\u6280\u672f\u3002\u56db\u3001\u8bc4\u4f30\u4e0e\u8fed\u4ee3 \uff08Evaluation & Iteration\uff09\u6a21\u578b\u8bad\u7ec3\u4e0d\u662f\u4e00\u8e74\u800c\u5c31\u7684\uff0c\u9700\u8981\u6301\u7eed\u8bc4\u4f30\u548c\u4f18\u5316\u3002\u8bc4\u4f30\u57fa\u51c6\uff1a \u4f7f\u7528\u4e00\u7cfb\u5217\u6807\u51c6\u5316\u7684\u5b66\u672f\u57fa\u51c6\uff08\u5982MMLU\u7528\u4e8e\u6d4b\u8bd5 Massive Multitask Language Understanding", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
