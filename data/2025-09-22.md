<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.SE](#cs.SE) [Total: 5]
- [cs.LG](#cs.LG) [Total: 15]
- [wechat.article](#wechat.article) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion](https://arxiv.org/abs/2509.16112)
*Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li*

Main category: cs.CL

TL;DR: CodeRAG是一个针对仓库级代码补全的检索增强框架，通过改进查询构建、多路径代码检索和最佳匹配重排序，显著提升了代码补全性能。


<details>
  <summary>Details</summary>
Motivation: 现有的仓库级代码补全方法存在查询构建不当、单路径代码检索以及代码检索器与LLM不对齐等问题，需要更有效的检索增强机制。

Method: 提出CodeRAG框架，包含对数概率引导的查询构建、多路径代码检索和偏好对齐的BestFit重排序三个核心组件。

Result: 在ReccEval和CCEval基准测试中，CodeRAG显著且持续地优于最先进的方法。

Conclusion: CodeRAG通过改进的检索增强机制有效解决了仓库级代码补全中的关键问题，提供了更好的代码补全性能。

Abstract: Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.

</details>


### [2] [RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation](https://arxiv.org/abs/2509.16198)
*Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang*

Main category: cs.CL

TL;DR: 提出了Repository Planning Graph (RPG)表示法和ZeroRepo框架，用于从零生成完整代码仓库，显著优于现有基线方法


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在函数和文件级别代码生成表现优秀，但从零生成完整仓库仍面临挑战，自然语言的模糊性不适合表示复杂软件结构

Method: 引入RPG图表示法统一提案和实现级别规划，构建ZeroRepo三阶段框架：提案规划、实现细化、图引导代码生成与测试验证

Result: 在RepoCraft基准测试中生成平均36K行代码，功能覆盖率达81.5%，通过率69.7%，远超Claude Code等基线方法

Conclusion: RPG能有效建模复杂依赖关系，通过近线性扩展实现渐进式复杂规划，提升LLM对仓库的理解并加速智能体定位

Abstract: Large language models excel at function- and file-level code generation, yet
generating complete repositories from scratch remains a fundamental challenge.
This process demands coherent and reliable planning across proposal- and
implementation-level stages, while natural language, due to its ambiguity and
verbosity, is ill-suited for faithfully representing complex software
structures. To address this, we introduce the Repository Planning Graph (RPG),
a persistent representation that unifies proposal- and implementation-level
planning by encoding capabilities, file structures, data flows, and functions
in one graph. RPG replaces ambiguous natural language with an explicit
blueprint, enabling long-horizon planning and scalable repository generation.
Building on RPG, we develop ZeroRepo, a graph-driven framework for repository
generation from scratch. It operates in three stages: proposal-level planning
and implementation-level refinement to construct the graph, followed by
graph-guided code generation with test validation. To evaluate this setting, we
construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.
On RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly
3.9$\times$ the strongest baseline (Claude Code) and about 64$\times$ other
baselines. It attains 81.5% functional coverage and a 69.7% pass rate,
exceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further
analysis shows that RPG models complex dependencies, enables progressively more
sophisticated planning through near-linear scaling, and enhances LLM
understanding of repositories, thereby accelerating agent localization.

</details>


### [3] [How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages](https://arxiv.org/abs/2509.15518)
*Siyang Wu,Zhewei Sun*

Main category: cs.CL

TL;DR: 本文系统比较了人类与LLM生成的俚语用法，发现LLM在俚语理解上存在显著偏见，虽然掌握了创造性特征但不足以支持语言学分析等外推任务。


<details>
  <summary>Details</summary>
Motivation: 俚语作为非正式语言对NLP系统构成挑战，需要评估LLM是否掌握了与人类一致的俚语结构知识，以确定其可靠性和泛化能力。

Method: 构建评估框架，从三个核心维度（系统性偏见、创造性、信息性）比较Online Slang Dictionary的人类俚语与GPT-4o、Llama-3生成的俚语。

Result: 发现LLM在俚语感知上存在显著偏见，虽然掌握了俚语的创造性特征，但这些知识不足以支持外推性任务如语言学分析。

Conclusion: LLM虽然学习了俚语的创造性方面，但其知识结构与人类不一致，限制了在俚语检测和解释等中介任务中的可靠性。

Abstract: Slang is a commonly used type of informal language that poses a daunting
challenge to NLP systems. Recent advances in large language models (LLMs),
however, have made the problem more approachable. While LLM agents are becoming
more widely applied to intermediary tasks such as slang detection and slang
interpretation, their generalizability and reliability are heavily dependent on
whether these models have captured structural knowledge about slang that align
well with human attested slang usages. To answer this question, we contribute a
systematic comparison between human and machine-generated slang usages. Our
evaluative framework focuses on three core aspects: 1) Characteristics of the
usages that reflect systematic biases in how machines perceive slang, 2)
Creativity reflected by both lexical coinages and word reuses employed by the
slang usages, and 3) Informativeness of the slang usages when used as
gold-standard examples for model distillation. By comparing human-attested
slang usages from the Online Slang Dictionary (OSD) and slang generated by
GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our
results suggest that while LLMs have captured significant knowledge about the
creative aspects of slang, such knowledge does not align with humans
sufficiently to enable LLMs for extrapolative tasks such as linguistic
analyses.

</details>


### [4] [Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems](https://arxiv.org/abs/2509.15839)
*Zhongze Luo,Zhenshuai Yin,Yongxin Guo,Zhichao Wang,Jionghao Zhu,Xiaoying Tang*

Main category: cs.CL

TL;DR: 提出了Multi-Physics中文物理推理基准，包含5个难度级别、1412道图像关联选择题，覆盖11个高中物理主题，用于系统评估多模态大语言模型在科学领域的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准在专业科学领域（如物理）存在不足：缺乏细粒度学科覆盖、忽视逐步推理过程、以英语为中心、未能系统评估视觉信息的作用。

Method: 构建包含5个难度级别、1412道图像关联选择题的中文物理基准；采用双重评估框架评估20个不同MLLM模型，分析最终答案准确性和逐步推理完整性；系统研究难度级别和视觉信息的影响。

Result: 提供了细粒度的社区资源，并提供了剖析最先进MLLM多模态推理过程的稳健方法；数据集和代码已开源。

Conclusion: Multi-Physics基准填补了现有评估在科学领域的空白，为系统评估多模态推理能力提供了重要工具。

Abstract: While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress,
their application in specialized scientific domains like physics reveals
significant gaps in current evaluation benchmarks. Specifically, existing
benchmarks often lack fine-grained subject coverage, neglect the step-by-step
reasoning process, and are predominantly English-centric, failing to
systematically evaluate the role of visual information. Therefore, we introduce
\textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive
benchmark that includes 5 difficulty levels, featuring 1,412 image-associated,
multiple-choice questions spanning 11 high-school physics subjects. We employ a
dual evaluation framework to evaluate 20 different MLLMs, analyzing both final
answer accuracy and the step-by-step integrity of their chain-of-thought.
Furthermore, we systematically study the impact of difficulty level and visual
information by comparing the model performance before and after changing the
input mode. Our work provides not only a fine-grained resource for the
community but also offers a robust methodology for dissecting the multimodal
reasoning process of state-of-the-art MLLMs, and our dataset and code have been
open-sourced: https://github.com/luozhongze/Multi-Physics.

</details>


### [5] [Beyond Pointwise Scores: Decomposed Criteria-Based Evaluation of LLM Responses](https://arxiv.org/abs/2509.16093)
*Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: DeCE是一个分解式LLM评估框架，将答案质量分解为精确度（事实准确性）和召回率（概念覆盖率），在专业领域实现了与专家判断更强的相关性。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标如BLEU和ROUGE无法捕捉语义正确性，现有LLM评估器往往将答案质量的细微差别简化为单一分数，无法满足高风险领域如法律或医学的评估需求。

Method: DeCE框架自动从标准答案要求中提取实例特定标准，将评估分解为精确度（事实准确性和相关性）和召回率（所需概念覆盖率），无需预定义分类法或手工制定的评分标准。

Result: DeCE与专家判断的相关性达到0.78，显著优于传统指标（0.12）、点式LLM评分（0.35）和多维评估器（0.48）。仅11.95%的LLM生成标准需要专家修订。

Conclusion: DeCE提供了一个可解释且可操作的LLM评估框架，在专业领域表现出色，能够揭示通用模型偏向召回率而专业模型偏向精确度的可解释权衡。

Abstract: Evaluating long-form answers in high-stakes domains such as law or medicine
remains a fundamental challenge. Standard metrics like BLEU and ROUGE fail to
capture semantic correctness, and current LLM-based evaluators often reduce
nuanced aspects of answer quality into a single undifferentiated score. We
introduce DeCE, a decomposed LLM evaluation framework that separates precision
(factual accuracy and relevance) and recall (coverage of required concepts),
using instance-specific criteria automatically extracted from gold answer
requirements. DeCE is model-agnostic and domain-general, requiring no
predefined taxonomies or handcrafted rubrics. We instantiate DeCE to evaluate
different LLMs on a real-world legal QA task involving multi-jurisdictional
reasoning and citation grounding. DeCE achieves substantially stronger
correlation with expert judgments ($r=0.78$), compared to traditional metrics
($r=0.12$), pointwise LLM scoring ($r=0.35$), and modern multidimensional
evaluators ($r=0.48$). It also reveals interpretable trade-offs: generalist
models favor recall, while specialized models favor precision. Importantly,
only 11.95% of LLM-generated criteria required expert revision, underscoring
DeCE's scalability. DeCE offers an interpretable and actionable LLM evaluation
framework in expert domains.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [MICA: Multi-Agent Industrial Coordination Assistant](https://arxiv.org/abs/2509.15237)
*Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen*

Main category: cs.AI

TL;DR: MICA是一个多代理工业协调助手系统，通过语音交互提供实时装配、故障排除等指导，采用五个角色专业化的语言代理和安全检查器确保准确合规，在离线硬件上部署且保护隐私。


<details>
  <summary>Details</summary>
Motivation: 工业工作流程需要能够在有限计算、连接性和严格隐私约束下运行的适应性强的可信助手系统。

Method: 采用五个角色专业化的语言代理协调工作，引入自适应步骤融合(ASF)动态混合专家推理和自然语音反馈的在线适应，建立新的多代理协调基准和评估指标。

Result: 实验表明MICA在任务成功率、可靠性和响应性方面持续优于基线结构，可在实际离线硬件上部署。

Conclusion: MICA是朝着可部署、保护隐私的多代理助手在动态工厂环境中应用的重要一步。

Abstract: Industrial workflows demand adaptive and trustworthy assistance that can
operate under limited computing, connectivity, and strict privacy constraints.
In this work, we present MICA (Multi-Agent Industrial Coordination Assistant),
a perception-grounded and speech-interactive system that delivers real-time
guidance for assembly, troubleshooting, part queries, and maintenance. MICA
coordinates five role-specialized language agents, audited by a safety checker,
to ensure accurate and compliant support. To achieve robust step understanding,
we introduce Adaptive Step Fusion (ASF), which dynamically blends expert
reasoning with online adaptation from natural speech feedback. Furthermore, we
establish a new multi-agent coordination benchmark across representative task
categories and propose evaluation metrics tailored to industrial assistance,
enabling systematic comparison of different coordination topologies. Our
experiments demonstrate that MICA consistently improves task success,
reliability, and responsiveness over baseline structures, while remaining
deployable on practical offline hardware. Together, these contributions
highlight MICA as a step toward deployable, privacy-preserving multi-agent
assistants for dynamic factory environments. The source code will be made
publicly available at https://github.com/Kratos-Wen/MICA.

</details>


### [7] [The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI](https://arxiv.org/abs/2509.15291)
*Federico Taschin,Abderrahmane Lazaraq,Ozan K. Tonguz,Inci Ozgunes*

Main category: cs.AI

TL;DR: 本文评估了MetaLight这一元强化学习方法在交通信号控制中的应用，发现虽然在某些条件下表现良好，但在其他条件下可能出现高达22%的错误，表明元强化学习方案往往不够稳健。


<details>
  <summary>Details</summary>
Motivation: 智能交通网络中强化学习应用的可靠性问题，特别是输入数据分布动态变化导致的训练代理可靠性挑战。

Method: 评估和分析最先进的元强化学习方法MetaLight在不同条件下的性能表现。

Result: MetaLight在某些条件下能产生相当好的结果，但在其他条件下表现不佳，错误率高达22%。

Conclusion: 元强化学习方案通常不够稳健，甚至可能带来重大的可靠性问题。

Abstract: The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart
transportation networks has increased significantly in the last few years.
Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to
be a very promising approach by several authors. However, a problem with using
Reinforcement Learning in Traffic Signal Control is the reliability of the
trained RL agents due to the dynamically changing distribution of the input
data with respect to the distribution of the data used for training. This
presents a major challenge and a reliability problem for the trained network of
AI agents and could have very undesirable and even detrimental consequences if
a suitable solution is not found. Several researchers have tried to address
this problem using different approaches. In particular, Meta Reinforcement
Learning (Meta RL) promises to be an effective solution. In this paper, we
evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and
show that, while under certain conditions MetaLight can indeed lead to
reasonably good results, under some other conditions it might not perform well
(with errors of up to 22%), suggesting that Meta RL schemes are often not
robust enough and can even pose major reliability problems.

</details>


### [8] [Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling](https://arxiv.org/abs/2509.15336)
*Humam Kourani,Anton Antonov,Alessandro Berti,Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 论文研究大型语言模型在知识驱动幻觉方面的风险，即在自动化流程建模任务中，模型内部知识会覆盖明确的源证据导致输出矛盾。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在分析任务中由于预训练知识导致的可靠性问题，特别是在证据与模型内部知识冲突时产生的知识驱动幻觉现象。

Method: 通过在业务流程管理领域进行受控实验，使用标准和非典型流程结构作为输入，测量LLMs对提供证据的忠实度。

Result: 研究发现LLMs确实存在知识驱动幻觉问题，当提供的证据与模型内部知识冲突时，模型倾向于依赖预训练模式而非实际证据。

Conclusion: 提出了评估这种关键可靠性问题的方法论，强调在任何基于证据的领域中都需要对AI生成产物进行严格验证。

Abstract: The utility of Large Language Models (LLMs) in analytical tasks is rooted in
their vast pre-trained knowledge, which allows them to interpret ambiguous
inputs and infer missing information. However, this same capability introduces
a critical risk of what we term knowledge-driven hallucination: a phenomenon
where the model's output contradicts explicit source evidence because it is
overridden by the model's generalized internal knowledge. This paper
investigates this phenomenon by evaluating LLMs on the task of automated
process modeling, where the goal is to generate a formal business process model
from a given source artifact. The domain of Business Process Management (BPM)
provides an ideal context for this study, as many core business processes
follow standardized patterns, making it likely that LLMs possess strong
pre-trained schemas for them. We conduct a controlled experiment designed to
create scenarios with deliberate conflict between provided evidence and the
LLM's background knowledge. We use inputs describing both standard and
deliberately atypical process structures to measure the LLM's fidelity to the
provided evidence. Our work provides a methodology for assessing this critical
reliability issue and raises awareness of the need for rigorous validation of
AI-generated artifacts in any evidence-based domain.

</details>


### [9] [Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context](https://arxiv.org/abs/2509.15366)
*Andrejs Sorstkins,Josh Bailey,Dr Alistair Baron*

Main category: cs.AI

TL;DR: 提出了一个诊断框架，用于评估和改进具有专家行为的LLM智能体，通过黄金数据集、银数据集和智能体法官来实现专家行为的标准化转移。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法无法充分诊断具有随机性和多步决策过程的LLM智能体性能，需要新的框架来促进专家行为向LLM智能体的转移。

Method: 集成三个核心组件：(1)专家标注的黄金数据集，(2)通过受控行为突变生成的银数据集，(3)基于LLM的智能体法官进行评分和针对性改进建议。

Result: 在多智能体招聘助理系统上验证，发现潜在认知失败（如偏见措辞、提取漂移、工具误路由），同时引导智能体达到专家级推理和风格。

Conclusion: 为随机性、工具增强的LLM智能体建立了标准化、可复现的专家行为转移基础，从静态评估转向主动的专家系统改进。

Abstract: The rapid evolution of neural architectures - from multilayer perceptrons to
large-scale Transformer-based models - has enabled language models (LLMs) to
exhibit emergent agentic behaviours when equipped with memory, planning, and
external tool use. However, their inherent stochasticity and multi-step
decision processes render classical evaluation methods inadequate for
diagnosing agentic performance. This work introduces a diagnostic framework for
expert systems that not only evaluates but also facilitates the transfer of
expert behaviour into LLM-powered agents. The framework integrates (i) curated
golden datasets of expert annotations, (ii) silver datasets generated through
controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores
and prescribes targeted improvements. These prescriptions are embedded into a
vectorized recommendation map, allowing expert interventions to propagate as
reusable improvement trajectories across multiple system instances. We
demonstrate the framework on a multi-agent recruiter-assistant system, showing
that it uncovers latent cognitive failures - such as biased phrasing,
extraction drift, and tool misrouting - while simultaneously steering agents
toward expert-level reasoning and style. The results establish a foundation for
standardized, reproducible expert behaviour transfer in stochastic,
tool-augmented LLM agents, moving beyond static evaluation to active expert
system refinement.

</details>


### [10] [MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents](https://arxiv.org/abs/2509.15635)
*Pan Tang,Shixiang Tang,Huanqi Pu,Zhiqing Miao,Zhixing Wang*

Main category: cs.AI

TL;DR: MicroRCA-Agent是一个基于大语言模型代理的微服务根因分析系统，通过多模态数据融合和创新的技术方法实现高效的故障定位。


<details>
  <summary>Details</summary>
Motivation: 解决微服务环境中复杂故障根因定位的挑战，利用大语言模型的跨模态理解和逻辑推理能力来提升故障分析效率。

Method: 结合预训练的Drain日志解析算法和多级数据过滤机制压缩日志；采用Isolation Forest无监督学习和状态码验证的双异常检测方法；设计统计对称比过滤机制和两阶段LLM分析策略；利用跨模态提示深度整合多模态异常信息。

Result: 在复杂微服务故障场景中表现出优越性能，最终得分为50.71，消融研究验证了各模态数据的互补价值和系统架构的有效性。

Conclusion: MicroRCA-Agent通过创新的多模态数据融合和LLM驱动的分析方法，为微服务根因分析提供了有效的解决方案，代码已开源。

Abstract: This paper presents MicroRCA-Agent, an innovative solution for microservice
root cause analysis based on large language model agents, which constructs an
intelligent fault root cause localization system with multimodal data fusion.
The technical innovations are embodied in three key aspects: First, we combine
the pre-trained Drain log parsing algorithm with multi-level data filtering
mechanism to efficiently compress massive logs into high-quality fault
features. Second, we employ a dual anomaly detection approach that integrates
Isolation Forest unsupervised learning algorithms with status code validation
to achieve comprehensive trace anomaly identification. Third, we design a
statistical symmetry ratio filtering mechanism coupled with a two-stage LLM
analysis strategy to enable full-stack phenomenon summarization across
node-service-pod hierarchies. The multimodal root cause analysis module
leverages carefully designed cross-modal prompts to deeply integrate multimodal
anomaly information, fully exploiting the cross-modal understanding and logical
reasoning capabilities of large language models to generate structured analysis
results encompassing fault components, root cause descriptions, and reasoning
trace. Comprehensive ablation studies validate the complementary value of each
modal data and the effectiveness of the system architecture. The proposed
solution demonstrates superior performance in complex microservice fault
scenarios, achieving a final score of 50.71. The code has been released at:
https://github.com/tangpan360/MicroRCA-Agent.

</details>


### [11] [CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair](https://arxiv.org/abs/2509.15690)
*Weixuan Sun,Jucai Zhai,Dengfeng Liu,Xin Zhang,Xiaojun Wu,Qiaobo Hao,AIMgroup,Yang Fang,Jiuyang Tang*

Main category: cs.AI

TL;DR: 提出了CCrepair数据集和基于强化学习的C++编译错误修复框架，通过混合奖励信号和LLM评估系统提升修复质量


<details>
  <summary>Details</summary>
Motivation: 解决C++编译错误自动修复的两个主要挑战：缺乏大规模高质量数据集，以及传统监督方法难以生成语义正确的补丁

Method: 构建CCrepair数据集，采用强化学习范式配合混合奖励信号，使用LLM作为评估器进行两阶段验证

Result: RL训练的Qwen2.5-1.5B模型性能达到与Qwen2.5-14B模型相当的水平，验证了训练范式的效率

Conclusion: 为研究社区提供了新的数据集和更有效的训练评估范式，为实用可靠的自动化编程助手铺平道路

Abstract: The automated repair of C++ compilation errors presents a significant
challenge, the resolution of which is critical for developer productivity.
Progress in this domain is constrained by two primary factors: the scarcity of
large-scale, high-fidelity datasets and the limitations of conventional
supervised methods, which often fail to generate semantically correct
patches.This paper addresses these gaps by introducing a comprehensive
framework with three core contributions. First, we present CCrepair, a novel,
large-scale C++ compilation error dataset constructed through a sophisticated
generate-and-verify pipeline. Second, we propose a Reinforcement Learning (RL)
paradigm guided by a hybrid reward signal, shifting the focus from mere
compilability to the semantic quality of the fix. Finally, we establish the
robust, two-stage evaluation system providing this signal, centered on an
LLM-as-a-Judge whose reliability has been rigorously validated against the
collective judgments of a panel of human experts. This integrated approach
aligns the training objective with generating high-quality, non-trivial patches
that are both syntactically and semantically correct. The effectiveness of our
approach was demonstrated experimentally. Our RL-trained Qwen2.5-1.5B-Instruct
model achieved performance comparable to a Qwen2.5-14B-Instruct model,
validating the efficiency of our training paradigm. Our work provides the
research community with a valuable new dataset and a more effective paradigm
for training and evaluating robust compilation repair models, paving the way
for more practical and reliable automated programming assistants.

</details>


### [12] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: LLM通过MCP协议连接医院EHR数据库，在真实医院环境中自主检索临床信息，在简单任务中表现近乎完美，但复杂任务存在挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域有潜力，但由于无法直接访问电子健康记录系统，在医院部署受限。Model Context Protocol (MCP) 为LLM与外部工具集成提供了解决方案。

Method: 开发EHR-MCP框架，将自定义MCP工具与医院EHR数据库集成，使用GPT-4.1通过LangGraph ReAct代理进行交互。测试6个感染控制团队用例任务，回顾性分析8名患者数据，与医生生成的金标准进行比较。

Result: LLM能正确选择和执行MCP工具，除两个任务外，所有任务准确率接近完美。在需要时间相关计算的复杂任务中表现较差。错误主要来自参数不正确或工具结果误解。响应可靠但存在上下文窗口限制风险。

Conclusion: LLM可通过MCP工具从EHR检索临床数据，在简单任务中表现优异，但复杂任务仍有挑战。EHR-MCP为医院AI代理提供了安全、一致的数据访问基础架构。

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [13] [Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges](https://arxiv.org/abs/2509.15283)
*Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo*

Main category: cs.SE

TL;DR: 本研究评估了开源本地大语言模型在复杂编程竞赛任务中的表现，发现其准确率约为专有模型的一半，但展示了开源模型的快速进步和本地评估流程的实用价值。


<details>
  <summary>Details</summary>
Motivation: 评估当前开源本地大语言模型在处理具有扩展问题描述和上下文的复杂竞争性编程任务中的性能，比较其与专有模型的差距。

Method: 基于FACE框架改造为完全离线运行的评估管道，使用Ollama运行时，将目录结构整合为JSON文件并添加检查点功能，对Kattis语料库的3,589个问题在8个代码导向模型上进行测试。

Result: 本地模型的整体pass@1准确率较低，最佳模型的表现约为专有模型(Gemini 1.5和ChatGPT-4)接受率的一半。

Conclusion: 开源本地模型与最先进专有服务之间存在持续差距，但开源模型进步迅速，且本地评估工作流程具有可在内部硬件上复制的实际优势。

Abstract: This study examines the performance of today's open-source, locally hosted
large-language models (LLMs) in handling complex competitive programming tasks
with extended problem descriptions and contexts. Building on the original
Framework for AI-driven Code Generation Evaluation (FACE), the authors retrofit
the pipeline to work entirely offline through the Ollama runtime, collapsing
FACE's sprawling per-problem directory tree into a handful of consolidated JSON
files, and adding robust checkpointing so multi-day runs can resume after
failures. The enhanced framework generates, submits, and records solutions for
the full Kattis corpus of 3,589 problems across eight code-oriented models
ranging from 6.7-9 billion parameters. The submission results show that the
overall pass@1 accuracy is modest for the local models, with the best models
performing at approximately half the acceptance rate of the proprietary models,
Gemini 1.5 and ChatGPT-4. These findings expose a persistent gap between
private, cost-controlled LLM deployments and state-of-the-art proprietary
services, yet also highlight the rapid progress of open models and the
practical benefits of an evaluation workflow that organizations can replicate
on in-house hardware.

</details>


### [14] [LoCaL: Countering Surface Bias in Code Evaluation Metrics](https://arxiv.org/abs/2509.15397)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 本文提出了LoCaL基准测试，用于评估基于参考的代码评估指标(CEMs)，发现现有CEMs存在表面特征偏见，在功能相似但表面不同或表面相似但功能不同的代码对上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和基于LLM的智能体日益流行，可靠的代码评估指标变得至关重要。现有基于参考的CEMs与功能正确性的相关性较弱，但原因未被深入探究，解决方案也未被探索。

Method: 提出了LoCaL基准测试，包含3117个方法级和程序级代码对，通过差分模糊测试计算功能相似性分数，无需预定义测试用例且执行更多测试。评估了四种最先进的参考型CEMs。

Result: 发现所有四种CEMs在LoCaL基准上的性能相比基线都有显著下降，显示出对表面特征的强烈偏见而非代码功能。

Conclusion: 将CEMs暴露于LoCaL类似数据可能有助于开发对表面偏见具有鲁棒性的评估指标。

Abstract: With the increasing popularity of large language models (LLMs) and LLM-based
agents, reliable and effective code evaluation metrics (CEMs) have become
crucial for progress across several software engineering tasks. While popular
benchmarks often provide test cases to assess the correctness of generated
code, crafting and executing test cases is expensive. Reference-based CEMs
provide a cheaper alternative by scoring a candidate program based on its
functional similarity to a reference. Although prior research has focused on
reporting the weak correlation between these CEMs and functional correctness,
the causes are only assumed, and plausible solutions remain unexplored. In this
work, we critically evaluate four state-of-the-art reference-based CEMs,
revealing their strong bias towards surface-level features rather than code
functionality. Despite this surface bias, current evaluation datasets for these
CEMs rarely include code pairs that are surface-similar yet functionally
dissimilar, or functionally similar yet surface-dissimilar. To mitigate this
gap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117
code pairs at both the method and program levels. Each pair is labeled with a
functional similarity score and aims to target regions where CEMs are likely to
perform poorly. The functional similarity scores are calculated through
differential fuzzing, which eliminates the need for predefined test cases and,
at the same time, improves the reliability of the scores by executing an order
of magnitude more tests than prior work. We find that all four CEMs show
significant performance degradation on LoCaL, compared to the baselines.
Finally, based on our findings, we draw the implication that exposing CEMs to
LoCaL-like data might facilitate the development of metrics that are robust to
surface bias.

</details>


### [15] [Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation](https://arxiv.org/abs/2509.15567)
*Hongyu Kuang,Ning Zhang,Hui Gao,Xin Zhou,Wesley K. G. Assunção,Xiaoxing Ma,Dong Shao,Guoping Rong,He Zhang*

Main category: cs.SE

TL;DR: 该研究提出了一种通过文本模板来压缩代码变更信息的方法，使用ChangeScribe工具生成包含代码变更摘要、注释提取和重要标识符的模板，然后基于CodeLlama-7B模型自动生成高质量的提交消息。


<details>
  <summary>Details</summary>
Motivation: 开发者在实践中经常忽视编写高质量的提交消息，而现有的自动生成方法需要更好地组织和表示代码变更信息。

Method: 首先使用启发式工具ChangeScribe生成包含三部分内容的文本模板（代码变更摘要、提取的注释、强调的代码标识符），然后基于这些模板对CodeLlama-7B模型进行微调来生成提交消息。

Result: 在广泛使用的数据集上评估显示，该方法在BLEU-Norm、METEOR和ROUGE-L指标上优于六个基线方法，平均提升分别为51.7%、78.7%和62.5%。消融研究和人工评估也证明了方法的有效性。

Conclusion: 提出的文本模板方法能够更好地利用预训练语言模型，生成简洁可读的提交消息，有效辅助开发者理解代码变更。

Abstract: Commit messages are valuable resources for describing why code changes are
committed to repositories in version control systems (e.g., Git). They
effectively help developers understand code changes and better perform software
maintenance tasks. Unfortunately, developers often neglect to write
high-quality commit messages in practice. Therefore, a growing body of work is
proposed to generate commit messages automatically. These works all
demonstrated that how to organize and represent code changes is vital in
generating good commit messages, including the use of fine-grained graphs or
embeddings to better represent code changes. In this study, we choose an
alternative way to condense code changes before generation, i.e., proposing
brief yet concise text templates consisting of the following three parts: (1)
summarized code changes, (2) elicited comments, and (3) emphasized code
identifiers. Specifically, we first condense code changes by using our proposed
templates with the help of a heuristic-based tool named ChangeScribe, and then
fine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding
commit messages. Our proposed templates better utilize pre-trained language
models, while being naturally brief and readable to complement generated commit
messages for developers. Our evaluation based on a widely used dataset showed
that our approach can outperform six baselines in terms of BLEU-Norm, METEOR,
and ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,
respectively. The ablation study and human evaluation also provide further
insights into the effectiveness of our approach.

</details>


### [16] [LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine Learning Pipelines](https://arxiv.org/abs/2509.15971)
*Owen Truong,Terrence Zhang,Arnav Marchareddy,Ryan Lee,Jeffery Busold,Michael Socas,Eman Abdullah AlOmar*

Main category: cs.SE

TL;DR: 开发了一个名为LeakageDetector的VS Code扩展，用于检测和修复Jupyter Notebook中的数据泄露问题，包括重叠泄露、预处理泄露和多测试泄露，并提供传统修复和LLM驱动的修复方法。


<details>
  <summary>Details</summary>
Motivation: 帮助机器学习工程师识别和纠正数据泄露问题，避免测试数据信息意外包含在训练数据中导致性能评估误导。

Method: 开发VS Code扩展LeakageDetector，检测三种主要数据泄露类型，并提供两种修复机制：传统快速修复和LLM驱动的指导方法。

Result: 创建了一个能够有效检测数据泄露问题的工具，并为开发者提供了修复指导。

Conclusion: LeakageDetector扩展能够帮助ML开发者更好地管理数据分割，避免数据泄露问题，提高代码质量。

Abstract: In software development environments, code quality is crucial. This study
aims to assist Machine Learning (ML) engineers in enhancing their code by
identifying and correcting Data Leakage issues within their models. Data
Leakage occurs when information from the test dataset is inadvertently included
in the training data when preparing a data science model, resulting in
misleading performance evaluations. ML developers must carefully separate their
data into training, evaluation, and test sets to avoid introducing Data Leakage
into their code. In this paper, we develop a new Visual Studio Code (VS Code)
extension, called LeakageDetector, that detects Data Leakage, mainly Overlap,
Preprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond
detection, we included two correction mechanisms: a conventional approach,
known as a quick fix, which manually fixes the leakage, and an LLM-driven
approach that guides ML developers toward best practices for building ML
pipelines.

</details>


### [17] [MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair](https://arxiv.org/abs/2509.16187)
*Ali Reza Ibrahimzada,Brandon Paulsen,Reyhaneh Jabbarvand,Joey Dodds,Daniel Kroening*

Main category: cs.SE

TL;DR: MatchFixAgent是一个基于LLM的多智能体框架，用于代码翻译的等价性验证和修复，支持多种编程语言，在2199个翻译对中实现了99.2%的验证覆盖率和50.6%的修复成功率。


<details>
  <summary>Details</summary>
Motivation: 现有代码翻译验证方法存在工程开销大、依赖不充分测试套件的问题，导致等价性误判和修复效果差，需要开发更通用和准确的验证修复框架。

Method: 采用多智能体架构，将等价性验证分解为多个子任务（语义分析、测试生成执行、修复、最终裁决），利用LLM进行编程语言无关的分析和修复。

Result: 在6种编程语言对的2199个翻译对上，实现了99.2%的验证覆盖率，72.8%与先前工作一致，60.7%不一致时MatchFixAgent正确；修复成功率50.6% vs 先前工作的18.5%。

Conclusion: MatchFixAgent相比现有方法具有更好的编程语言适应性和验证准确性，能有效解决代码翻译的等价性验证和修复问题。

Abstract: Code translation transforms source code from one programming language (PL) to
another. Validating the functional equivalence of translation and repairing, if
necessary, are critical steps in code translation. Existing automated
validation and repair approaches struggle to generalize to many PLs due to high
engineering overhead, and they rely on existing and often inadequate test
suites, which results in false claims of equivalence and ineffective
translation repair. We develop MatchFixAgent, a large language model
(LLM)-based, PL-agnostic framework for equivalence validation and repair of
translations. MatchFixAgent features a multi-agent architecture that divides
equivalence validation into several sub-tasks to ensure thorough and consistent
semantic analysis of the translation. Then it feeds this analysis to test agent
to write and execute tests. Upon observing a test failure, the repair agent
attempts to fix the translation bug. The final (in)equivalence decision is made
by the verdict agent, considering semantic analyses and test execution results.
  We compare MatchFixAgent's validation and repair results with four
repository-level code translation techniques. We use 2,219 translation pairs
from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub
projects totaling over 900K lines of code. Our results demonstrate that
MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,
with the same equivalence validation result as prior work on 72.8% of them.
When MatchFixAgent's result disagrees with prior work, we find that 60.7% of
the time MatchFixAgent's result is actually correct. In addition, we show that
MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior
work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to
many PL pairs than prior work, while producing highly accurate validation
results.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [18] [Modeling Transformers as complex networks to analyze learning dynamics](https://arxiv.org/abs/2509.15269)
*Elisabetta Rocchetti*

Main category: cs.LG

TL;DR: 该研究通过复杂网络理论分析LLM训练动态，将Transformer模型表示为有向加权图，追踪训练过程中网络结构的演化，发现探索、巩固和精炼三个阶段，识别出信息传播器和收集器的层级结构。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型在训练过程中如何获得复杂能力是机制可解释性的关键问题，研究旨在通过复杂网络理论的视角来表征这些学习动态。

Method: 提出新方法将基于Transformer的LLM表示为有向加权图（节点为注意力头和MLP，边表示因果影响），在Pythia-14M模型的143个训练检查点上追踪图论指标演化。

Result: 发现网络结构经历探索、巩固和精炼三个明显阶段，识别出稳定的信息传播器层级结构和动态的信息收集器组件，这些角色在关键学习节点重新配置。

Conclusion: 组件级网络视角为可视化和理解LLM中功能电路形成的自组织原则提供了强大的宏观视角。

Abstract: The process by which Large Language Models (LLMs) acquire complex
capabilities during training remains a key open question in mechanistic
interpretability. This project investigates whether these learning dynamics can
be characterized through the lens of Complex Network Theory (CNT). I introduce
a novel methodology to represent a Transformer-based LLM as a directed,
weighted graph where nodes are the model's computational components (attention
heads and MLPs) and edges represent causal influence, measured via an
intervention-based ablation technique. By tracking the evolution of this
component-graph across 143 training checkpoints of the Pythia-14M model on a
canonical induction task, I analyze a suite of graph-theoretic metrics. The
results reveal that the network's structure evolves through distinct phases of
exploration, consolidation, and refinement. Specifically, I identify the
emergence of a stable hierarchy of information spreader components and a
dynamic set of information gatherer components, whose roles reconfigure at key
learning junctures. This work demonstrates that a component-level network
perspective offers a powerful macroscopic lens for visualizing and
understanding the self-organizing principles that drive the formation of
functional circuits in LLMs.

</details>


### [19] [Predicting Language Models' Success at Zero-Shot Probabilistic Prediction](https://arxiv.org/abs/2509.15356)
*Kevin Ren,Santiago Cortes-Gomez,Carlos Miguel Patiño,Ananya Joshi,Ruiqi Lyu,Jingjing Tang,Alistair Turcan,Khurram Yamin,Steven Wu,Bryan Wilder*

Main category: cs.LG

TL;DR: LLM在零样本表格预测任务中表现不稳定，但预测概率可作为个体准确度的信号。研究构建了无需标注数据的指标来预测LLM在新任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为零样本模型生成个体特征时的可靠性问题，探讨用户何时可以相信LLM能为其特定任务提供高质量预测。

Method: 进行大规模实证研究，评估LLM在各种表格预测任务中的零样本预测能力，并构建无需标注数据的指标来预测LLM性能。

Result: 发现LLM性能在不同任务间差异很大，但当LLM在基础预测任务表现良好时，其预测概率成为个体准确度的更强信号。某些无标注数据评估指标能有效预测LLM在新任务上的表现。

Conclusion: LLM在零样本表格预测中的表现具有可变性，但可以通过构建合适的指标来预测其在特定任务上的适用性，为实际应用提供指导。

Abstract: Recent work has investigated the capabilities of large language models (LLMs)
as zero-shot models for generating individual-level characteristics (e.g., to
serve as risk models or augment survey datasets). However, when should a user
have confidence that an LLM will provide high-quality predictions for their
particular task? To address this question, we conduct a large-scale empirical
study of LLMs' zero-shot predictive capabilities across a wide range of tabular
prediction tasks. We find that LLMs' performance is highly variable, both on
tasks within the same dataset and across different datasets. However, when the
LLM performs well on the base prediction task, its predicted probabilities
become a stronger signal for individual-level accuracy. Then, we construct
metrics to predict LLMs' performance at the task level, aiming to distinguish
between tasks where LLMs may perform well and where they are likely unsuitable.
We find that some of these metrics, each of which are assessed without labeled
data, yield strong signals of LLMs' predictive performance on new tasks.

</details>


### [20] [Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers](https://arxiv.org/abs/2509.15498)
*Zahra Aref,Narayan B. Mandayam*

Main category: cs.LG

TL;DR: 提出了EWA-VQ-ODT方法，通过向量量化的经验加权吸引力机制增强在线决策变换器，提高样本效率和长期动作效果学习能力


<details>
  <summary>Details</summary>
Motivation: 传统在线决策变换器使用标准注意力机制，缺乏对动作特定结果的显式记忆，导致学习长期动作有效性效率低下

Method: 引入轻量级模块维护每个动作的心理账户，通过向量量化码本存储标量吸引力值，在线更新并通过衰减和奖励强化机制调整注意力偏置

Result: 在标准连续控制基准测试中，EWA-VQ-ODT相比ODT提高了样本效率和平均回报，特别是在早期训练阶段表现更优

Conclusion: 该方法计算效率高、可解释性强，具有理论保证，为强化学习中的序列决策提供了有效的记忆增强机制

Abstract: Transformers have emerged as a compelling architecture for sequential
decision-making by modeling trajectories via self-attention. In reinforcement
learning (RL), they enable return-conditioned control without relying on value
function approximation. Decision Transformers (DTs) exploit this by casting RL
as supervised sequence modeling, but they are restricted to offline data and
lack exploration. Online Decision Transformers (ODTs) address this limitation
through entropy-regularized training on on-policy rollouts, offering a stable
alternative to traditional RL methods like Soft Actor-Critic, which depend on
bootstrapped targets and reward shaping. Despite these advantages, ODTs use
standard attention, which lacks explicit memory of action-specific outcomes.
This leads to inefficiencies in learning long-term action effectiveness.
Inspired by cognitive models such as Experience-Weighted Attraction (EWA), we
propose Experience-Weighted Attraction with Vector Quantization for Online
Decision Transformers (EWA-VQ-ODT), a lightweight module that maintains
per-action mental accounts summarizing recent successes and failures.
Continuous actions are routed via direct grid lookup to a compact
vector-quantized codebook, where each code stores a scalar attraction updated
online through decay and reward-based reinforcement. These attractions modulate
attention by biasing the columns associated with action tokens, requiring no
change to the backbone or training objective. On standard continuous-control
benchmarks, EWA-VQ-ODT improves sample efficiency and average return over ODT,
particularly in early training. The module is computationally efficient,
interpretable via per-code traces, and supported by theoretical guarantees that
bound the attraction dynamics and its impact on attention drift.

</details>


### [21] [Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem](https://arxiv.org/abs/2509.15519)
*Chao Li,Bingkun Bao,Yang Gao*

Main category: cs.LG

TL;DR: 提出DAC方法解决完全去中心化多智能体强化学习中的非平稳性和相对过度泛化问题，通过动态感知上下文建模将任务形式化为上下文马尔可夫决策过程


<details>
  <summary>Details</summary>
Motivation: 完全去中心化合作多智能体强化学习中，智能体无法观测其他智能体动作导致价值函数更新的非平稳性和价值函数估计的相对过度泛化问题，现有方法无法同时解决这两个问题

Method: DAC方法将每个智能体感知的局部任务动态归因于未观测上下文之间的切换，使用潜在变量建模逐步动态分布作为上下文，引入基于上下文的价值函数解决非平稳性，推导乐观边际价值促进合作动作选择

Result: 在矩阵游戏、捕食者-猎物和SMAC等多种合作任务上评估，DAC相比多个基线方法表现出优越性能

Conclusion: DAC方法通过动态感知上下文建模有效解决了完全去中心化多智能体强化学习中的非平稳性和相对过度泛化问题

Abstract: This paper studies fully decentralized cooperative multi-agent reinforcement
learning, where each agent solely observes the states, its local actions, and
the shared rewards. The inability to access other agents' actions often leads
to non-stationarity during value function updates and relative
overgeneralization during value function estimation, hindering effective
cooperative policy learning. However, existing works fail to address both
issues simultaneously, due to their inability to model the joint policy of
other agents in a fully decentralized setting. To overcome this limitation, we
propose a novel method named Dynamics-Aware Context (DAC), which formalizes the
task, as locally perceived by each agent, as an Contextual Markov Decision
Process, and further addresses both non-stationarity and relative
overgeneralization through dynamics-aware context modeling. Specifically, DAC
attributes the non-stationary local task dynamics of each agent to switches
between unobserved contexts, each corresponding to a distinct joint policy.
Then, DAC models the step-wise dynamics distribution using latent variables and
refers to them as contexts. For each agent, DAC introduces a context-based
value function to address the non-stationarity issue during value function
update. For value function estimation, an optimistic marginal value is derived
to promote the selection of cooperative actions, thereby addressing the
relative overgeneralization issue. Experimentally, we evaluate DAC on various
cooperative tasks (including matrix game, predator and prey, and SMAC), and its
superior performance against multiple baselines validates its effectiveness.

</details>


### [22] [KITE: Kernelized and Information Theoretic Exemplars for In-Context Learning](https://arxiv.org/abs/2509.15676)
*Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 本文从信息论角度研究ICL中的示例选择问题，提出基于查询特定优化的方法，通过近似子模优化和核技巧提升性能，在分类任务中显著优于标准检索方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在上下文学习中示例选择的关键问题，传统最近邻方法在高维嵌入空间中存在泛化能力差和多样性不足的缺陷，需要更理论化的解决方案。

Method: 将LLM建模为输入嵌入的线性函数，将示例选择构建为查询特定的优化问题，推导近似子模的代理目标函数，使用贪婪算法，并引入核技巧和基于最优设计的正则化器来增强多样性。

Result: 在多个分类任务上，该方法相比标准检索方法取得了显著改进，证明了结构感知和多样化示例选择在实际标签稀缺场景中的优势。

Conclusion: 基于信息论原理的查询特定优化方法能够有效提升ICL性能，核技巧和多样性正则化的结合为解决高维空间中的示例选择问题提供了有效途径。

Abstract: In-context learning (ICL) has emerged as a powerful paradigm for adapting
large language models (LLMs) to new and data-scarce tasks using only a few
carefully selected task-specific examples presented in the prompt. However,
given the limited context size of LLMs, a fundamental question arises: Which
examples should be selected to maximize performance on a given user query?
While nearest-neighbor-based methods like KATE have been widely adopted for
this purpose, they suffer from well-known drawbacks in high-dimensional
embedding spaces, including poor generalization and a lack of diversity. In
this work, we study this problem of example selection in ICL from a principled,
information theory-driven perspective. We first model an LLM as a linear
function over input embeddings and frame the example selection task as a
query-specific optimization problem: selecting a subset of exemplars from a
larger example bank that minimizes the prediction error on a specific query.
This formulation departs from traditional generalization-focused learning
theoretic approaches by targeting accurate prediction for a specific query
instance. We derive a principled surrogate objective that is approximately
submodular, enabling the use of a greedy algorithm with an approximation
guarantee. We further enhance our method by (i) incorporating the kernel trick
to operate in high-dimensional feature spaces without explicit mappings, and
(ii) introducing an optimal design-based regularizer to encourage diversity in
the selected examples. Empirically, we demonstrate significant improvements
over standard retrieval methods across a suite of classification tasks,
highlighting the benefits of structure-aware, diverse example selection for ICL
in real-world, label-scarce scenarios.

</details>


### [23] [Nonconvex Regularization for Feature Selection in Reinforcement Learning](https://arxiv.org/abs/2509.15652)
*Kyohei Suzuki,Konstantinos Slavakis*

Main category: cs.LG

TL;DR: 提出一种具有理论收敛保证的强化学习特征选择批量算法，通过PMC惩罚正则化Bellman残差目标来缓解估计偏差，并使用FRBS算法求解，在含噪声特征场景中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统正则化方案存在估计偏差问题，需要在强化学习中开发更有效的特征选择方法来处理高维噪声特征场景

Method: 扩展LSTD框架中的策略评估，使用非凸PMC惩罚正则化Bellman残差目标，将其转化为非单调包含问题，并应用FRBS算法求解

Result: 在基准数据集上的数值实验表明，该方法在含大量噪声特征的情况下显著优于最先进的特征选择方法

Conclusion: 所提出的PMC正则化方法和FRBS算法为强化学习中的特征选择提供了有效的解决方案，具有理论保证和实际性能优势

Abstract: This work proposes an efficient batch algorithm for feature selection in
reinforcement learning (RL) with theoretical convergence guarantees. To
mitigate the estimation bias inherent in conventional regularization schemes,
the first contribution extends policy evaluation within the classical
least-squares temporal-difference (LSTD) framework by formulating a
Bellman-residual objective regularized with the sparsity-inducing, nonconvex
projected minimax concave (PMC) penalty. Owing to the weak convexity of the PMC
penalty, this formulation can be interpreted as a special instance of a general
nonmonotone-inclusion problem. The second contribution establishes novel
convergence conditions for the forward-reflected-backward splitting (FRBS)
algorithm to solve this class of problems. Numerical experiments on benchmark
datasets demonstrate that the proposed approach substantially outperforms
state-of-the-art feature-selection methods, particularly in scenarios with many
noisy features.

</details>


### [24] [Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search](https://arxiv.org/abs/2509.15927)
*Zhiyu Mou,Yiqin Lv,Miao Xu,Cheems Wang,Yixiu Mao,Qichen Ye,Chao Li,Rongquan Bai,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: AIGB-Pearl是一种结合生成式规划和策略优化的自动竞价方法，通过构建轨迹评估器来指导策略搜索，解决了现有AIGB方法在细粒度生成质量评估和离线数据探索方面的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成竞价(AIGB)方法虽然优于传统离线强化学习方法，但仍存在性能瓶颈，主要原因是忽视了细粒度生成质量评估，且无法超越静态数据集进行探索。

Method: 提出AIGB-Pearl方法，整合生成式规划和策略优化：1）构建非自举的轨迹评估器来分配奖励和指导策略搜索；2）采用LLM架构增强表示能力；3）使用混合点对和配对损失进行更好的分数学习；4）自适应整合专家反馈提升泛化能力。

Result: 在模拟和真实广告系统上的大量实验表明，该方法达到了最先进的性能水平。

Conclusion: AIGB-Pearl通过引入轨迹评估器和多种技术改进，有效提升了自动竞价的生成质量和性能表现。

Abstract: Auto-bidding is an essential tool for advertisers to enhance their
advertising performance. Recent progress has shown that AI-Generated Bidding
(AIGB), which formulates the auto-bidding as a trajectory generation task and
trains a conditional diffusion-based planner on offline data, achieves superior
and stable performance compared to typical offline reinforcement learning
(RL)-based auto-bidding methods. However, existing AIGB methods still encounter
a performance bottleneck due to their neglect of fine-grained generation
quality evaluation and inability to explore beyond static datasets. To address
this, we propose AIGB-Pearl (\emph{Planning with EvAluator via RL}), a novel
method that integrates generative planning and policy optimization. The key to
AIGB-Pearl is to construct a non-bootstrapped \emph{trajectory evaluator} to
assign rewards and guide policy search, enabling the planner to optimize its
generation quality iteratively through interaction. Furthermore, to enhance
trajectory evaluator accuracy in offline settings, we incorporate three key
techniques: (i) a Large Language Model (LLM)-based architecture for better
representational capacity, (ii) hybrid point-wise and pair-wise losses for
better score learning, and (iii) adaptive integration of expert feedback for
better generalization ability. Extensive experiments on both simulated and
real-world advertising systems demonstrate the state-of-the-art performance of
our approach.

</details>


### [25] [RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation](https://arxiv.org/abs/2509.15965)
*Chao Yu,Yuanqing Wang,Zhen Guo,Hao Lin,Si Xu,Hongzhi Zang,Quanlu Zhang,Yongji Wu,Chunyang Zhu,Junhao Hu,Zixiao Huang,Mingjie Wei,Yuqing Xie,Ke Yang,Bo Dai,Zhexuan Xu,Xiangyuan Wang,Xu Fu,Zhihao Liu,Kang Chen,Weilin Liu,Gang Liu,Boxun Li,Jianlei Yang,Zhi Yang,Guohao Dai,Yu Wang*

Main category: cs.LG

TL;DR: RLinf是一个基于宏-微流转换(M2Flow)范式的高性能强化学习训练系统，通过自动分解和重组RL工作流，实现了1.1x-2.13x的训练加速。


<details>
  <summary>Details</summary>
Motivation: 强化学习工作流的异构性和动态性导致现有系统的硬件利用率低、训练速度慢，主要瓶颈在于系统灵活性不足。

Method: 提出M2Flow设计范式，在时间和空间维度自动分解RL工作流并重组为优化执行流；采用自适应通信、上下文切换、弹性流水线和基于性能分析的调度策略。

Result: 在推理RL和具身RL任务上，RLinf持续优于最先进系统，端到端训练吞吐量提升1.1-2.13倍。

Conclusion: RLinf通过提高系统灵活性有效解决了RL训练效率问题，M2Flow范式为高性能RL系统设计提供了新思路。

Abstract: Reinforcement learning (RL) has demonstrated immense potential in advancing
artificial general intelligence, agentic intelligence, and embodied
intelligence. However, the inherent heterogeneity and dynamicity of RL
workflows often lead to low hardware utilization and slow training on existing
systems. In this paper, we present RLinf, a high-performance RL training system
based on our key observation that the major roadblock to efficient RL training
lies in system flexibility. To maximize flexibility and efficiency, RLinf is
built atop a novel RL system design paradigm called macro-to-micro flow
transformation (M2Flow), which automatically breaks down high-level,
easy-to-compose RL workflows at both the temporal and spatial dimensions, and
recomposes them into optimized execution flows. Supported by RLinf worker's
adaptive communication capability, we devise context switching and elastic
pipelining to realize M2Flow transformation, and a profiling-guided scheduling
policy to generate optimal execution plans. Extensive evaluations on both
reasoning RL and embodied RL tasks demonstrate that RLinf consistently
outperforms state-of-the-art systems, achieving 1.1x-2.13x speedup in
end-to-end training throughput.

</details>


### [26] [GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning](https://arxiv.org/abs/2509.15738)
*Musen Lin,Minghao Liu,Taoran Lu,Lichen Yuan,Yiwei Liu,Haonan Xu,Yu Miao,Yuhao Chao,Zhaojian Li*

Main category: cs.LG

TL;DR: GUI-ReWalk是一个用于合成GUI轨迹数据的多阶段框架，通过随机探索和推理引导相结合的方式生成多样且真实的人机交互数据，显著提升了GUI代理的性能。


<details>
  <summary>Details</summary>
Motivation: GUI代理的发展受限于高质量轨迹数据的稀缺性，现有数据收集方法要么成本高昂且不一致，要么在多样性和任务覆盖度之间难以平衡。

Method: 提出GUI-ReWalk框架：1）随机探索阶段模拟人类试错行为；2）推理引导阶段基于推断目标进行连贯交互；3）支持多步长任务生成，构建跨应用的长时程工作流。

Result: 在多个基准测试（Screenspot-Pro、OSWorld-G等）上评估显示，GUI-ReWalk能够实现更好的交互流覆盖、更高的轨迹熵和更真实的用户意图。

Conclusion: GUI-ReWalk为GUI代理研究提供了一个可扩展且数据高效的框架，能够推动稳健的实时自动化应用。

Abstract: Graphical User Interface (GUI) Agents, powered by large language and
vision-language models, hold promise for enabling end-to-end automation in
digital environments. However, their progress is fundamentally constrained by
the scarcity of scalable, high-quality trajectory data. Existing data
collection strategies either rely on costly and inconsistent manual annotations
or on synthetic generation methods that trade off between diversity and
meaningful task coverage. To bridge this gap, we present GUI-ReWalk: a
reasoning-enhanced, multi-stage framework for synthesizing realistic and
diverse GUI trajectories. GUI-ReWalk begins with a stochastic exploration phase
that emulates human trial-and-error behaviors, and progressively transitions
into a reasoning-guided phase where inferred goals drive coherent and
purposeful interactions. Moreover, it supports multi-stride task generation,
enabling the construction of long-horizon workflows across multiple
applications. By combining randomness for diversity with goal-aware reasoning
for structure, GUI-ReWalk produces data that better reflects the intent-aware,
adaptive nature of human-computer interaction. We further train Qwen2.5-VL-7B
on the GUI-ReWalk dataset and evaluate it across multiple benchmarks, including
Screenspot-Pro, OSWorld-G, UI-Vision, AndroidControl, and GUI-Odyssey. Results
demonstrate that GUI-ReWalk enables superior coverage of diverse interaction
flows, higher trajectory entropy, and more realistic user intent. These
findings establish GUI-ReWalk as a scalable and data-efficient framework for
advancing GUI agent research and enabling robust real-world automation.

</details>


### [27] [Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations](https://arxiv.org/abs/2509.15981)
*Yujie Zhu,Charles A. Hepburn,Matthew Thorpe,Giovanni Montana*

Main category: cs.LG

TL;DR: SPReD是一个强化学习框架，通过集成方法建模Q值分布来量化不确定性，使用概率和优势两种方法决定何时模仿演示，相比二元决策方法实现了连续不确定性比例正则化，在8个机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在稀疏奖励的强化学习中，演示可以加速学习，但确定何时模仿演示仍然具有挑战性。现有方法（如Q-filter）做出二元模仿决策，可能导致训练过程中的梯度方差问题。

Method: 使用集成方法显式建模演示和策略动作的Q值分布来量化不确定性。开发了两种互补方法：概率方法估计演示优越性的可能性，优势方法通过统计显著性缩放模仿。应用连续的不确定性比例正则化权重。

Result: 在8个机器人任务实验中取得了显著提升，在复杂任务中比现有方法性能提升高达14倍，同时对演示质量和数量保持鲁棒性。

Conclusion: SPReD通过不确定性感知的连续正则化方法有效解决了何时模仿演示的问题，计算简单但效果显著，为稀疏奖励强化学习提供了有效的演示利用框架。

Abstract: In reinforcement learning with sparse rewards, demonstrations can accelerate
learning, but determining when to imitate them remains challenging. We propose
Smooth Policy Regularisation from Demonstrations (SPReD), a framework that
addresses the fundamental question: when should an agent imitate a
demonstration versus follow its own policy? SPReD uses ensemble methods to
explicitly model Q-value distributions for both demonstration and policy
actions, quantifying uncertainty for comparisons. We develop two complementary
uncertainty-aware methods: a probabilistic approach estimating the likelihood
of demonstration superiority, and an advantage-based approach scaling imitation
by statistical significance. Unlike prevailing methods (e.g. Q-filter) that
make binary imitation decisions, SPReD applies continuous,
uncertainty-proportional regularisation weights, reducing gradient variance
during training. Despite its computational simplicity, SPReD achieves
remarkable gains in experiments across eight robotics tasks, outperforming
existing approaches by up to a factor of 14 in complex tasks while maintaining
robustness to demonstration quality and quantity. Our code is available at
https://github.com/YujieZhu7/SPReD.

</details>


### [28] [DiffusionNFT: Online Diffusion Reinforcement with Forward Process](https://arxiv.org/abs/2509.16117)
*Kaiwen Zheng,Huayu Chen,Haotian Ye,Haoxiang Wang,Qinsheng Zhang,Kai Jiang,Hang Su,Stefano Ermon,Jun Zhu,Ming-Yu Liu*

Main category: cs.LG

TL;DR: DiffusionNFT是一种新的在线强化学习范式，通过流匹配直接在正向过程中优化扩散模型，避免了传统方法的限制，效率提升25倍且无需分类器引导。


<details>
  <summary>Details</summary>
Motivation: 现有的在线强化学习在扩散模型中的应用面临似然不可处理、求解器限制、正反向不一致以及与分类器引导复杂集成等问题。

Method: 提出DiffusionNFT方法，通过流匹配在正向过程中直接优化扩散模型，对比正负生成来定义隐式策略改进方向，将强化信号自然融入监督学习目标。

Result: DiffusionNFT比FlowGRPO效率提升25倍，在1k步内将GenEval分数从0.24提升到0.98，无需分类器引导。使用多个奖励模型显著提升了SD3.5-Medium在所有基准测试中的性能。

Conclusion: DiffusionNFT为扩散模型提供了一种高效、灵活的在线强化学习范式，解决了现有方法的根本缺陷，具有广泛的应用前景。

Abstract: Online reinforcement learning (RL) has been central to post-training language
models, but its extension to diffusion models remains challenging due to
intractable likelihoods. Recent works discretize the reverse sampling process
to enable GRPO-style training, yet they inherit fundamental drawbacks,
including solver restrictions, forward-reverse inconsistency, and complicated
integration with classifier-free guidance (CFG). We introduce Diffusion
Negative-aware FineTuning (DiffusionNFT), a new online RL paradigm that
optimizes diffusion models directly on the forward process via flow matching.
DiffusionNFT contrasts positive and negative generations to define an implicit
policy improvement direction, naturally incorporating reinforcement signals
into the supervised learning objective. This formulation enables training with
arbitrary black-box solvers, eliminates the need for likelihood estimation, and
requires only clean images rather than sampling trajectories for policy
optimization. DiffusionNFT is up to $25\times$ more efficient than FlowGRPO in
head-to-head comparisons, while being CFG-free. For instance, DiffusionNFT
improves the GenEval score from 0.24 to 0.98 within 1k steps, while FlowGRPO
achieves 0.95 with over 5k steps and additional CFG employment. By leveraging
multiple reward models, DiffusionNFT significantly boosts the performance of
SD3.5-Medium in every benchmark tested.

</details>


### [29] [SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection](https://arxiv.org/abs/2509.16060)
*Maithili Joshi,Palash Nandi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: 论文提出SABER方法，通过在白盒设置下连接LLM中间层的残差连接来绕过安全对齐机制，在HarmBench测试集上比最佳基线提升51%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管经过安全对齐训练，大语言模型仍然容易受到越狱攻击，研究发现安全机制主要嵌入在模型中后层，这为白盒攻击提供了机会。

Method: 提出SABER方法，通过连接两个中间层s和e（s<e）的残差连接来绕过安全对齐机制，这是一种白盒越狱方法。

Result: 在HarmBench测试集上实现了51%的性能提升，在验证集上仅引起边际困惑度变化，表明攻击有效且对正常性能影响小。

Conclusion: SABER方法有效揭示了LLM安全机制的脆弱性，为模型安全性研究提供了新的视角和方法。

Abstract: Large Language Models (LLMs) with safe-alignment training are powerful
instruments with robust language comprehension capabilities. These models
typically undergo meticulous alignment procedures involving human feedback to
ensure the acceptance of safe inputs while rejecting harmful or unsafe ones.
However, despite their massive scale and alignment efforts, LLMs remain
vulnerable to jailbreak attacks, where malicious users manipulate the model to
produce harmful outputs that it was explicitly trained to avoid. In this study,
we find that the safety mechanisms in LLMs are predominantly embedded in the
middle-to-late layers. Building on this insight, we introduce a novel white-box
jailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which
connects two intermediate layers $s$ and $e$ such that $s < e$, through a
residual connection. Our approach achieves a 51% improvement over the
best-performing baseline on the HarmBench test set. Furthermore, SABER induces
only a marginal shift in perplexity when evaluated on the HarmBench validation
set. The source code is publicly available at
https://github.com/PalGitts/SABER.

</details>


### [30] [HyP-ASO: A Hybrid Policy-based Adaptive Search Optimization Framework for Large-Scale Integer Linear Programs](https://arxiv.org/abs/2509.15828)
*Ning Xu,Junkai Zhang,Yang Wu,Huigen Ye,Hua Xu,Huiling Xu,Yifan Zhang*

Main category: cs.LG

TL;DR: HyP-ASO是一个混合策略的自适应搜索优化框架，结合定制公式和深度强化学习来加速大规模整数线性规划问题的求解。


<details>
  <summary>Details</summary>
Motivation: 传统求解器处理大规模整数线性规划问题速度慢，现有基于大邻域搜索的框架在生成有效邻域方面存在困难。

Method: 采用混合策略：定制公式利用可行解计算变量选择概率，强化学习策略网络预测邻域大小。

Result: 实验表明HyP-ASO显著优于现有LNS方法，具有轻量级和高可扩展性特点。

Conclusion: 该框架适合解决大规模整数线性规划问题，在性能和效率方面都有显著提升。

Abstract: Directly solving large-scale Integer Linear Programs (ILPs) using traditional
solvers is slow due to their NP-hard nature. While recent frameworks based on
Large Neighborhood Search (LNS) can accelerate the solving process, their
performance is often constrained by the difficulty in generating sufficiently
effective neighborhoods. To address this challenge, we propose HyP-ASO, a
hybrid policy-based adaptive search optimization framework that combines a
customized formula with deep Reinforcement Learning (RL). The formula leverages
feasible solutions to calculate the selection probabilities for each variable
in the neighborhood generation process, and the RL policy network predicts the
neighborhood size. Extensive experiments demonstrate that HyP-ASO significantly
outperforms existing LNS-based approaches for large-scale ILPs. Additional
experiments show it is lightweight and highly scalable, making it well-suited
for solving large-scale ILPs.

</details>


### [31] [Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents](https://arxiv.org/abs/2509.16151)
*Isaiah J. King,Benjamin Bowman,H. Howie Huang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于图表示的深度强化学习方法，用于自动化网络防御，通过关系归纳偏置使智能体能够零样本适应新网络拓扑。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在网络防御中过度拟合特定网络拓扑，面对环境扰动时效果不佳。需要一种能够泛化到新网络结构的方法。

Method: 将网络防御建模为基于上下文的部分可观察马尔可夫决策问题，使用属性图表示观测，让智能体通过关系归纳偏置进行推理，将动作理解为对图的编辑。

Result: 该方法大幅超越现有最先进技术，使智能体能够在各种复杂多智能体环境中防御从未见过的网络，对抗多种攻击者。

Conclusion: 基于图表示和关系归纳偏置的方法显著提高了网络防御RL智能体的泛化能力和适应性。

Abstract: Deep reinforcement learning (RL) is emerging as a viable strategy for
automated cyber defense (ACD). The traditional RL approach represents networks
as a list of computers in various states of safety or threat. Unfortunately,
these models are forced to overfit to specific network topologies, rendering
them ineffective when faced with even small environmental perturbations. In
this work, we frame ACD as a two-player context-based partially observable
Markov decision problem with observations represented as attributed graphs.
This approach allows our agents to reason through the lens of relational
inductive bias. Agents learn how to reason about hosts interacting with other
system entities in a more general manner, and their actions are understood as
edits to the graph representing the environment. By introducing this bias, we
will show that our agents can better reason about the states of networks and
zero-shot adapt to new ones. We show that this approach outperforms the
state-of-the-art by a wide margin, and makes our agents capable of defending
never-before-seen networks against a wide range of adversaries in a variety of
complex, and multi-agent environments.

</details>


### [32] [Inverting Trojans in LLMs](https://arxiv.org/abs/2509.16203)
*Zhengxing Li,Guangmingmei Yang,Jayaram Raghuram,David J. Miller,George Kesidis*

Main category: cs.LG

TL;DR: 提出了一种针对LLM后门攻击的触发器反转检测方法，通过离散搜索、隐式黑名单和置信度检测来有效识别和反转真实后门触发器


<details>
  <summary>Details</summary>
Motivation: 现有后门检测方法主要针对图像AI，难以直接应用于LLM，因为LLM输入空间离散、可能的触发器组合数量巨大，且缺乏有效的黑名单机制

Method: 采用三组件方法：1）从单例开始的贪婪离散搜索；2）通过激活空间余弦相似度实现隐式黑名单；3）基于高误分类率和异常高置信度的检测机制

Result: 与许多近期工作不同，该方法能够可靠地检测并成功反转真实的后门触发器短语

Conclusion: 该方法有效解决了LLM后门检测的特殊挑战，为LLM安全提供了实用的检测方案

Abstract: While effective backdoor detection and inversion schemes have been developed
for AIs used e.g. for images, there are challenges in "porting" these methods
to LLMs. First, the LLM input space is discrete, which precludes gradient-based
search over this space, central to many backdoor inversion methods. Second,
there are ~30,000^k k-tuples to consider, k the token-length of a putative
trigger. Third, for LLMs there is the need to blacklist tokens that have strong
marginal associations with the putative target response (class) of an attack,
as such tokens give false detection signals. However, good blacklists may not
exist for some domains. We propose a LLM trigger inversion approach with three
key components: i) discrete search, with putative triggers greedily accreted,
starting from a select list of singletons; ii) implicit blacklisting, achieved
by evaluating the average cosine similarity, in activation space, between a
candidate trigger and a small clean set of samples from the putative target
class; iii) detection when a candidate trigger elicits high misclassifications,
and with unusually high decision confidence. Unlike many recent works, we
demonstrate that our approach reliably detects and successfully inverts
ground-truth backdoor trigger phrases.

</details>


<div id='wechat.article'></div>

# wechat.article [[Back]](#toc)

### [33] [DeepSeek-R1通过<em class="highlight">强化学习</em>激励大语言模型的推理能力 |《自然》论文](http://mp.weixin.qq.com/s?__biz=MzAwNTAyMDY0MQ==&mid=2652723537&idx=4&sn=dc259480691d7514b5a7eee397104a5f&chksm=8164014f2dbe0e5f32f81a98c7066b73f35613b83174f5ee91fa4eca19e7aa60854b7d3be033#rd)
*自然系列*

Main category: wechat.article

TL;DR: 他们所提出的强化学习框架能够促生出高级推理模式，例如自我反思、验证以及动态策略调整。因此，训练后的模型在数学、编程竞赛以及STEM领域等可验证任务上表现出了更优性能，其表现超越了通过基于人工示范的传统监督


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 他们所提出的强化学习框架能够促生出高级推理模式，例如自我反思、验证以及动态策略调整。因此，训练后的模型在数学、编程竞赛以及STEM领域等可验证任务上表现出了更优性能，其表现超越了通过基于人工示范的传统监督

</details>


### [34] [用于机器人现实世界<em class="highlight">强化学习</em>的VLAC](http://mp.weixin.qq.com/s?__biz=Mzg5Mzg3ODEwNA==&mid=2247488852&idx=1&sn=88b7c95f60037d88785f46b2af2dbf5e&chksm=c1c96d1f05791828fba29028aaa56f3261f09db4494365df2dc4749760c6538551b3a1569eed#rd)
*human five*

Main category: wechat.article

TL;DR: 提升真实世界强化学习效率的一种直接方法是提供密集的进度奖励，但真实世界强化学习的奖励设计仍面临诸多难题。许多方法依赖非通用的、针对特定任务设计的奖励函数，且每个场景都需单独设计。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 提升真实世界强化学习效率的一种直接方法是提供密集的进度奖励，但真实世界强化学习的奖励设计仍面临诸多难题。许多方法依赖非通用的、针对特定任务设计的奖励函数，且每个场景都需单独设计。

</details>


### [35] [<em class="highlight">强化学习</em>之Q-Learning让机器像人一样学会做决策](http://mp.weixin.qq.com/s?__biz=MzA5MzY1MTQ4Mw==&mid=2247484352&idx=1&sn=3545da2c960a375f99d35b59da3aeba6&chksm=916b75a5288b3512e267e2fafd4695e29a3be4b82809a86f3162200fbbfa84b1aaf42cafb293#rd)
*Wonderful仿真*

Main category: wechat.article

TL;DR: 这个学习过程就很像今天要介绍的Q-Learning算法——一种让机器通过试错来学习最优决策的强化学习方法。什么是Q-Learning？Q-Learning是强化学习中最经典的算法之一，由Christopher Watkins在1989年提出。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这个学习过程就很像今天要介绍的Q-Learning算法——一种让机器通过试错来学习最优决策的强化学习方法。什么是Q-Learning？Q-Learning是强化学习中最经典的算法之一，由Christopher Watkins在1989年提出。

</details>


### [36] [深度研究系统的<em class="highlight">强化学习</em>基础：综述](http://mp.weixin.qq.com/s?__biz=MjM5MzU2NzM5MA==&mid=2649679058&idx=1&sn=cbb482d6c0543f7e7e11b537c6190e75&chksm=bf97f26cfdd38a28d5a20a2c98e09d60167627815a578b295023c946d2b029a854c100598a1f#rd)
*信息网络工程研究中心*

Main category: wechat.article

TL;DR: 据我们所知，本综述是首个专门聚焦深度研究系统强化学习基础的工作。本文沿三个维度系统化了 DeepSeek-R1 之后的研究：（i） 数据合成与数据整理；


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 据我们所知，本综述是首个专门聚焦深度研究系统强化学习基础的工作。本文沿三个维度系统化了 DeepSeek-R1 之后的研究：（i） 数据合成与数据整理；

</details>


### [37] [9/21/2025 AI速递 | 硅谷创业公司打造<em class="highlight">强化学习</em>环境，推动AI训练新热潮](http://mp.weixin.qq.com/s?__biz=Mzk2NDkxMzM0MA==&mid=2247486246&idx=1&sn=dfabd2fc3f493d3a22de5c083d583535&chksm=c58b55e49141d7045d84a9e67e5e3db3f8bed984324d69102372048767c1a22bc51e553c9941#rd)
*渗透智能AGI*

Main category: wechat.article

TL;DR: 强化学习是一种机器学习方法，通过使智能代理在与环境交互的过程中不断学习和优化其行为策略，从而实现特定目标。当前，许多AI实验室正面临数据获取和实验成本高昂的问题，而这些初创公司提供的解决方案，有望显著提


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习是一种机器学习方法，通过使智能代理在与环境交互的过程中不断学习和优化其行为策略，从而实现特定目标。当前，许多AI实验室正面临数据获取和实验成本高昂的问题，而这些初创公司提供的解决方案，有望显著提

</details>


### [38] [使用<em class="highlight">强化学习</em>解决餐饮配送服务中的骑手路径规划与分配问题](http://mp.weixin.qq.com/s?__biz=MzUyNTc2NDA2Mg==&mid=2247494075&idx=1&sn=7dc797715f961c9e50383f89da4ec601&chksm=fbeacdb6b7a8e9d1f4e715d9cf8509f7c637b9beb46c956fe179252216cf01077406a45044a3#rd)
*垃圾分类站*

Main category: wechat.article

TL;DR: 强化学习通过让智能体（agent）在与环境的交互中学习最优策略，以最大化预期的累计奖励，为解决这种复杂的动态决策问题提供了新的思路。研究问题


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习通过让智能体（agent）在与环境的交互中学习最优策略，以最大化预期的累计奖励，为解决这种复杂的动态决策问题提供了新的思路。研究问题

</details>


### [39] [清华周伯文教授课题组大模型<em class="highlight">强化学习</em>新综述](http://mp.weixin.qq.com/s?__biz=MzkyNTcyOTExNQ==&mid=2247485451&idx=1&sn=d9b9658629aac9845ff5cd8843d30c14&chksm=c01f26b5d8fce9486bf21a0beb66e6e75559b30033fade3bced2086c5625d36afaeffc68103c#rd)
*AI科研进阶社*

Main category: wechat.article

TL;DR: 图中首先介绍了强化学习的基本概念，包括状态（State）、动作（Action）、奖励（Reward）和策略（Policy）。在强化学习的框架中，代理（Agent）与环境（Environment）进行交互，代理根据当前状态选择动作，环境则根据代理的动作提


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 图中首先介绍了强化学习的基本概念，包括状态（State）、动作（Action）、奖励（Reward）和策略（Policy）。在强化学习的框架中，代理（Agent）与环境（Environment）进行交互，代理根据当前状态选择动作，环境则根据代理的动作提

</details>


### [40] [吴恩达来信：<em class="highlight">Agentic</em>编程与<em class="highlight">Agentic</em>软件测试协同合作](http://mp.weixin.qq.com/s?__biz=MzIxNzI0ODE4Nw==&mid=2247497620&idx=1&sn=41f65d527e8c78d00dfa10e85f29bd29&chksm=96608b9ffb9f50863685bd182699b0ff92af2d7d84840cf9cdf530e688ac1ae781d15cd60445#rd)
*DeeplearningAI*

Main category: wechat.article

TL;DR: * “奖励作弊”，即编程智能体修改测试代码，使测试更容易通过。* 一个智能体在工作目录下运行了“rm \*.py”，导致整个项目的代码被删除（幸运的是，代码已在GitHub上备份）。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: * “奖励作弊”，即编程智能体修改测试代码，使测试更容易通过。* 一个智能体在工作目录下运行了“rm \*.py”，导致整个项目的代码被删除（幸运的是，代码已在GitHub上备份）。

</details>


### [41] [10 倍效率、0 人工干预！企业级“<em class="highlight">Agentic</em> AI 生命周期”首次曝光，打工人看完直接沉默](http://mp.weixin.qq.com/s?__biz=MzIyNDkxMjQ3OA==&mid=2247485249&idx=1&sn=ee46811f756bb43805db4bd0b5278afb&chksm=e9874817aaa8ea59ba65b9ccd707ec0e4a1520ce2e21361faf0f63dc8dd3ce47478658603092#rd)
*机器之魂*

Main category: wechat.article

TL;DR: 例如，Agent2Agent（A2A）协议指定了智能体卡（一个JSON文档）的概念，它充当智能体的数字“名片”。它包含以下关键信息：CopyIdentity： 名称、描述、提供者信息。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 例如，Agent2Agent（A2A）协议指定了智能体卡（一个JSON文档）的概念，它充当智能体的数字“名片”。它包含以下关键信息：CopyIdentity： 名称、描述、提供者信息。

</details>


### [42] [<em class="highlight">Agentic</em> AI : 助力中国汽车零部件企业高效出海](http://mp.weixin.qq.com/s?__biz=MzU3OTc2MTUyNg==&mid=2247499966&idx=1&sn=9a0789646bb8cc31f422bb033d7750c8&chksm=fc5dfeea95223a684a955d6e13ed3ca8c28061013dbf5d7f6a6ef8b12f0021a8e4f1f1cfc677#rd)
*微钉科技*

Main category: wechat.article

TL;DR: 智能关务智能体Intelligent Customs Agent智慧关务 submit。1、打开信息录入表单。2、上传供应商单据。3、ai自动填充信息。4、人工二次信息确认。5、提交最终录入表单。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 智能关务智能体Intelligent Customs Agent智慧关务 submit。1、打开信息录入表单。2、上传供应商单据。3、ai自动填充信息。4、人工二次信息确认。5、提交最终录入表单。

</details>


### [43] [<em class="highlight">Agentic</em> AI 商业落地的六大关键经验-By 麦肯锡](http://mp.weixin.qq.com/s?__biz=MzkzODMwMzY2MA==&mid=2247483953&idx=1&sn=3b8be31236c26900a1d6907cdd83fb1b&chksm=c39e3a99171441dbcf1f900cec83b7073c9b4fff882996948bf9789db1a89fc7388438b5b4f2#rd)
*ABCD启示录X*

Main category: wechat.article

TL;DR: The #1 mistake？that win don't ask "how cool is this agent？" They ask "how much faster can Sarah complete her entire workflow？variance？" if not， you're overengineering.。1. rule-based + structured data ...


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: The #1 mistake？that win don't ask "how cool is this agent？" They ask "how much faster can Sarah complete her entire workflow？variance？" if not， you're overengineering.。1. rule-based + structured data = use automation， not agents。

</details>


### [44] [【人工智能】|Nature封面聚焦DeepSeek-R1：强化学习如何“教会”<em class="highlight">大模型</em>自主推理？](http://mp.weixin.qq.com/s?__biz=MzU5OTI0ODY2Mg==&mid=2247625768&idx=2&sn=70eb861501f30ceb7f755edf368cd022&chksm=ff727cdf530230f1fbd7f1173b6d2b9cff3ab840225ccef0eb7ac7eb9e54be6b5cb56de5d265#rd)
*陕西省国生商会*

Main category: wechat.article

TL;DR: 大模型进展专栏 9月17日，中国人工智能领域迎来了一项里程碑式的成就。由DeepSeek团队研发的大型语言模型DeepSeek-R1的研究成果——《DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning》（DeepSeek-R1利用纯强化学习为大模型


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型进展专栏 9月17日，中国人工智能领域迎来了一项里程碑式的成就。由DeepSeek团队研发的大型语言模型DeepSeek-R1的研究成果——《DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning》（DeepSeek-R1利用纯强化学习为大模型

</details>


### [45] [RLHF要下岗？Meta × 牛津搞出新套路：用算力教算力，<em class="highlight">大模型</em>训练新范式来了！](http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247708466&idx=1&sn=eec5d0fcdaf9dbbd80d1f03b5f634d95&chksm=97d231fed7ed800714cda2ab012e7e12fbb21f17ed38d13d023c7978bac00b5285680102ff84#rd)
*PaperWeekly*

Main category: wechat.article

TL;DR: 在没有标准答案的任务里，大模型该向谁学习？长期以来，我们依赖人类标注、LLM 判官或多数投票来为模型提供监督，但这些方式要么成本高昂，要么偏好明显，要么只能在候选里“挑最不差的”。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 在没有标准答案的任务里，大模型该向谁学习？长期以来，我们依赖人类标注、LLM 判官或多数投票来为模型提供监督，但这些方式要么成本高昂，要么偏好明显，要么只能在候选里“挑最不差的”。

</details>


### [46] [比思维链准43%！逻辑脑+<em class="highlight">大模型</em>直觉，推理可靠性大幅提升](http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652629554&idx=3&sn=f4a3a225e71b1015d6ca6884c63e1113&chksm=f0c696a70976731e49ff5402eebe7263b6de5bfa0edb43b672bec73906f564cbaee0f589d2f4#rd)
*新智元*

Main category: wechat.article

TL;DR: 大语言模型（LLMs）已在文本生成、代码编写乃至多模态任务中展现出惊人的能力，但在涉及严谨逻辑与物理的空间推理任务上，它们仍显得力不从心。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大语言模型（LLMs）已在文本生成、代码编写乃至多模态任务中展现出惊人的能力，但在涉及严谨逻辑与物理的空间推理任务上，它们仍显得力不从心。

</details>


### [47] [2025必看AI干货!《<em class="highlight">大模型</em>/AIGC/GPT-4/Transformer/DL/KG/NLP/CV AI+X》集合](http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247670980&idx=6&sn=974792504434c204f633c2d2c4d4a76e&chksm=fdccd3bd0a494f024882e711efe18ddbb6a3031624c38210d1c690dfd54d496fe0df5925bd69#rd)
*专知*

Main category: wechat.article

TL;DR: 大语言模型推理系统综述大语言模型驱动的AI智能体通信综述：协议、安全风险与防御对策【博士论文】用于定位、重建与渲染的高效且精确的神经表示


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大语言模型推理系统综述大语言模型驱动的AI智能体通信综述：协议、安全风险与防御对策【博士论文】用于定位、重建与渲染的高效且精确的神经表示

</details>


### [48] [首批上线！首钢股份第一批AI<em class="highlight">大模型</em>智能体投入使用](http://mp.weixin.qq.com/s?__biz=MzI0MDc2MDI0OQ==&mid=2247556270&idx=2&sn=eab4d87569da9aef1fc0ddefd658f069&chksm=e8c25159b42490c65b16fc33c32a3d6060d65ff35a438d486af4e373aa38ba9993eb4478b658#rd)
*今日钢城*

Main category: wechat.article

TL;DR: 助力安全隐患 “早发现、早整改” 首钢股份大模型平台 ouyang 开始会话 隐患项 隐患描述 标准依据 隐患 类别 潜在危险 整改措施 电线破损 多根电线表面有明显破


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 助力安全隐患 “早发现、早整改” 首钢股份大模型平台 ouyang 开始会话 隐患项 隐患描述 标准依据 隐患 类别 潜在危险 整改措施 电线破损 多根电线表面有明显破

</details>


### [49] [金融<em class="highlight">大模型</em>+Agent：构建智能金融管理新场景](http://mp.weixin.qq.com/s?__biz=Mzg2MTU4MjA2MQ==&mid=2247501208&idx=1&sn=62a158c800a90fe88a08651182c058d2&chksm=cf2744c76aad43f474faaefb69c7d1c94eb2ca610d6618039ad6c3be37e5f2a3bd587176a449#rd)
*用友金融*

Main category: wechat.article

TL;DR: 大模型+智能体 近期，金融行业AI技术落地明显提速，大模型与智能体应用正加速从概念验证走向业务深水区，推动智能运营、风险管控、数据决策等核心环节的效率变革。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型+智能体 近期，金融行业AI技术落地明显提速，大模型与智能体应用正加速从概念验证走向业务深水区，推动智能运营、风险管控、数据决策等核心环节的效率变革。

</details>


### [50] [AI圈'<em class="highlight">模型大</em>爆炸'：6<em class="highlight">大模型</em>杀疯了！2025年普通人必须知道的生存指南](http://mp.weixin.qq.com/s?__biz=Mzk3NTI1MzgwMg==&mid=2247484944&idx=1&sn=c0f5091293a5a5281bfcf9f61b995542&chksm=c537393de353c99c7177edaddd72dcf8d6e7fb067cba31e93eb740f31d1ff07db4e53d1f4ca1#rd)
*烛龙照网*

Main category: wechat.article

TL;DR: 这种“即插即用”的特性，让它在2025年年中迅速抢占企业级大模型市场20%的份额，成为增长最快的参与者之一。无论是开发者用它调试复杂代码，学生用它辅助数学解题，还是设计师用它将创意可视化，Gemini 2.5 Pro都在证明：AI


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这种“即插即用”的特性，让它在2025年年中迅速抢占企业级大模型市场20%的份额，成为增长最快的参与者之一。无论是开发者用它调试复杂代码，学生用它辅助数学解题，还是设计师用它将创意可视化，Gemini 2.5 Pro都在证明：AI

</details>


### [51] [几乎解决所有多模态<em class="highlight">大模型</em>问题](http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650449986&idx=1&sn=67d62aa5bb686521a8321c769b882468&chksm=bf2493190114ba49954f768d52060ab35f39bb9d5aa46f05adc82da2995f2ee85fa0a887a2be#rd)
*AINLP*

Main category: wechat.article

TL;DR: 多模态情感分析未来的研究方向 多模态transformer的七十二变 任意视觉提示的多模态大模型 多模态-lisa （cvpr2024） 最新多模态大模型的idea 多模态agents及其应用。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 多模态情感分析未来的研究方向 多模态transformer的七十二变 任意视觉提示的多模态大模型 多模态-lisa （cvpr2024） 最新多模态大模型的idea 多模态agents及其应用。

</details>


### [52] [中国信通院牵头的5项<em class="highlight">大模型</em>行业标准正式发布](http://mp.weixin.qq.com/s?__biz=MzI2MzcxMTU5Mg==&mid=2247532970&idx=1&sn=af316b8bdb4dade0dfe17d0c3caf3d38&chksm=eb39ac92370da0d3177b4f7c4551d3b378ee62e5140a86404f6648d7849f4ee24871e5d354bb#rd)
*四川兴合田职业教育研究院*

Main category: wechat.article

TL;DR: 该系列标准覆盖大模型的开发、管理、运营等多个阶段，主要包括模型开发、能力评估、应用成效、运营管理和可信要求五部分，为大模型技术和产品的研发测试和应用推广提供了重要参考。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 该系列标准覆盖大模型的开发、管理、运营等多个阶段，主要包括模型开发、能力评估、应用成效、运营管理和可信要求五部分，为大模型技术和产品的研发测试和应用推广提供了重要参考。

</details>


### [53] [一文读懂 Go 语言 AI 智能体框架 Eino：灵活高效的<em class="highlight">大模型</em>应用开发工具](http://mp.weixin.qq.com/s?__biz=MzIzODIzNzE0NQ==&mid=2654455438&idx=1&sn=232cfdc7d033d0640fcacf2a25c54c6d&chksm=f3501ab8f8123553cfb5a88c04f9410e627aa54698551d13100a473c8cf38c128d5299b1b3ec#rd)
*玄姐聊AGI*

Main category: wechat.article

TL;DR: Tool扩展大模型能力的工具（比如：搜索引擎、数据库查询、文件读写），支持自定义。Embedding把文本转成向量（方便做语义搜索）。Retriever从向量库 / 文档库中检索相关内容（大模型 “查资料” 的关键）。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: Tool扩展大模型能力的工具（比如：搜索引擎、数据库查询、文件读写），支持自定义。Embedding把文本转成向量（方便做语义搜索）。Retriever从向量库 / 文档库中检索相关内容（大模型 “查资料” 的关键）。

</details>


### [54] [白话模型-01之<em class="highlight">大模型</em>研发全流程一文解读](http://mp.weixin.qq.com/s?__biz=Mzk2NDEyMTM1Mg==&mid=2247485492&idx=2&sn=d7abea6e005a1c4cc241d4d301ae3774&chksm=c54dde5ff4dd85716d6e0b4b75f1b8086c836699e49922fd3f8a81a1930bb1e0e414e938ffd0#rd)
*GPU那些事儿*

Main category: wechat.article

TL;DR: 这是让大模型行为与人类价值观对齐的关键技术。四、评估与迭代 （Evaluation & Iteration）模型训练不是一蹴而就的，需要持续评估和优化。评估基准： 使用一系列标准化的学术基准（如MMLU用于测试 Massive Multitask Language Understanding


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这是让大模型行为与人类价值观对齐的关键技术。四、评估与迭代 （Evaluation & Iteration）模型训练不是一蹴而就的，需要持续评估和优化。评估基准： 使用一系列标准化的学术基准（如MMLU用于测试 Massive Multitask Language Understanding

</details>


### [55] [<em class="highlight">大模型</em>进展专栏第十期丨Nature封面聚焦DeepSeek-R1：强化学习如何“教会”<em class="highlight">大模型</em>自主推理？](http://mp.weixin.qq.com/s?__biz=MzA4ODcwOTExMQ==&mid=2655833018&idx=3&sn=008c4399d1ff8ea0351f14a337d87b55&chksm=8a003ab5c6cdfd6fb725a38347920d1be76caf592e6e17206ec1da15be2d0757e5745adc2f6f#rd)
*中国指挥与控制学会*

Main category: wechat.article

TL;DR: 大模型进展专栏 9月17日，中国人工智能领域迎来了一项里程碑式的成就。由DeepSeek团队研发的大型语言模型DeepSeek-R1的研究成果——《DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning》（DeepSeek-R1利用纯强化学习为大模型


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型进展专栏 9月17日，中国人工智能领域迎来了一项里程碑式的成就。由DeepSeek团队研发的大型语言模型DeepSeek-R1的研究成果——《DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning》（DeepSeek-R1利用纯强化学习为大模型

</details>
